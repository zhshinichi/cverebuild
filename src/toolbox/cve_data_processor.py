import json, os, subprocess
from data.scripts import cve_processor, scraper_utils

class CVEDataProcessor:
    def __init__(self, cve_id: str, cve_json: str = None):
        self.cve_id = cve_id
        self.cve_json = cve_json

    def knowledge_builder_setup(cve_path: str) -> dict:
        """
        Loads the cve json file from the given path
        """
        if not os.path.exists(cve_path):
            raise FileNotFoundError(f"âŒ File not found at {cve_path}")
        return json.loads(open(cve_path, "r", encoding='utf-8').read())

    def pre_reqs_builder_setup(cve_info: dict) -> str:
        """
        Clones a repo to a the parent of given commit and returns the directory tree of the repo
        """
        cur_dir = os.getcwd()
        os.chdir("simulation_environments/")

        if not os.path.exists(cve_info["project"]):
            subprocess.run(f"git clone {cve_info['git_url']}.git", shell=True, timeout=300)
            os.chdir(cve_info["project"])
            subprocess.run(f"git checkout {cve_info['hash']}~1", shell=True, timeout=300)
        else:
            os.chdir(cve_info["project"])
        os.environ['REPO_PATH'] = f"{cve_info['project']}/"
        dir_tree = subprocess.run("tree -d", shell=True, capture_output=True).stdout.decode("utf-8")
        os.chdir(cur_dir)

        return dir_tree
    
    def run(self, code_url: str = "") -> dict:
        cur_dir = os.getcwd()
        # 1) If cache exists, load cve from cache
        if self.cve_json:
            # æ™ºèƒ½é€‰æ‹©æ•°æ®æºï¼ˆå®¹å™¨å†…é™çº§é€»è¾‘ + CVEä¸å­˜åœ¨æ—¶ç»§ç»­å°è¯•fallbackï¼‰
            primary_data = self.cve_json
            # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„ç»å¯¹è·¯å¾„è€Œä¸æ˜¯ç›¸å¯¹è·¯å¾„
            fallback_data = "/workspaces/submission/src/data/large_scale/simple_web_cves_20.json"
            
            cve = None
            data_file = None
            
            # å°è¯•ä¸»æ•°æ®æº
            if os.path.exists(primary_data):
                print(f"[CVEDataProcessor] Checking primary data: {primary_data}")
                try:
                    cve = json.loads(open(primary_data, "r", encoding='utf-8').read()).get(self.cve_id)
                    if cve:
                        data_file = primary_data
                        print(f"[CVEDataProcessor] âœ… Found {self.cve_id} in primary data")
                    else:
                        print(f"[CVEDataProcessor] âš ï¸ {self.cve_id} not in primary data, trying fallback...")
                except Exception as e:
                    print(f"[CVEDataProcessor] âš ï¸ Error reading primary data: {e}")
            
            # å¦‚æžœä¸»æ•°æ®æºæ²¡æ‰¾åˆ°CVEï¼Œå°è¯•fallback
            if not cve and os.path.exists(fallback_data):
                print(f"[CVEDataProcessor] Checking fallback data: {fallback_data}")
                try:
                    cve = json.loads(open(fallback_data, "r", encoding='utf-8').read()).get(self.cve_id)
                    if cve:
                        data_file = fallback_data
                        print(f"[CVEDataProcessor] âœ… Found {self.cve_id} in fallback data")
                except Exception as e:
                    print(f"[CVEDataProcessor] âš ï¸ Error reading fallback data: {e}")
            
            # å¦‚æžœä¸¤ä¸ªæ•°æ®æºéƒ½æ²¡æ‰¾åˆ°CVE
            if not cve:
                error_msg = f"âŒ {self.cve_id} not found in any data source\n"
                error_msg += f"   Checked: {primary_data}\n"
                if os.path.exists(fallback_data):
                    error_msg += f"   Checked: {fallback_data}"
                else:
                    error_msg += f"   Fallback not available: {fallback_data}"
                raise ValueError(error_msg)
        
        # 2) Load and process cve from the 'cvelist' repository
        else:
            # a) get raw cve json from the cvelist repo
            _cve = cve_processor.get_cve_by_id(self.cve_id)

            # b) get github url from patch commit
            patch_urls = _cve.get("patch_urls")
            if patch_urls:
                print(f"ðŸ” Found patch URLs: {patch_urls}")

                # é¦–å…ˆæ£€æŸ¥æ•°æ®é‡Œæ˜¯å¦å·²ç»æœ‰ sw_version å’Œ sw_version_wget
                if _cve.get("sw_version") and _cve.get("sw_version_wget"):
                    print(f"ðŸ“¦ Using pre-defined version: {_cve.get('sw_version')}")
                    cve = {
                        "published_date": _cve.get("published_date") or cve_processor.get_published_date(_cve['id']),
                        "patch_commits": _cve.get("patch_commits") or [
                            {
                                "url": patch['patch_commit_url'],
                                "content": cve_processor.get_patch_content(patch['owner'], patch['project'], patch['hash'])
                            }
                            for patch in _cve.get('patch_urls')
                        ],
                        "sw_version": _cve.get("sw_version"),
                        "sw_version_wget": _cve.get("sw_version_wget"),
                        "description": _cve.get('description'),
                        "sec_adv": _cve.get("sec_adv"),
                    }
                else:
                    # å°è¯•ä»Ž GitHub èŽ·å–ç‰ˆæœ¬ tag
                    version_data = _cve.get("version_data")
                    if version_data:
                        try:
                            version = cve_processor.get_software_versions(_cve['id'])[0]
                        except Exception as e:
                            version = (False, 'anomaly')
                        
                        tag = None
                        if version[1] != 'n/a' and version[1] != 'anomaly':
                            tag = cve_processor.affected_version_exist(patch_urls[0]['owner'], patch_urls[0]['project'], version[1], version[0])
                        
                        if tag:
                            cve = {
                                "published_date": cve_processor.get_published_date(_cve['id']),
                                "patch_commits": [
                                    {
                                        "url": patch['patch_commit_url'],
                                        "content": cve_processor.get_patch_content(patch['owner'], patch['project'], patch['hash'])
                                    }
                                    for patch in _cve.get('patch_urls')
                                ],
                                "sw_version": f"{tag}",
                                "sw_version_wget": f"{patch_urls[0]['repo_url']}/archive/refs/tags/{tag}.zip",
                                "description": _cve.get('description')
                            }
                        else:
                            raise ValueError(f"âŒ We were not able to find the affected version tag in the repo. Please provide the code_url argument")
                    else:
                        raise ValueError(f"âŒ No version_data found and no pre-defined sw_version. Please provide the code_url argument")

            else:
                if code_url:
                    cve = {
                        "published_date": cve_processor.get_published_date(_cve['id']),
                        "patch_commits": [],
                        "sw_version": "n/a",
                        "sw_version_wget": code_url,
                        "description": _cve.get('description')
                    }
                else:
                    raise ValueError(f"âŒ We were not able to find patch URLs, so please provide the code_url argument")
                
            potential_advisories = _cve.get("other_urls")
            sec_advs = []
            if potential_advisories:
                keywords = ['security', 'advisory', 'advisories', 'bounties', 'bounty']
                for url in potential_advisories:
                    url_words = url.split('/')
                    if any(keyword in url_words for keyword in keywords):
                        sec_adv_content = scraper_utils.scrape(url)
                        sec_advs.append({
                                            "url": url,
                                            "content": sec_adv_content
                                        })
            cve['sec_advs'] = sec_advs

            cwe = _cve.get("cwe")
            if cwe:
                cve["cwe"] = [{"id": c['id'], "value": c['value']} for c in cwe]

        # 3) download the vulnerable tag version of the repo
        subprocess.run("rm -rf simulation_environments/*", shell=True)
        os.chdir("simulation_environments/")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ pip åŒ…ï¼ˆæ–°å­—æ®µ pip_packageï¼‰
        pip_package = cve.get('pip_package')
        pip_version = cve.get('pip_version')
        
        if pip_package and pip_version:
            # å¯¹äºŽ pip åŒ…ï¼Œä½¿ç”¨ pip download ä¸‹è½½æºä»£ç 
            print(f"ðŸ“¦ Detected pip package: {pip_package}=={pip_version}")
            print(f"ðŸ“¥ Downloading pip package source...")
            
            # ä½¿ç”¨ pip download èŽ·å–æºä»£ç åˆ†å‘åŒ…
            pip_result = subprocess.run(
                f"pip download {pip_package}=={pip_version} --no-deps --no-binary :all: -d .",
                shell=True,
                capture_output=True,
                text=True
            )
            
            if pip_result.returncode != 0:
                # å¦‚æžœæ²¡æœ‰æºä»£ç åˆ†å‘åŒ…ï¼Œå°è¯•ä¸‹è½½ wheel
                print("âš ï¸ Source distribution not available, downloading wheel...")
                pip_result = subprocess.run(
                    f"pip download {pip_package}=={pip_version} --no-deps -d .",
                    shell=True,
                    capture_output=True,
                    text=True
                )
            
            if pip_result.returncode != 0:
                os.chdir(cur_dir)
                raise RuntimeError(f"Failed to download pip package {pip_package}=={pip_version}: {pip_result.stderr}")
            
            # è§£åŽ‹ä¸‹è½½çš„åŒ…
            downloaded_files = os.listdir(".")
            print(f"ðŸ“‚ Downloaded files: {downloaded_files}")
            
            # å¤„ç† .tar.gz æˆ– .whl æ–‡ä»¶
            for file in downloaded_files:
                if file.endswith('.tar.gz'):
                    subprocess.run(f"tar xzf {file}", shell=True)
                elif file.endswith('.whl'):
                    subprocess.run(f"unzip {file} -d {pip_package.replace('-', '_')}", shell=True)
            
            # æ‰¾åˆ°è§£åŽ‹åŽçš„ç›®å½•
            dirs = [f for f in os.listdir(".") if os.path.isdir(f)]
            if not dirs:
                os.chdir(cur_dir)
                raise FileNotFoundError(f"No directory found after extracting pip package")
            
            dir_name = dirs[0]
            print(f"ðŸ“‚ Using directory: {dir_name}")
            os.chdir(dir_name)
            os.environ['REPO_PATH'] = f"{dir_name}/"
            
            # æ›´æ–° cve ä¿¡æ¯
            cve['dir_tree'] = subprocess.run("tree -d", shell=True, capture_output=True).stdout.decode("utf-8")
            cve['repo_path'] = f"{dir_name}/"
            os.chdir(cur_dir)
            
            return cve
        
        download_url = cve['sw_version_wget']
        print(f"ðŸ“¥ Downloading from: {download_url}")
        
        # å‡†å¤‡ codeload å¤‡ç”¨ URLï¼ˆç”¨äºŽ GitHub archive ä¸‹è½½å¤±è´¥æ—¶ï¼‰
        # https://github.com/user/repo/archive/refs/tags/v1.0.zip -> https://codeload.github.com/user/repo/zip/refs/tags/v1.0
        codeload_url = None
        if 'github.com' in download_url and '/archive/' in download_url:
            import re
            match = re.match(r'https://github\.com/([^/]+)/([^/]+)/archive/(.+)\.zip', download_url)
            if match:
                owner, repo, ref_path = match.groups()
                codeload_url = f"https://codeload.github.com/{owner}/{repo}/zip/{ref_path}"
        
        zip_filename = download_url.split('/')[-1] if download_url.endswith('.zip') else 'download.zip'
        
        # ä¼˜å…ˆå°è¯•åŽŸå§‹æ–¹å¼ï¼ˆwgetï¼‰
        wget_result = subprocess.run(
            f"wget --timeout=120 --tries=3 '{download_url}'", 
            shell=True, 
            capture_output=True,
            text=True
        )
        
        download_success = wget_result.returncode == 0
        
        if not download_success:
            print(f"âš ï¸ wget failed with return code {wget_result.returncode}")
            print(f"stderr: {wget_result.stderr}")
            
            # æž„å»ºå°è¯•åˆ—è¡¨ï¼šå…ˆæ­£å¸¸ SSLï¼Œå†å¿½ç•¥ SSL éªŒè¯ï¼ˆå¤„ç†ä»£ç†/MITM çŽ¯å¢ƒï¼‰
            curl_attempts = []
            target_url = codeload_url if codeload_url else download_url
            curl_attempts.append((f"curl -sSL --connect-timeout 60 --max-time 300 -o {zip_filename} '{target_url}'", "curl with SSL"))
            curl_attempts.append((f"curl -sSL -k --connect-timeout 60 --max-time 300 -o {zip_filename} '{target_url}'", "curl with -k (insecure)"))
            
            for curl_cmd, desc in curl_attempts:
                print(f"ðŸ”„ Trying {desc}: {target_url}")
                curl_result = subprocess.run(
                    curl_cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=360
                )
                if curl_result.returncode == 0:
                    # æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆä¸ä¸ºç©ºï¼‰
                    if os.path.exists(zip_filename) and os.path.getsize(zip_filename) > 0:
                        print(f"âœ… Download succeeded with {desc}")
                        download_success = True
                        break
                print(f"âš ï¸ {desc} failed: {curl_result.stderr}")
            
            if not download_success:
                os.chdir(cur_dir)
                raise RuntimeError(f"Failed to download {download_url}: all download methods failed")

        # æ£€æŸ¥æ˜¯å¦æœ‰ zip æ–‡ä»¶
        zip_files = [file for file in os.listdir(".") if file.endswith(".zip")]
        if not zip_files:
            os.chdir(cur_dir)
            raise FileNotFoundError(f"No .zip file found after downloading from {download_url}. Directory contents: {os.listdir('.')}")
        
        zip_name = zip_files[0]
        print(f"ðŸ“¦ Found zip file: {zip_name}")
        subprocess.run(f"unzip {zip_name}", shell=True)

        # æ£€æŸ¥æ˜¯å¦æœ‰è§£åŽ‹åŽçš„ç›®å½•
        dirs = [file for file in os.listdir(".") if os.path.isdir(file)]
        if not dirs:
            os.chdir(cur_dir)
            raise FileNotFoundError(f"No directory found after unzipping {zip_name}. Directory contents: {os.listdir('.')}")
        
        # ðŸ”§ ä¿®å¤ï¼šé€‰æ‹©ä¸Ž zip æ–‡ä»¶åæœ€åŒ¹é…çš„ç›®å½•ï¼Œé¿å…é€‰æ‹©æ®‹ç•™ç›®å½•
        zip_base = zip_name.replace('.zip', '').lower()
        # å°è¯•æ‰¾åˆ°åŒ¹é…çš„ç›®å½•
        matching_dirs = [d for d in dirs if zip_base in d.lower() or d.lower() in zip_base]
        if matching_dirs:
            dir_name = matching_dirs[0]
        else:
            # æ²¡æœ‰åŒ¹é…çš„ï¼Œé€‰æ‹©æœ€æ–°åˆ›å»ºçš„ç›®å½•ï¼ˆåˆšè§£åŽ‹çš„ï¼‰
            dirs_with_time = [(d, os.path.getctime(d)) for d in dirs]
            dirs_with_time.sort(key=lambda x: x[1], reverse=True)
            dir_name = dirs_with_time[0][0]
        
        print(f"ðŸ“‚ Using directory: {dir_name} (from {len(dirs)} dirs)")
        os.chdir(dir_name)
        os.environ['REPO_PATH'] = f"{dir_name}/"

        # Fix syntax error in Calibre 7.15.0 fts.py (missing comma)
        fts_file = "src/calibre/srv/fts.py"
        if os.path.exists(fts_file):
            with open(fts_file, 'r', encoding='utf-8') as f:
                content = f.read()
            # Fix: query = rd.query.get('query' '') -> query = rd.query.get('query', '')
            content = content.replace("rd.query.get('query' '')", "rd.query.get('query', '')")
            with open(fts_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… Applied syntax fix to {fts_file}")

        # 4) get the directory tree of the repo
        cve['dir_tree'] = subprocess.run("tree -d", shell=True, capture_output=True).stdout.decode("utf-8")
        cve['repo_path'] = f"{dir_name}/"
        os.chdir(cur_dir)

        return cve
