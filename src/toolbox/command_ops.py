import subprocess
import os
import time
import uuid
import signal
import re
from typing import Optional, Dict, List
from collections import defaultdict
from dataclasses import dataclass, field

from agentlib.lib import tools

# å¯¼å…¥ç»éªŒåº“ï¼ˆæ‡’åŠ è½½é¿å…å¾ªç¯å¯¼å…¥ï¼‰
def _get_experience_library():
    """æ‡’åŠ è½½ç»éªŒåº“ï¼Œé¿å…å¾ªç¯å¯¼å…¥"""
    from toolbox.experience_library import get_experience_library
    return get_experience_library()

# å…¨å±€åæ€å™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
_mid_exec_reflector: Optional['MidExecutionReflector'] = None
_reflection_enabled: bool = True


# ==================== æ™ºèƒ½ä¸Šä¸‹æ–‡åˆ†æå™¨ ====================
@dataclass
class ContextualInsight:
    """ä¸Šä¸‹æ–‡åˆ†æç»“æœ"""
    issue_type: str  # download_failed, file_corrupted, version_not_exist, etc.
    evidence: str  # è¯æ®æè¿°
    blocking: bool  # æ˜¯å¦åº”è¯¥é˜»æ­¢åç»­ç›¸å…³å‘½ä»¤
    suggestion: str  # å…·ä½“å»ºè®®
    related_files: List[str] = field(default_factory=list)  # ç›¸å…³æ–‡ä»¶


class ContextAwareAnalyzer:
    """
    æ™ºèƒ½ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†æå™¨
    
    åˆ†æå‘½ä»¤æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ï¼Œè¯†åˆ«æ·±å±‚é—®é¢˜ï¼š
    - curlä¸‹è½½åªæœ‰9å­—èŠ‚ = ä¸‹è½½å¤±è´¥
    - file xxx.zip: ASCII text = æ–‡ä»¶ä¸æ˜¯zip
    - 404 Not Found = URLé”™è¯¯
    - OutputType='Library' = ç±»åº“é¡¹ç›®ï¼Œä¸èƒ½ dotnet run
    
    ğŸ’¡ è®°å¿†åŠŸèƒ½è¯´æ˜ï¼š
    è¿™ä¸ªåˆ†æå™¨å®ç°äº†"å¼ºåˆ¶è®°å¿†"ï¼Œä¸æ™®é€šçš„"å»ºè®®"ä¸åŒï¼š
    1. å¤±è´¥æ¨¡å¼è¢«è®°å½•åˆ° blocking_insights
    2. åç»­ç›¸åŒå‘½ä»¤ä¼šè¢« should_block_command å¼ºåˆ¶é˜»æ­¢
    3. Agent æ— æ³•ç»•è¿‡è¿™ä¸ªé™åˆ¶ï¼Œå¿…é¡»é‡‡ç”¨æ–°ç­–ç•¥
    
    ğŸ”„ ç»éªŒåº“é›†æˆï¼š
    ä¸ ProjectExperienceLibrary é…åˆï¼Œå®ç°ï¼š
    1. ä»å†å²ä»»åŠ¡ä¸­å­¦ä¹ é¡¹ç›®ç±»å‹ç»éªŒ
    2. è‡ªåŠ¨è¯†åˆ«é¡¹ç›®ç±»å‹å¹¶åº”ç”¨å¯¹åº”ç»éªŒ
    3. è·¨ä»»åŠ¡å…±äº«å¤±è´¥æ¨¡å¼å’Œè§£å†³æ–¹æ¡ˆ
    """
    
    def __init__(self):
        # ç´¯ç§¯çš„ä¸Šä¸‹æ–‡è®°å¿†
        self.download_history: Dict[str, Dict] = {}  # filename -> {size, type, url, status}
        self.known_bad_urls: set = set()  # å·²çŸ¥å¤±è´¥çš„URL
        self.known_bad_versions: set = set()  # å·²çŸ¥ä¸å­˜åœ¨çš„ç‰ˆæœ¬
        self.blocking_insights: List[ContextualInsight] = []  # é˜»æ­¢æ€§é—®é¢˜
        
        # ğŸ†• é‡å¤å‘½ä»¤å¤±è´¥æ£€æµ‹å™¨
        self.command_failure_counts: Dict[str, int] = defaultdict(int)  # å‘½ä»¤æ¨¡å¼ -> å¤±è´¥æ¬¡æ•°
        self.blocked_command_patterns: set = set()  # å·²è¢«é˜»æ­¢çš„å‘½ä»¤æ¨¡å¼
        self.MAX_REPEATED_FAILURES = 3  # è¶…è¿‡æ­¤æ¬¡æ•°è‡ªåŠ¨é˜»æ­¢
        
        # ğŸ†• é¡¹ç›®ç±»å‹æ£€æµ‹çŠ¶æ€
        self.detected_project_type: Optional[str] = None  # dotnet, python, node, java, go
        self.project_files_detected: List[str] = []  # æ£€æµ‹åˆ°çš„é¡¹ç›®æ–‡ä»¶
        
        # ç»éªŒåº“é›†æˆï¼ˆæ‡’åŠ è½½ï¼‰
        self._experience_library = None
    
    @property
    def experience_library(self):
        """æ‡’åŠ è½½è·å–ç»éªŒåº“"""
        if self._experience_library is None:
            try:
                self._experience_library = _get_experience_library()
            except Exception as e:
                print(f"âš ï¸ åŠ è½½ç»éªŒåº“å¤±è´¥: {e}")
                self._experience_library = None
        return self._experience_library
    
    def _proactive_check_dotnet_project(self, command: str) -> Optional[str]:
        """
        ä¸»åŠ¨æ£€æµ‹ .NET é¡¹ç›®ç±»å‹
        
        åœ¨æ‰§è¡Œ dotnet run ä¹‹å‰ï¼Œæ£€æŸ¥ .csproj æ–‡ä»¶ç¡®å®šé¡¹ç›®ç±»å‹ã€‚
        å¦‚æœæ˜¯ç±»åº“é¡¹ç›®ï¼Œç›´æ¥é˜»æ­¢æ‰§è¡Œã€‚
        
        è¿”å›ï¼šé˜»æ­¢åŸå› ï¼Œæˆ– None è¡¨ç¤ºå…è®¸æ‰§è¡Œ
        """
        # æå– .csproj æ–‡ä»¶è·¯å¾„
        proj_match = re.search(r'--project\s+(\S+\.csproj)', command)
        if not proj_match:
            # å°è¯•åŒ¹é…ç®€å•æ ¼å¼: dotnet run xxx.csproj
            proj_match = re.search(r'dotnet\s+run\s+.*?(\S+\.csproj)', command, re.IGNORECASE)
        
        if not proj_match:
            return None
        
        csproj_path = proj_match.group(1)
        
        try:
            # è¯»å– .csproj æ–‡ä»¶å†…å®¹
            content = None
            found_path = None
            
            # æœç´¢è·¯å¾„åˆ—è¡¨
            search_paths = [
                csproj_path,  # åŸå§‹è·¯å¾„
                os.path.join('/workspaces/submission/src/simulation_environments', csproj_path),
                os.path.join('/tmp', csproj_path),
                os.path.join('.', csproj_path),
            ]
            
            # æœç´¢åŒ…å«é¡¹ç›®åç§°çš„ç›®å½•
            proj_name = os.path.basename(csproj_path).replace('.csproj', '')
            if proj_name:
                # åœ¨æ¨¡æ‹Ÿç¯å¢ƒç›®å½•ä¸­æœç´¢
                sim_env_base = '/workspaces/submission/src/simulation_environments'
                try:
                    if os.path.isdir(sim_env_base):
                        for subdir in os.listdir(sim_env_base):
                            potential_path = os.path.join(sim_env_base, subdir, csproj_path)
                            search_paths.append(potential_path)
                except:
                    pass
            
            for path in search_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    found_path = path
                    break
            
            if content is None:
                return None  # æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œä¸é˜»æ­¢
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç±»åº“é¡¹ç›®
            library_indicators = [
                '<OutputType>Library</OutputType>',
                '<OutputType>library</OutputType>',
                "<OutputType>Library</OutputType>".lower(),
            ]
            
            content_lower = content.lower()
            
            # æ£€æµ‹ç±»åº“é¡¹ç›®
            # å…³é”®ï¼šå³ä½¿æ˜¯ Web SDKï¼Œå¦‚æœæ˜ç¡®è®¾ç½®äº† OutputType=Libraryï¼Œä¹Ÿåº”è¯¥é˜»æ­¢
            if '<outputtype>library</outputtype>' in content_lower:
                # è®°å½•åˆ°ç»éªŒåº“
                if self.experience_library:
                    self.experience_library.identify_project_type("OutputType is 'Library'", command)
                
                return f"""â›” ä¸»åŠ¨æ£€æµ‹åˆ°ç±»åº“é¡¹ç›®ï¼

ğŸ“Š é¡¹ç›®æ–‡ä»¶åˆ†æ: {found_path or csproj_path}
   æ£€æµ‹åˆ° <OutputType>Library</OutputType>
   è¿™æ˜¯ä¸€ä¸ª .NET ç±»åº“/NuGet åŒ…ï¼Œä¸æ˜¯å¯æ‰§è¡Œç¨‹åºã€‚

âœ… æ¨èæ›¿ä»£æ–¹æ¡ˆï¼š
   1. dotnet test  # è¿è¡Œå•å…ƒæµ‹è¯•
   2. åˆ›å»ºæµ‹è¯•æ§åˆ¶å°ç¨‹åºå¼•ç”¨è¯¥åº“

âŒ é˜»æ­¢æ‰§è¡Œ: {command[:60]}..."""
            
            # æ£€æµ‹æ˜¯å¦ç¼ºå°‘å…¥å£ç‚¹ï¼ˆæ²¡æœ‰ Exe ç±»å‹ä¸”ä¸æ˜¯ Web SDKï¼‰
            if '<outputtype>' not in content_lower:
                # é»˜è®¤å¯èƒ½æ˜¯ç±»åº“ï¼ˆæ²¡æœ‰æ˜ç¡®æŒ‡å®š OutputTypeï¼‰
                if 'microsoft.net.sdk.web' not in content_lower:
                    # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦æœ‰ Main å…¥å£
                    # å¦‚æœæ˜¯ classlib æ¨¡æ¿ï¼Œé€šå¸¸æ²¡æœ‰ OutputType
                    if 'microsoft.net.sdk' in content_lower and 'aspnetcore' not in content_lower:
                        return None  # ä¸ç¡®å®šï¼Œè®©å®ƒå°è¯•
        
        except Exception as e:
            # è¯»å–å¤±è´¥ï¼Œä¸é˜»æ­¢
            print(f"âš ï¸ ä¸»åŠ¨æ£€æµ‹å¤±è´¥: {e}")
            return None
        
        return None
    
    def _proactive_check_npm_project(self) -> Optional[str]:
        """
        ä¸»åŠ¨æ£€æµ‹ npm é¡¹ç›®ç±»å‹
        
        åœ¨æ‰§è¡Œ npm start ä¹‹å‰ï¼Œæ£€æŸ¥ package.json æ˜¯å¦æœ‰ start è„šæœ¬ã€‚
        å¦‚æœæ²¡æœ‰ start è„šæœ¬ï¼Œç›´æ¥é˜»æ­¢æ‰§è¡Œã€‚
        
        è¿”å›ï¼šé˜»æ­¢åŸå› ï¼Œæˆ– None è¡¨ç¤ºå…è®¸æ‰§è¡Œ
        """
        import json as json_module
        
        # å¸¸è§å·¥ä½œç›®å½•
        search_paths = ['.', '/workspaces/submission/src/simulation_environments']
        
        for base_dir in search_paths:
            package_json_path = os.path.join(base_dir, 'package.json')
            if os.path.exists(package_json_path):
                try:
                    with open(package_json_path, 'r', encoding='utf-8') as f:
                        package_data = json_module.load(f)
                    
                    scripts = package_data.get('scripts', {})
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ start è„šæœ¬
                    if 'start' not in scripts:
                        # è®°å½•åˆ°ç»éªŒåº“
                        if self.experience_library:
                            self.experience_library.identify_project_type('Missing script: "start"', 'npm start')
                        
                        available_scripts = list(scripts.keys())[:5] if scripts else ['æ— ']
                        
                        return f"""â›” ä¸»åŠ¨æ£€æµ‹åˆ° npm åº“é¡¹ç›®ï¼

ğŸ“Š package.json åˆ†æ: {package_json_path}
   æ²¡æœ‰æ‰¾åˆ° 'start' è„šæœ¬
   å¯ç”¨è„šæœ¬: {', '.join(available_scripts)}

âœ… æ¨èæ›¿ä»£æ–¹æ¡ˆï¼š
   1. npm test  # è¿è¡Œæµ‹è¯•
   2. åˆ›å»ºæµ‹è¯• HTML é¡µé¢å¼•å…¥è¯¥åº“

âŒ é˜»æ­¢æ‰§è¡Œ: npm start"""
                
                except Exception as e:
                    print(f"âš ï¸ npm ä¸»åŠ¨æ£€æµ‹å¤±è´¥: {e}")
                    return None
                
                break
        
        return None
    
    # ==================== ğŸ†• é‡å¤å¤±è´¥æ£€æµ‹å™¨ ====================
    
    def record_command_failure(self, command: str, error_output: str = "") -> Optional[str]:
        """
        è®°å½•å‘½ä»¤å¤±è´¥ï¼Œå¹¶æ£€æµ‹æ˜¯å¦è¶…è¿‡é‡å¤æ¬¡æ•°é™åˆ¶
        
        è¿”å›ï¼šå¦‚æœè¶…è¿‡é™åˆ¶ï¼Œè¿”å›é˜»æ­¢åŸå› ï¼›å¦åˆ™è¿”å› None
        """
        # æå–å‘½ä»¤æ¨¡å¼ï¼ˆå»é™¤å‚æ•°ï¼‰
        pattern = self._extract_command_pattern(command)
        
        # è®°å½•å¤±è´¥
        self.command_failure_counts[pattern] += 1
        count = self.command_failure_counts[pattern]
        
        print(f"ğŸ“Š å‘½ä»¤å¤±è´¥è®°å½•: '{pattern}' å·²å¤±è´¥ {count} æ¬¡")
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if count >= self.MAX_REPEATED_FAILURES:
            self.blocked_command_patterns.add(pattern)
            return f"""â›” å‘½ä»¤å·²è¢«è‡ªåŠ¨é˜»æ­¢ï¼

ğŸ“Š é‡å¤å¤±è´¥æ£€æµ‹:
   å‘½ä»¤æ¨¡å¼: {pattern}
   å·²å¤±è´¥æ¬¡æ•°: {count}
   æœ€åé”™è¯¯: {error_output[:200] if error_output else 'æ— '}

âš ï¸ åŒä¸€å‘½ä»¤åå¤å¤±è´¥ {self.MAX_REPEATED_FAILURES}+ æ¬¡ï¼Œè¯´æ˜è¯¥æ–¹æ³•æ ¹æœ¬ä¸å¯è¡Œã€‚
âœ… è¯·é‡‡ç”¨å®Œå…¨ä¸åŒçš„ç­–ç•¥ï¼"""
        
        return None
    
    def _extract_command_pattern(self, command: str) -> str:
        """
        æå–å‘½ä»¤æ¨¡å¼ï¼ˆä¿ç•™è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡é¿å…è¯¯åˆ¤ï¼‰
        
        ğŸ”§ æ”¹è¿›ï¼šä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡ï¼Œé¿å…å°†ä¸åŒå‘½ä»¤è¯¯åˆ¤ä¸ºç›¸åŒæ¨¡å¼
        ä¾‹å¦‚ï¼šcd project_a å’Œ cd project_b åº”è¯¥æ˜¯ä¸åŒçš„æ¨¡å¼
        """
        # å¤„ç†å¤åˆå‘½ä»¤ï¼ˆ&& æˆ– ;ï¼‰
        if '&&' in command:
            # å–æœ€åä¸€ä¸ªæœ‰æ„ä¹‰çš„å‘½ä»¤ä½œä¸ºæ¨¡å¼
            parts = command.split('&&')
            last_cmd = parts[-1].strip()
            if last_cmd:
                return self._extract_command_pattern(last_cmd)
        
        parts = command.strip().split()
        if not parts:
            return command
        
        base_cmd = parts[0]
        
        # ğŸ”§ ä¿®å¤ï¼šcd å‘½ä»¤éœ€è¦ä¿ç•™ç›®æ ‡ç›®å½•
        if base_cmd == 'cd' and len(parts) > 1:
            target = parts[1]
            # ä¿ç•™æœ€åä¸¤çº§ç›®å½•ä½œä¸ºæ¨¡å¼
            if '/' in target:
                target_parts = target.rstrip('/').split('/')
                target = '/'.join(target_parts[-2:]) if len(target_parts) > 1 else target_parts[-1]
            return f"cd {target}"
        
        # åŒ…ç®¡ç†å™¨å‘½ä»¤ï¼šä¿ç•™å‘½ä»¤ + å­å‘½ä»¤ + ä¸»è¦åŒ…å
        if base_cmd in ['npm', 'yarn', 'pnpm', 'pip', 'pip3', 'composer']:
            if len(parts) >= 3:
                # npm install package-name -> "npm install package"
                return f"{base_cmd} {parts[1]} {parts[2].split('@')[0].split('==')[0][:30]}"
            elif len(parts) >= 2:
                return f"{base_cmd} {parts[1]}"
        
        # æ„å»ºå·¥å…·ï¼šä¿ç•™å‘½ä»¤ + ç›®æ ‡
        if base_cmd in ['mvn', 'gradle', 'make', 'cargo']:
            if len(parts) >= 2:
                return f"{base_cmd} {parts[1]}"
        
        # dotnetï¼šä¿ç•™å‘½ä»¤ + å­å‘½ä»¤ + é¡¹ç›®æ–‡ä»¶
        if base_cmd == 'dotnet' and len(parts) >= 2:
            sub_cmd = parts[1]
            if sub_cmd in ['run', 'build', 'test'] and len(parts) >= 3:
                proj = parts[2] if parts[2].endswith('.csproj') else ''
                if proj:
                    return f"dotnet {sub_cmd} {os.path.basename(proj)}"
            return f"dotnet {sub_cmd}"
        
        # curl/wgetï¼šä¿ç•™å®Œæ•´ URL çš„ä¸»æœºéƒ¨åˆ†
        if base_cmd in ['curl', 'wget']:
            for part in parts[1:]:
                if part.startswith('http'):
                    # æå–ä¸»æœºåå’Œè·¯å¾„å¼€å¤´
                    import urllib.parse
                    try:
                        parsed = urllib.parse.urlparse(part)
                        return f"{base_cmd} {parsed.netloc}{parsed.path[:30]}"
                    except:
                        pass
            if len(parts) > 1:
                return f"{base_cmd} {parts[1][:50]}"
        
        # å…¶ä»–å‘½ä»¤ï¼šä¿ç•™å‰ä¸¤ä¸ªéƒ¨åˆ†
        if len(parts) >= 2:
            return f"{base_cmd} {parts[1][:50]}"
        
        return base_cmd
    
    def is_command_blocked_by_repetition(self, command: str) -> Optional[str]:
        """æ£€æŸ¥å‘½ä»¤æ˜¯å¦å› é‡å¤å¤±è´¥è¢«é˜»æ­¢"""
        pattern = self._extract_command_pattern(command)
        
        if pattern in self.blocked_command_patterns:
            count = self.command_failure_counts.get(pattern, 0)
            return f"""â›” å‘½ä»¤å·²è¢«é˜»æ­¢ï¼ˆé‡å¤å¤±è´¥ {count} æ¬¡ï¼‰

ğŸ“Š å‘½ä»¤æ¨¡å¼: {pattern}
âš ï¸ è¯¥å‘½ä»¤å·²å¤šæ¬¡å¤±è´¥ï¼Œè¯·ä½¿ç”¨å®Œå…¨ä¸åŒçš„æ–¹æ³•ï¼"""
        
        return None
    
    # ==================== ğŸ†• å·¥å…·/è¯­è¨€åŒ¹é…æ£€æµ‹å™¨ ====================
    
    def detect_tool_language_mismatch(self, command: str) -> Optional[str]:
        """
        æ£€æµ‹æ˜¯å¦ä½¿ç”¨äº†é”™è¯¯çš„å·¥å…·å¤„ç†é¡¹ç›®
        
        ä¾‹å¦‚ï¼š
        - ç”¨ pip install å®‰è£… .NET NuGet åŒ…
        - ç”¨ python è¿è¡Œ .cs/.csproj æ–‡ä»¶
        - ç”¨ dotnet å¤„ç† Python é¡¹ç›®
        - ğŸ†• åœ¨ dotnet é¡¹ç›®ä¸­ä½¿ç”¨ pip/python
        """
        cmd_lower = command.lower()
        
        # ğŸ†• å¢å¼ºï¼šå¦‚æœå·²æ£€æµ‹åˆ°é¡¹ç›®ç±»å‹ï¼Œæ£€æŸ¥å·¥å…·æ˜¯å¦åŒ¹é…
        if self.detected_project_type == 'dotnet':
            # åœ¨ .NET é¡¹ç›®ä¸­ä½¿ç”¨ Python å·¥å…·
            if 'pip install' in cmd_lower or 'pip3 install' in cmd_lower:
                return f"""â›” é¡¹ç›®ç±»å‹ä¸åŒ¹é…ï¼

ğŸ” å·²æ£€æµ‹åˆ°: è¿™æ˜¯ä¸€ä¸ª .NET/C# é¡¹ç›®
   æ£€æµ‹æ–‡ä»¶: {', '.join(self.project_files_detected[:3])}

ğŸš¨ é”™è¯¯: æ‚¨åœ¨å°è¯•ä½¿ç”¨ pip (Python åŒ…ç®¡ç†å™¨)
   å‘½ä»¤: {command[:50]}...

âœ… .NET é¡¹ç›®çš„æ­£ç¡®æ–¹æ³•:
   1. dotnet restore  # æ¢å¤ä¾èµ–
   2. dotnet build    # ç¼–è¯‘
   3. dotnet test     # æµ‹è¯•"""
            
            if ('python ' in cmd_lower or 'python3 ' in cmd_lower) and not 'python -c' in cmd_lower:
                return f"""â›” é¡¹ç›®ç±»å‹ä¸åŒ¹é…ï¼

ğŸ” å·²æ£€æµ‹åˆ°: è¿™æ˜¯ä¸€ä¸ª .NET/C# é¡¹ç›®
   æ£€æµ‹æ–‡ä»¶: {', '.join(self.project_files_detected[:3])}

ğŸš¨ é”™è¯¯: æ‚¨åœ¨å°è¯•ä½¿ç”¨ Python æ‰§è¡Œ
   å‘½ä»¤: {command[:50]}...

âœ… .NET é¡¹ç›®çš„æ­£ç¡®æ–¹æ³•:
   1. dotnet build    # ç¼–è¯‘
   2. dotnet run      # è¿è¡Œï¼ˆå¦‚æœæ˜¯å¯æ‰§è¡Œé¡¹ç›®ï¼‰
   3. dotnet test     # è¿è¡Œæµ‹è¯•"""
        
        elif self.detected_project_type == 'node':
            # åœ¨ Node é¡¹ç›®ä¸­ä½¿ç”¨ dotnet
            if 'dotnet ' in cmd_lower:
                return f"""â›” é¡¹ç›®ç±»å‹ä¸åŒ¹é…ï¼

ğŸ” å·²æ£€æµ‹åˆ°: è¿™æ˜¯ä¸€ä¸ª Node.js/JavaScript é¡¹ç›®
   æ£€æµ‹æ–‡ä»¶: {', '.join(self.project_files_detected[:3])}

ğŸš¨ é”™è¯¯: æ‚¨åœ¨å°è¯•ä½¿ç”¨ dotnet (.NET CLI)

âœ… Node.js é¡¹ç›®çš„æ­£ç¡®æ–¹æ³•:
   1. npm install  # å®‰è£…ä¾èµ–
   2. npm test     # è¿è¡Œæµ‹è¯•"""
        
        # æ£€æµ‹ï¼šç”¨ pip å®‰è£… .NET åŒ…ï¼ˆé€šè¿‡å‘½ä»¤å…³é”®è¯ï¼‰
        if 'pip install' in cmd_lower:
            # æ£€æŸ¥æ˜¯å¦åŒ…å« .NET é¡¹ç›®å…³é”®è¯
            dotnet_indicators = ['aspnetcore', 'nuget', '.net', 'microsoft.', 'system.']
            for indicator in dotnet_indicators:
                if indicator in cmd_lower:
                    return f"""â›” å·¥å…·ç±»å‹é”™è¯¯ï¼

ğŸš¨ æ£€æµ‹åˆ°æ‚¨åœ¨å°è¯•ç”¨ pip å®‰è£… .NET åŒ…
   å‘½ä»¤: {command[:60]}...
   é—®é¢˜: pip æ˜¯ Python åŒ…ç®¡ç†å™¨ï¼Œä¸èƒ½å®‰è£… .NET NuGet åŒ…ï¼

âœ… æ­£ç¡®æ–¹æ³•:
   1. dotnet restore  # æ¢å¤ NuGet ä¾èµ–
   2. dotnet build    # ç¼–è¯‘é¡¹ç›®
   3. dotnet test     # è¿è¡Œæµ‹è¯•"""
        
        # æ£€æµ‹ï¼šç”¨ python è¿è¡Œ .cs/.csproj æ–‡ä»¶
        if 'python ' in cmd_lower or 'python3 ' in cmd_lower:
            if '.cs' in command or '.csproj' in command:
                return f"""â›” å·¥å…·ç±»å‹é”™è¯¯ï¼

ğŸš¨ æ£€æµ‹åˆ°æ‚¨åœ¨å°è¯•ç”¨ Python è¿è¡Œ C# æ–‡ä»¶
   å‘½ä»¤: {command[:60]}...
   é—®é¢˜: .cs æ˜¯ C# æºæ–‡ä»¶ï¼Œä¸èƒ½ç”¨ Python æ‰§è¡Œï¼

âœ… æ­£ç¡®æ–¹æ³•:
   1. dotnet build xxx.csproj  # ç¼–è¯‘ C# é¡¹ç›®
   2. dotnet test              # è¿è¡Œæµ‹è¯•
   3. dotnet run               # è¿è¡Œå¯æ‰§è¡Œé¡¹ç›®"""
        
        # æ£€æµ‹ï¼šç”¨ npm/node å¤„ç† .NET é¡¹ç›®
        if 'npm ' in cmd_lower or 'node ' in cmd_lower:
            if '.csproj' in command or 'dotnet' in cmd_lower:
                return f"""â›” å·¥å…·ç±»å‹é”™è¯¯ï¼

ğŸš¨ æ£€æµ‹åˆ°æ‚¨åœ¨å°è¯•ç”¨ Node.js å¤„ç† .NET é¡¹ç›®
   å‘½ä»¤: {command[:60]}...
   é—®é¢˜: npm/node æ˜¯ JavaScript å·¥å…·ï¼Œä¸èƒ½å¤„ç† .NET é¡¹ç›®ï¼

âœ… æ­£ç¡®æ–¹æ³•:
   1. dotnet restore && dotnet build
   2. dotnet test"""
        
        # æ£€æµ‹ï¼šç”¨ dotnet å¤„ç† Python é¡¹ç›®
        if 'dotnet ' in cmd_lower:
            if '.py' in command or 'setup.py' in command or 'requirements.txt' in command:
                return f"""â›” å·¥å…·ç±»å‹é”™è¯¯ï¼

ğŸš¨ æ£€æµ‹åˆ°æ‚¨åœ¨å°è¯•ç”¨ dotnet å¤„ç† Python é¡¹ç›®
   å‘½ä»¤: {command[:60]}...
   é—®é¢˜: dotnet æ˜¯ .NET CLIï¼Œä¸èƒ½å¤„ç† Python é¡¹ç›®ï¼

âœ… æ­£ç¡®æ–¹æ³•:
   1. pip install -r requirements.txt  # å®‰è£…ä¾èµ–
   2. python setup.py install          # å®‰è£…åŒ…
   3. pytest                            # è¿è¡Œæµ‹è¯•"""
        
        return None
    
    def detect_project_type_from_files(self, target_project_dir: Optional[str] = None) -> Optional[str]:
        """
        ä»ç›®æ ‡é¡¹ç›®ç›®å½•çš„æ–‡ä»¶æ£€æµ‹é¡¹ç›®ç±»å‹
        
        âš ï¸ é‡è¦ä¿®å¤ (CVE-2024-32873): åªåœ¨ç›®æ ‡é¡¹ç›®ç›®å½•æ£€æµ‹ï¼Œæ’é™¤æ¡†æ¶è‡ªèº«æ–‡ä»¶ï¼
        ä¹‹å‰çš„BUGï¼šæ‰«æåˆ° agentlib/setup.py å¯¼è‡´ Go é¡¹ç›®è¢«è¯¯åˆ¤ä¸º Python é¡¹ç›®
        
        è¿”å›: 'dotnet', 'python', 'node', 'java', 'go' æˆ– None
        
        Args:
            target_project_dir: ç›®æ ‡é¡¹ç›®ç›®å½•ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ simulation_environments
        """
        # ğŸ”´ P0ä¿®å¤: åªåœ¨ç›®æ ‡é¡¹ç›®ç›®å½•ä¸‹æ£€æµ‹ï¼Œä¸æ‰«ææ¡†æ¶è‡ªèº«ç›®å½•
        # ä¹‹å‰çš„é—®é¢˜ï¼š'.' ä¼šæ‰«æåˆ° agentlib/setup.pyï¼Œå¯¼è‡´ Go é¡¹ç›®è¢«è¯¯åˆ¤ä¸º Python
        search_dirs = []
        
        # ä¼˜å…ˆä½¿ç”¨æŒ‡å®šçš„ç›®æ ‡é¡¹ç›®ç›®å½•
        if target_project_dir and os.path.isdir(target_project_dir):
            search_dirs.append(target_project_dir)
        
        # åªæœç´¢ simulation_environments ä¸‹çš„ç›®å½•ï¼ˆç›®æ ‡é¡¹ç›®æ‰€åœ¨ä½ç½®ï¼‰
        sim_env_base = '/workspaces/submission/src/simulation_environments'
        if os.path.isdir(sim_env_base):
            search_dirs.append(sim_env_base)
        
        # âš ï¸ ä¸å†æ‰«æå½“å‰ç›®å½• '.'ï¼Œé¿å…æ‰«æåˆ°æ¡†æ¶è‡ªèº«çš„ agentlib/setup.py
        
        # éœ€è¦æ’é™¤çš„ç›®å½•ï¼ˆæ¡†æ¶è‡ªèº«çš„ç›®å½•ï¼‰
        excluded_dirs = {
            'agentlib',
            'src/agentlib',
            '/workspaces/submission/src/agentlib',
            'toolbox',
            'agents',
            'prompts',
            'orchestrator',
            'planner',
        }
        
        # æ–‡ä»¶ç±»å‹ -> é¡¹ç›®ç±»å‹æ˜ å°„
        file_type_map = {
            '.csproj': 'dotnet',
            '.sln': 'dotnet',
            '.cs': 'dotnet',
            'package.json': 'node',
            'requirements.txt': 'python',
            'setup.py': 'python',
            'pyproject.toml': 'python',
            'pom.xml': 'java',
            'build.gradle': 'java',
            'go.mod': 'go',
        }
        
        detected_files = []
        detected_type = None
        type_votes = {}  # å¤šæ•°æŠ•ç¥¨ï¼Œè§£å†³æ­§ä¹‰
        
        for base_dir in search_dirs:
            if not os.path.isdir(base_dir):
                continue
            
            # ğŸ”´ æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
            normalized_base = os.path.normpath(base_dir)
            if any(excl in normalized_base for excl in excluded_dirs):
                continue
                
            try:
                # æ£€æŸ¥æ ¹ç›®å½•
                for entry in os.listdir(base_dir):
                    entry_path = os.path.join(base_dir, entry)
                    
                    # ğŸ”´ è·³è¿‡æ¡†æ¶è‡ªèº«çš„ç›®å½•
                    if entry in excluded_dirs:
                        continue
                    
                    # ç›´æ¥æ–‡ä»¶æ£€æŸ¥
                    for pattern, proj_type in file_type_map.items():
                        if entry.endswith(pattern) or entry == pattern:
                            detected_files.append(entry)
                            type_votes[proj_type] = type_votes.get(proj_type, 0) + 1
                            if detected_type is None:
                                detected_type = proj_type
                    
                    # å­ç›®å½•æ£€æŸ¥ï¼ˆåªæ£€æŸ¥ä¸€å±‚ï¼‰
                    if os.path.isdir(entry_path):
                        # ğŸ”´ è·³è¿‡æ¡†æ¶è‡ªèº«çš„å­ç›®å½•
                        if entry in excluded_dirs:
                            continue
                        try:
                            for sub_entry in os.listdir(entry_path):
                                for pattern, proj_type in file_type_map.items():
                                    if sub_entry.endswith(pattern) or sub_entry == pattern:
                                        detected_files.append(os.path.join(entry, sub_entry))
                                        type_votes[proj_type] = type_votes.get(proj_type, 0) + 1
                                        if detected_type is None:
                                            detected_type = proj_type
                        except:
                            pass
            except:
                pass
        
        # ğŸ”´ ä½¿ç”¨å¤šæ•°æŠ•ç¥¨æ¥ç¡®å®šæœ€ç»ˆç±»å‹ï¼ˆè§£å†³æ­§ä¹‰ï¼‰
        if type_votes:
            # go.mod ä¼˜å…ˆäº setup.pyï¼ˆGoé¡¹ç›®ä¼˜å…ˆçº§æ›´é«˜ï¼Œå› ä¸ºå¾ˆå¤šé¡¹ç›®å¯èƒ½æœ‰setup.pyä½†å®é™…æ˜¯å…¶ä»–è¯­è¨€ï¼‰
            priority_order = ['go', 'dotnet', 'java', 'node', 'python']
            for priority_type in priority_order:
                if priority_type in type_votes:
                    detected_type = priority_type
                    break
        
        if detected_type:
            self.detected_project_type = detected_type
            self.project_files_detected = detected_files[:5]  # åªä¿ç•™å‰5ä¸ª
            print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°é¡¹ç›®ç±»å‹: {detected_type} (æ–‡ä»¶: {', '.join(detected_files[:3])}...)")
        
        return detected_type
    
    def analyze_curl_wget_output(self, command: str, output: str, exit_code: int) -> Optional[ContextualInsight]:
        """
        åˆ†æ curl/wget ä¸‹è½½å‘½ä»¤çš„è¾“å‡º
        
        å…³é”®æ£€æµ‹ï¼š
        - ä¸‹è½½å¤§å°è¿‡å°ï¼ˆ< 100 bytes é€šå¸¸æ˜¯é”™è¯¯é¡µé¢ï¼‰
        - 404 Not Found
        - Connection refused
        - å³ä½¿ exit_code=0 ä¹Ÿæ£€æµ‹æ–‡ä»¶å¤§å°ï¼ï¼ˆGitHubè¿”å›çš„"Not Found"é¡µé¢ä¼šå¯¼è‡´curlæˆåŠŸä½†å†…å®¹æ— æ•ˆï¼‰
        """
        # æå–ä¸‹è½½çš„æ–‡ä»¶åå’ŒURL
        filename = None
        url = None
        
        # curl -o filename URL æˆ– curl -L -o filename URL
        match = re.search(r'curl\s+.*?-o\s+(\S+)\s+(https?://\S+)', command)
        if match:
            filename = match.group(1)
            url = match.group(2)
        else:
            # wget URL æˆ– wget -O filename URL
            match = re.search(r'wget\s+.*?(?:-O\s+(\S+)\s+)?(https?://\S+)', command)
            if match:
                url = match.group(2)
                filename = match.group(1) or (url.split('/')[-1] if url else None)
        
        if not url:
            return None
        
        # ğŸ”´ å…³é”®ä¿®å¤ï¼šå³ä½¿ exit_code=0 ä¹Ÿæ£€æµ‹ä¸‹è½½æ–‡ä»¶å¤§å°
        # curl çš„ progress æ ¼å¼ï¼š100     9  100     9 è¡¨ç¤ºä¸‹è½½äº†9å­—èŠ‚
        # è¿™ç§æ ¼å¼æ„å‘³ç€ 100% å®Œæˆï¼Œä½†åªæœ‰ 9 å­—èŠ‚
        size_patterns = [
            r'100\s+(\d+)\s+100\s+\d+',  # curl æ ‡å‡†æ ¼å¼
            r'(\d+)\s+\d+%\s+\d+',       # wget æ ¼å¼
        ]
        
        for pattern in size_patterns:
            size_match = re.search(pattern, output)
            if size_match:
                size = int(size_match.group(1))
                # ğŸ”´ æ ¸å¿ƒæ£€æµ‹ï¼šä»»ä½• < 1000 å­—èŠ‚çš„ä¸‹è½½éƒ½å¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                # GitHub çš„ "Not Found" é¡µé¢é€šå¸¸åªæœ‰ 9 å­—èŠ‚
                if size < 1000:  # æ‰©å¤§é˜ˆå€¼ï¼Œä»»ä½•å°äº1KBçš„zipä¸‹è½½å‡ ä¹è‚¯å®šå¤±è´¥
                    self.known_bad_urls.add(url)
                    
                    # æå–å¯èƒ½çš„ä»“åº“ä¿¡æ¯ç”¨äº git clone å»ºè®®
                    repo_match = re.search(r'github\.com/([^/]+/[^/]+)', url)
                    git_suggestion = ""
                    if repo_match:
                        repo_path = repo_match.group(1)
                        git_suggestion = f"\n   æ¨èå‘½ä»¤: git clone https://github.com/{repo_path}.git"
                    
                    insight = ContextualInsight(
                        issue_type='download_failed',
                        evidence=f"âš ï¸ ä¸‹è½½æ–‡ä»¶ '{filename}' åªæœ‰ {size} å­—èŠ‚ï¼è¿™ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶ï¼ˆGitHub è¿”å›äº†é”™è¯¯é¡µé¢è€Œéå®é™…å†…å®¹ï¼‰",
                        blocking=True,
                        suggestion=f"ğŸ›‘ åœæ­¢ä¸‹è½½å°è¯•ï¼URL è¿”å›äº†é”™è¯¯é¡µé¢è€Œéæ–‡ä»¶ã€‚{git_suggestion}\n   æˆ–ä½¿ç”¨: git clone --depth 1 <repo_url>  ç„¶å git checkout <version>",
                        related_files=[filename] if filename else []
                    )
                    self.blocking_insights.append(insight)
                    if filename:
                        self.download_history[filename] = {
                            'size': size, 
                            'status': 'failed', 
                            'url': url,
                            'reason': f'ä¸‹è½½åªæœ‰{size}å­—èŠ‚ï¼Œæ˜¯é”™è¯¯é¡µé¢è€Œéå®é™…æ–‡ä»¶'
                        }
                    return insight
                break
        
        # æ£€æµ‹404é”™è¯¯
        if '404' in output or 'Not Found' in output:
            self.known_bad_urls.add(url)
            # å°è¯•æå–ç‰ˆæœ¬å·
            version_match = re.search(r'v?(\d+\.\d+\.\d+)', url)
            if version_match:
                self.known_bad_versions.add(version_match.group(1))
            
            # æå–ä»“åº“ä¿¡æ¯
            repo_match = re.search(r'github\.com/([^/]+/[^/]+)', url)
            git_suggestion = ""
            if repo_match:
                git_suggestion = f" ä½¿ç”¨ git clone https://github.com/{repo_match.group(1)}.git æ›¿ä»£"
            
            insight = ContextualInsight(
                issue_type='url_not_found',
                evidence=f"URLè¿”å›404é”™è¯¯: {url}",
                blocking=True,
                suggestion=f"è¯¥URLä¸å­˜åœ¨ã€‚{git_suggestion}\næˆ–å…ˆ git clone ä»“åº“ï¼Œå† git tag -l æŸ¥çœ‹å¯ç”¨ç‰ˆæœ¬",
                related_files=[filename] if filename else []
            )
            self.blocking_insights.append(insight)
            return insight
        
        # ä¸‹è½½æˆåŠŸï¼Œè®°å½•ï¼ˆä½†åªæœ‰æ–‡ä»¶å¤§å°è¶³å¤Ÿå¤§æ—¶æ‰è®¤ä¸ºæˆåŠŸï¼‰
        if exit_code == 0 and filename:
            self.download_history[filename] = {'status': 'success', 'url': url}
        
        return None
    
    def analyze_file_command_output(self, command: str, output: str) -> Optional[ContextualInsight]:
        """
        åˆ†æ file å‘½ä»¤çš„è¾“å‡ºï¼Œæ£€æµ‹æ–‡ä»¶ç±»å‹æ˜¯å¦æ­£ç¡®
        å¹¶è‡ªåŠ¨å°†æ— æ•ˆæ–‡ä»¶è®°å½•åˆ°é»‘åå•ï¼Œé˜»æ­¢åç»­ unzip
        """
        # file xxx.zip: ASCII text
        match = re.search(r'(\S+\.zip):\s*(.*)', output)
        if match:
            filename = match.group(1)
            file_type = match.group(2).lower()
            
            # å¦‚æœzipæ–‡ä»¶ä¸æ˜¯å®é™…çš„zipæ ¼å¼
            if 'zip' not in file_type and 'archive' not in file_type:
                # ğŸ”´ å…³é”®ï¼šç«‹å³è®°å½•åˆ°ä¸‹è½½å†å²ï¼Œé˜»æ­¢åç»­ unzip
                self.download_history[filename] = {
                    'status': 'not_zip', 
                    'type': file_type,
                    'reason': f'fileå‘½ä»¤æ£€æµ‹åˆ°å®é™…ç±»å‹æ˜¯: {file_type}'
                }
                
                insight = ContextualInsight(
                    issue_type='file_corrupted',
                    evidence=f"ğŸš¨ æ–‡ä»¶ '{filename}' ä¸æ˜¯æœ‰æ•ˆçš„ZIPæ–‡ä»¶ï¼\n   fileå‘½ä»¤æ£€æµ‹åˆ°å®é™…ç±»å‹æ˜¯: {file_type}",
                    blocking=True,
                    suggestion=f"ğŸ›‘ ç«‹å³åœæ­¢ï¼ä¸è¦ç»§ç»­å°è¯• unzip '{filename}'ï¼\n   è¿™ä¸ªæ–‡ä»¶ä¸‹è½½å¤±è´¥æˆ–æŸåã€‚\n   å»ºè®®ï¼šä½¿ç”¨ git clone å…‹éš†ä»“åº“è€Œä¸æ˜¯ä¸‹è½½ zip",
                    related_files=[filename]
                )
                self.blocking_insights.append(insight)
                return insight
        
        return None
    
    def analyze_ls_output(self, command: str, output: str) -> Optional[ContextualInsight]:
        """
        åˆ†æ ls -la è¾“å‡ºï¼Œæ£€æµ‹å¼‚å¸¸å°çš„æ–‡ä»¶
        
        ä¾‹å¦‚ï¼š-rw-r--r-- 1 root root 9 Dec 12 08:36 lunary.zip
        9å­—èŠ‚çš„zipæ–‡ä»¶æ˜æ˜¾æ˜¯æ— æ•ˆçš„
        """
        # æ£€æµ‹ zip/tar.gz ç­‰å‹ç¼©æ–‡ä»¶çš„å¤§å°
        # æ ¼å¼: -rw-r--r-- 1 root root   9 Dec 12 08:36 lunary.zip
        file_pattern = r'-[rwx-]+\s+\d+\s+\w+\s+\w+\s+(\d+)\s+\w+\s+\d+\s+[\d:]+\s+(\S+\.(?:zip|tar\.gz|tgz|tar|gz))'
        
        tiny_files = []
        for match in re.finditer(file_pattern, output, re.IGNORECASE):
            size = int(match.group(1))
            filename = match.group(2)
            
            # å°äº 1000 å­—èŠ‚çš„å‹ç¼©æ–‡ä»¶å‡ ä¹è‚¯å®šæ˜¯æ— æ•ˆçš„
            if size < 1000:
                tiny_files.append((filename, size))
                # è®°å½•åˆ°ä¸‹è½½å†å²ï¼Œé˜»æ­¢åç»­ unzip
                self.download_history[filename] = {
                    'status': 'failed', 
                    'size': size,
                    'reason': f'lsæ£€æµ‹åˆ°æ–‡ä»¶åªæœ‰{size}å­—èŠ‚'
                }
        
        if tiny_files:
            file_list = ', '.join([f"'{f}'({s}å­—èŠ‚)" for f, s in tiny_files])
            insight = ContextualInsight(
                issue_type='tiny_archive_detected',
                evidence=f"âš ï¸ å‘ç°å¼‚å¸¸å°çš„å‹ç¼©æ–‡ä»¶: {file_list}\n   æ­£å¸¸çš„æºç å‹ç¼©åŒ…åº”è¯¥è‡³å°‘æœ‰å‡ KB",
                blocking=True,
                suggestion=f"è¿™äº›æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼ˆå¯èƒ½æ˜¯GitHubè¿”å›çš„é”™è¯¯é¡µé¢ï¼‰ã€‚\n   ğŸ›‘ ä¸è¦å°è¯• unzip è¿™äº›æ–‡ä»¶ï¼\n   å»ºè®®ï¼šrm {' '.join([f[0] for f in tiny_files])} && git clone <repo_url>",
                related_files=[f[0] for f in tiny_files]
            )
            self.blocking_insights.append(insight)
            return insight
        
        return None
    
    def analyze_unzip_output(self, command: str, output: str, exit_code: int) -> Optional[ContextualInsight]:
        """
        åˆ†æ unzip å‘½ä»¤çš„è¾“å‡º
        """
        # æå–æ–‡ä»¶å
        match = re.search(r'unzip\s+(?:-\w+\s+)*(\S+)', command)
        if not match:
            return None
        
        filename = match.group(1)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„æŸåæ–‡ä»¶
        if filename in self.download_history:
            history = self.download_history[filename]
            if history.get('status') in ['failed', 'corrupted']:
                insight = ContextualInsight(
                    issue_type='unzip_known_bad_file',
                    evidence=f"å°è¯•è§£å‹å·²çŸ¥æ— æ•ˆçš„æ–‡ä»¶ '{filename}'ï¼ˆä¹‹å‰çš„ä¸‹è½½å·²å¤±è´¥ï¼‰",
                    blocking=True,
                    suggestion=f"âš ï¸ åœæ­¢ï¼è¿™ä¸ªæ–‡ä»¶ '{filename}' å·²è¢«æ£€æµ‹ä¸ºæ— æ•ˆã€‚è¯·ï¼š1) åˆ é™¤å®ƒ (rm {filename}) 2) ä½¿ç”¨ git clone æ›¿ä»£ä¸‹è½½zip 3) æ£€æŸ¥æ­£ç¡®çš„ç‰ˆæœ¬å·å’ŒURL",
                    related_files=[filename]
                )
                return insight
        
        # æ£€æŸ¥ unzip é”™è¯¯ç±»å‹
        if 'End-of-central-directory signature not found' in output:
            insight = ContextualInsight(
                issue_type='file_not_zip',
                evidence=f"'{filename}' ä¸æ˜¯æœ‰æ•ˆçš„ZIPæ–‡ä»¶ï¼ˆç¼ºå°‘ZIPæ–‡ä»¶å¤´ï¼‰",
                blocking=True,
                suggestion=f"âš ï¸ è¿™ä¸ªæ–‡ä»¶ä¸æ˜¯ZIPæ ¼å¼ï¼å¯èƒ½åŸå› ï¼š1) ä¸‹è½½URLè¿”å›äº†é”™è¯¯é¡µé¢è€Œéæ–‡ä»¶ 2) ä¸‹è½½è¢«é‡å®šå‘ 3) ç‰ˆæœ¬å·ä¸å­˜åœ¨ã€‚è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ git clone ç›´æ¥å…‹éš†ä»“åº“",
                related_files=[filename]
            )
            self.blocking_insights.append(insight)
            self.download_history[filename] = {'status': 'not_zip'}
            return insight
        
        return None
    
    def analyze_dotnet_output(self, command: str, output: str, exit_code: int) -> Optional[ContextualInsight]:
        """
        åˆ†æ dotnet å‘½ä»¤è¾“å‡ºï¼Œæ£€æµ‹ç±»åº“é¡¹ç›®ç­‰é—®é¢˜
        
        é€šç”¨æ£€æµ‹ï¼š
        - OutputType='Library' è¡¨ç¤ºé¡¹ç›®æ˜¯ç±»åº“ï¼Œä¸èƒ½ç”¨ dotnet run å¯åŠ¨
        - è¿™ç±»é¡¹ç›®éœ€è¦åˆ›å»ºæµ‹è¯•ç¨‹åºæˆ–ä½¿ç”¨ dotnet test
        
        ç»éªŒåº“é›†æˆï¼š
        - è‡ªåŠ¨è¯†åˆ«é¡¹ç›®ç±»å‹å¹¶åŠ è½½å¯¹åº”ç»éªŒ
        - ä½¿ç”¨å†å²ç»éªŒå¢å¼ºå»ºè®®
        """
        combined = output + (command if command else '')
        
        # æ£€æµ‹ .NET Library é¡¹ç›®ï¼ˆæ— æ³•ç”¨ dotnet run è¿è¡Œï¼‰
        if "OutputType is 'Library'" in output or "The current OutputType is 'Library'" in output:
            # ä»å‘½ä»¤ä¸­æå–é¡¹ç›®è·¯å¾„
            proj_match = re.search(r'--project\s+(\S+\.csproj)', command)
            project_name = proj_match.group(1) if proj_match else "unknown"
            
            # ğŸ”„ ä½¿ç”¨ç»éªŒåº“è¯†åˆ«é¡¹ç›®ç±»å‹å¹¶è·å–å»ºè®®
            advice = ""
            if self.experience_library:
                self.experience_library.identify_project_type(output, command)
                advice = self.experience_library.get_current_advice() or ""
                # è®°å½•ç»éªŒåˆ°ç»éªŒåº“
                self.experience_library.record_experience("dotnet", "library", {
                    "command": "dotnet run",
                    "success": False,
                    "error": "OutputType is 'Library'",
                    "lesson": "ç±»åº“é¡¹ç›®ä¸èƒ½ç”¨ dotnet run å¯åŠ¨ï¼Œåº”ä½¿ç”¨ dotnet test"
                })
            
            # ä¼˜å…ˆä½¿ç”¨ç»éªŒåº“å»ºè®®ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å»ºè®®
            default_suggestion = """ğŸ›‘ è¿™æ˜¯ä¸€ä¸ªç±»åº“/NuGetåŒ…é¡¹ç›®ï¼Œä¸æ˜¯ Web åº”ç”¨ï¼

   å¯¹äºæ­¤ç±»æ¼æ´ï¼Œéœ€è¦é‡‡ç”¨ä¸åŒçš„å¤ç°ç­–ç•¥ï¼š
   1. ã€æ¨èã€‘ä½¿ç”¨ dotnet test è¿è¡Œç°æœ‰å•å…ƒæµ‹è¯•
   2. åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ§åˆ¶å°ç¨‹åºå¼•ç”¨è¯¥åº“å¹¶è§¦å‘æ¼æ´
   3. å¦‚æœæ¼æ´æ˜¯é€»è¾‘é—®é¢˜ï¼ˆå¦‚å‚æ•°éªŒè¯ç¼ºé™·ï¼‰ï¼Œéœ€è¦ç¼–å†™ä»£ç æµ‹è¯•
   
   âŒ ä¸è¦ç»§ç»­å°è¯• 'dotnet run' å‘½ä»¤
   âœ… è¿è¡Œ: dotnet test æˆ–åˆ›å»ºæµ‹è¯•ç¨‹åº"""
            
            insight = ContextualInsight(
                issue_type='library_project_detected',
                evidence=f"ğŸš¨ æ£€æµ‹åˆ° .NET ç±»åº“é¡¹ç›®ï¼\n   é¡¹ç›® '{project_name}' çš„ OutputType='Library'ï¼Œä¸æ˜¯å¯æ‰§è¡Œç¨‹åºã€‚\n   ç±»åº“é¡¹ç›®ä¸èƒ½ç”¨ 'dotnet run' å¯åŠ¨ã€‚",
                blocking=True,
                suggestion=advice if advice else default_suggestion,
                related_files=[project_name]
            )
            self.blocking_insights.append(insight)
            return insight
        
        # æ£€æµ‹ dotnet run å¤±è´¥ä½†æ²¡æœ‰ runnable é¡¹ç›®
        if 'Ensure you have a runnable project type' in output:
            insight = ContextualInsight(
                issue_type='not_runnable_project',
                evidence="é¡¹ç›®ä¸æ˜¯å¯æ‰§è¡Œç±»å‹ï¼ˆç¼ºå°‘ Main å…¥å£ç‚¹æˆ– OutputType ä¸æ˜¯ 'Exe'ï¼‰",
                blocking=True,
                suggestion="""è¿™ä¸ªé¡¹ç›®ä¸èƒ½ç›´æ¥è¿è¡Œã€‚å¯èƒ½çš„åŸå› ï¼š
   1. è¿™æ˜¯ä¸€ä¸ªç±»åº“é¡¹ç›®ï¼ˆéœ€è¦åˆ›å»ºæµ‹è¯•ç¨‹åºï¼‰
   2. ç¼ºå°‘ Main æ–¹æ³•å…¥å£ç‚¹
   3. è¿™æ˜¯ä¸€ä¸ª NuGet åŒ…è€Œé Web åº”ç”¨
   
   è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ dotnet test æˆ–åˆ›å»ºå¼•ç”¨è¯¥åº“çš„æµ‹è¯•ç¨‹åº""",
                related_files=[]
            )
            self.blocking_insights.append(insight)
            return insight
        
        return None
    
    def analyze_npm_yarn_output(self, command: str, output: str, exit_code: int) -> Optional[ContextualInsight]:
        """
        åˆ†æ npm/yarn å‘½ä»¤è¾“å‡ºï¼Œæ£€æµ‹åº“é¡¹ç›®é—®é¢˜
        ç»éªŒåº“é›†æˆï¼šè‡ªåŠ¨è¯†åˆ«é¡¹ç›®ç±»å‹å¹¶è®°å½•ç»éªŒ
        """
        combined = output + (command if command else '')
        
        # æ£€æµ‹ npm åº“é¡¹ç›®ï¼ˆæ²¡æœ‰ start è„šæœ¬ï¼‰
        if 'Missing script: "start"' in output or 'missing script: start' in output.lower():
            # ğŸ”„ è®°å½•ç»éªŒåˆ°ç»éªŒåº“
            if self.experience_library:
                self.experience_library.identify_project_type(output, command)
                self.experience_library.record_experience("node", "library", {
                    "command": "npm start",
                    "success": False,
                    "error": 'Missing script: "start"',
                    "lesson": "npm åº“é¡¹ç›®æ²¡æœ‰ start è„šæœ¬ï¼Œåº”ä½¿ç”¨ npm test"
                })
            
            advice = self.experience_library.get_current_advice() if self.experience_library else None
            default_suggestion = """è¿™æ˜¯ä¸€ä¸ª npm åº“/åŒ…ï¼Œä¸æ˜¯å¯è¿è¡Œçš„ Web åº”ç”¨ï¼
   
   å¯¹äºæ­¤ç±»æ¼æ´ï¼š
   1. ä½¿ç”¨ npm test è¿è¡Œç°æœ‰æµ‹è¯•
   2. åˆ›å»ºæµ‹è¯• HTML é¡µé¢å¼•å…¥è¯¥åº“å¹¶è§¦å‘æ¼æ´
   3. æŸ¥çœ‹ package.json ä¸­çš„ scripts éƒ¨åˆ†æ‰¾å¯ç”¨å‘½ä»¤
   
   âŒ ä¸è¦ç»§ç»­å°è¯• npm start"""
            
            insight = ContextualInsight(
                issue_type='npm_library_project',
                evidence="æ£€æµ‹åˆ° npm åº“é¡¹ç›®ï¼šæ²¡æœ‰ 'start' è„šæœ¬",
                blocking=True,
                suggestion=advice if advice else default_suggestion,
                related_files=['package.json']
            )
            self.blocking_insights.append(insight)
            return insight
        
        return None
    
    def analyze_python_output(self, command: str, output: str, exit_code: int) -> Optional[ContextualInsight]:
        """
        åˆ†æ Python å‘½ä»¤è¾“å‡ºï¼Œæ£€æµ‹åº“é¡¹ç›®é—®é¢˜
        """
        # æ£€æµ‹çº¯ Python åº“ï¼ˆæ²¡æœ‰ web å…¥å£ç‚¹ï¼‰
        if 'No module named' in output and any(x in command.lower() for x in ['flask', 'django', 'uvicorn', 'gunicorn']):
            lib_match = re.search(r"No module named '([^']+)'", output)
            lib_name = lib_match.group(1) if lib_match else 'unknown'
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯ web æ¡†æ¶é—®é¢˜
            if lib_name in ['flask', 'django', 'uvicorn', 'gunicorn', 'starlette', 'fastapi']:
                insight = ContextualInsight(
                    issue_type='python_library_project',
                    evidence=f"ç¼ºå°‘ Web æ¡†æ¶ '{lib_name}'ï¼Œå¯èƒ½è¿™æ˜¯ä¸€ä¸ªçº¯ Python åº“è€Œé Web åº”ç”¨",
                    blocking=False,  # åªæ˜¯è­¦å‘Šï¼Œä¸é˜»æ­¢
                    suggestion=f"""æ£€æµ‹åˆ°å¯èƒ½çš„ Python åº“é¡¹ç›®ã€‚å¦‚æœè¿™æ˜¯ä¸€ä¸ªåº“ï¼š
   1. ä½¿ç”¨ pytest/python -m pytest è¿è¡Œæµ‹è¯•
   2. åˆ›å»ºæµ‹è¯•è„šæœ¬ import è¯¥åº“å¹¶è§¦å‘æ¼æ´
   3. å¦‚æœç¡®å®æ˜¯ Web åº”ç”¨ï¼Œè¿è¡Œ: pip install {lib_name}""",
                    related_files=[]
                )
                self.blocking_insights.append(insight)
                return insight
        
        return None
    
    def analyze_command(self, command: str, output: str, exit_code: int) -> Optional[ContextualInsight]:
        """
        åˆ†æä»»æ„å‘½ä»¤ï¼Œè¿”å›ä¸Šä¸‹æ–‡æ´å¯Ÿ
        """
        cmd_lower = command.lower().strip()
        
        # curl æˆ– wget ä¸‹è½½å‘½ä»¤
        if 'curl' in cmd_lower or 'wget' in cmd_lower:
            return self.analyze_curl_wget_output(command, output, exit_code)
        
        # file å‘½ä»¤
        if cmd_lower.startswith('file '):
            return self.analyze_file_command_output(command, output)
        
        # ls å‘½ä»¤ - æ£€æµ‹å¼‚å¸¸å°çš„å‹ç¼©æ–‡ä»¶
        if cmd_lower.startswith('ls '):
            return self.analyze_ls_output(command, output)
        
        # unzip å‘½ä»¤
        if 'unzip' in cmd_lower:
            return self.analyze_unzip_output(command, output, exit_code)
        
        # dotnet å‘½ä»¤ - æ£€æµ‹ç±»åº“é¡¹ç›®
        if 'dotnet' in cmd_lower:
            return self.analyze_dotnet_output(command, output, exit_code)
        
        # npm/yarn å‘½ä»¤ - æ£€æµ‹ npm åº“é¡¹ç›®
        if 'npm' in cmd_lower or 'yarn' in cmd_lower:
            return self.analyze_npm_yarn_output(command, output, exit_code)
        
        # python/pip å‘½ä»¤ - æ£€æµ‹ Python åº“é¡¹ç›®
        if 'python' in cmd_lower or 'pip' in cmd_lower:
            return self.analyze_python_output(command, output, exit_code)
        
        return None
    
    def should_block_command(self, command: str) -> Optional[str]:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥é˜»æ­¢æ‰§è¡ŒæŸä¸ªå‘½ä»¤
        
        æ£€æŸ¥é¡ºåºï¼š
        0. ğŸ†• è‡ªåŠ¨æ£€æµ‹é¡¹ç›®ç±»å‹ï¼ˆä»æ–‡ä»¶ç³»ç»Ÿï¼‰
        1. å·¥å…·/è¯­è¨€åŒ¹é…ï¼šæ£€æŸ¥æ˜¯å¦ç”¨é”™è¯¯å·¥å…·å¤„ç†é¡¹ç›®
        2. é‡å¤å¤±è´¥ï¼šåŒä¸€å‘½ä»¤å¤±è´¥è¶…è¿‡Næ¬¡è‡ªåŠ¨é˜»æ­¢
        3. ä¸»åŠ¨æ£€æµ‹ï¼šå¯¹äº dotnet runï¼Œæ£€æŸ¥ .csproj æ–‡ä»¶ç¡®å®šé¡¹ç›®ç±»å‹
        4. ç»éªŒåº“ï¼šæ ¹æ®å†å²ç»éªŒé¢„å…ˆé˜»æ­¢å·²çŸ¥ä¼šå¤±è´¥çš„å‘½ä»¤
        5. å½“å‰ä¼šè¯è®°å¿†ï¼šæ ¹æ®æœ¬æ¬¡ä»»åŠ¡ä¸­çš„å¤±è´¥è®°å½•é˜»æ­¢
        
        è¿”å›é˜»æ­¢åŸå› ï¼Œæˆ– None è¡¨ç¤ºå…è®¸æ‰§è¡Œ
        """
        cmd_lower = command.lower()
        
        # ğŸ†• æ­¥éª¤ 0ï¼šå¦‚æœè¿˜æ²¡æ£€æµ‹é¡¹ç›®ç±»å‹ï¼Œä¸»åŠ¨æ£€æµ‹ï¼ˆåªæ£€æµ‹ä¸€æ¬¡ï¼‰
        if self.detected_project_type is None:
            self.detect_project_type_from_files()
        
        # ğŸ†• å·¥å…·/è¯­è¨€åŒ¹é…æ£€æµ‹ï¼ˆé˜²æ­¢ç”¨ pip å®‰è£… .NET åŒ…ç­‰ï¼‰
        mismatch_block = self.detect_tool_language_mismatch(command)
        if mismatch_block:
            return mismatch_block
        
        # ğŸ†• é‡å¤å¤±è´¥æ£€æµ‹ï¼ˆåŒä¸€å‘½ä»¤å¤±è´¥è¶…è¿‡Næ¬¡è‡ªåŠ¨é˜»æ­¢ï¼‰
        repetition_block = self.is_command_blocked_by_repetition(command)
        if repetition_block:
            return repetition_block
        
        # ğŸš¨ ä¸»åŠ¨æ£€æµ‹ï¼šåœ¨æ‰§è¡Œ dotnet run å‰æ£€æŸ¥é¡¹ç›®æ–‡ä»¶
        if 'dotnet run' in cmd_lower:
            proactive_block = self._proactive_check_dotnet_project(command)
            if proactive_block:
                return proactive_block
        
        # ğŸš¨ ä¸»åŠ¨æ£€æµ‹ï¼šåœ¨æ‰§è¡Œ npm start å‰æ£€æŸ¥ package.json
        if 'npm start' in cmd_lower or 'npm run start' in cmd_lower:
            proactive_block = self._proactive_check_npm_project()
            if proactive_block:
                return proactive_block
        
        # ğŸ”„ æ£€æŸ¥ç»éªŒåº“ï¼ˆè·¨ä»»åŠ¡çš„å†å²ç»éªŒï¼‰
        if self.experience_library:
            block_reason = self.experience_library.should_block_based_on_experience(command)
            if block_reason:
                return block_reason
        
        # æ£€æŸ¥æ˜¯å¦å°è¯•è§£å‹å·²çŸ¥æŸåçš„æ–‡ä»¶
        if 'unzip' in cmd_lower:
            match = re.search(r'unzip\s+(?:-\w+\s+)*(\S+)', command)
            if match:
                filename = match.group(1)
                if filename in self.download_history:
                    status = self.download_history[filename].get('status')
                    if status in ['failed', 'corrupted', 'not_zip']:
                        return f"â›” é˜»æ­¢æ‰§è¡Œï¼šæ–‡ä»¶ '{filename}' å·²è¢«æ£€æµ‹ä¸ºæ— æ•ˆï¼ˆ{status}ï¼‰ã€‚è¯·ä½¿ç”¨ git clone æ›¿ä»£ä¸‹è½½zipæ–¹å¼ã€‚"
        
        # æ£€æŸ¥æ˜¯å¦å°è¯•ä¸‹è½½å·²çŸ¥å¤±è´¥çš„URL
        for bad_url in self.known_bad_urls:
            if bad_url in command:
                return f"â›” é˜»æ­¢æ‰§è¡Œï¼šURL '{bad_url[:50]}...' ä¹‹å‰ä¸‹è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥æ­£ç¡®çš„ç‰ˆæœ¬æˆ–ä½¿ç”¨å…¶ä»–æ–¹å¼è·å–ä»£ç ã€‚"
        
        # æ£€æŸ¥æ˜¯å¦å·²æ£€æµ‹åˆ°ç±»åº“é¡¹ç›®ï¼Œé˜»æ­¢ç»§ç»­å°è¯• dotnet run / npm start
        for insight in self.blocking_insights:
            if insight.issue_type == 'library_project_detected' and 'dotnet run' in cmd_lower:
                return f"â›” é˜»æ­¢æ‰§è¡Œï¼šå·²æ£€æµ‹åˆ°è¿™æ˜¯ .NET ç±»åº“é¡¹ç›®ï¼ˆOutputType='Library'ï¼‰\n   è¯·æ”¹ç”¨ 'dotnet test' æˆ–åˆ›å»ºæµ‹è¯•ç¨‹åºè€Œä¸æ˜¯ç»§ç»­å°è¯• 'dotnet run'"
            
            if insight.issue_type == 'not_runnable_project' and 'dotnet run' in cmd_lower:
                return f"â›” é˜»æ­¢æ‰§è¡Œï¼šé¡¹ç›®ä¸æ˜¯å¯æ‰§è¡Œç±»å‹\n   è¯·æ”¹ç”¨ 'dotnet test' æˆ–åˆ›å»ºæµ‹è¯•ç¨‹åº"
            
            if insight.issue_type == 'npm_library_project' and ('npm start' in cmd_lower or 'npm run start' in cmd_lower):
                return f"â›” é˜»æ­¢æ‰§è¡Œï¼šå·²æ£€æµ‹åˆ°è¿™æ˜¯ npm åº“é¡¹ç›®ï¼ˆæ²¡æœ‰ start è„šæœ¬ï¼‰\n   è¯·æ”¹ç”¨ 'npm test' æˆ–åˆ›å»ºæµ‹è¯•é¡µé¢"
        
        return None
    
    def get_accumulated_insights(self) -> str:
        """
        è·å–ç´¯ç§¯çš„ä¸Šä¸‹æ–‡æ´å¯Ÿæ‘˜è¦
        """
        if not self.blocking_insights:
            return ""
        
        summary = "\nğŸ“Š ç´¯ç§¯çš„é—®é¢˜åˆ†æï¼š\n"
        for i, insight in enumerate(self.blocking_insights[-3:], 1):  # æœ€è¿‘3ä¸ª
            summary += f"  {i}. [{insight.issue_type}] {insight.evidence[:80]}...\n"
        
        return summary
    
    def reset(self):
        """é‡ç½®åˆ†æå™¨çŠ¶æ€"""
        self.download_history.clear()
        self.known_bad_urls.clear()
        self.known_bad_versions.clear()
        self.blocking_insights.clear()
        
        # ğŸ†• é‡ç½®é‡å¤å¤±è´¥æ£€æµ‹å™¨
        self.command_failure_counts.clear()
        self.blocked_command_patterns.clear()
        
        # ğŸ†• é‡ç½®é¡¹ç›®ç±»å‹æ£€æµ‹
        self.detected_project_type = None
        self.project_files_detected.clear()
        
        # ğŸ”„ é‡ç½®ç»éªŒåº“ä¼šè¯ï¼ˆä¿ç•™æŒä¹…åŒ–ç»éªŒï¼‰
        if self.experience_library:
            self.experience_library.reset_current_session()


# å…¨å±€ä¸Šä¸‹æ–‡åˆ†æå™¨
_context_analyzer: Optional[ContextAwareAnalyzer] = None


def get_context_analyzer() -> ContextAwareAnalyzer:
    """è·å–æˆ–åˆ›å»ºå…¨å±€ä¸Šä¸‹æ–‡åˆ†æå™¨"""
    global _context_analyzer
    if _context_analyzer is None:
        _context_analyzer = ContextAwareAnalyzer()
    return _context_analyzer


def reset_context_analyzer():
    """é‡ç½®ä¸Šä¸‹æ–‡åˆ†æå™¨"""
    global _context_analyzer
    if _context_analyzer:
        _context_analyzer.reset()


# ==================== é‡å¤å‘½ä»¤æ£€æµ‹å™¨ ====================
@dataclass
class CommandPattern:
    """å‘½ä»¤æ¨¡å¼ï¼Œç”¨äºæ£€æµ‹ç›¸ä¼¼å‘½ä»¤"""
    base_pattern: str  # å‘½ä»¤çš„åŸºæœ¬æ¨¡å¼ï¼ˆå»é™¤å…·ä½“å‚æ•°ï¼‰
    count: int = 0
    failed_count: int = 0
    last_output: str = ""
    

class RepetitiveCommandDetector:
    """
    æ£€æµ‹é‡å¤æ‰§è¡Œç›¸åŒæˆ–ç›¸ä¼¼å‘½ä»¤çš„è¡Œä¸ºã€‚
    å½“ Agent å¤šæ¬¡å°è¯•ç›¸åŒçš„å¤±è´¥å‘½ä»¤æ—¶ï¼Œå¼ºåˆ¶å¹²é¢„ã€‚
    """
    
    # æœ€å¤§å…è®¸çš„ç›¸åŒå‘½ä»¤å¤±è´¥æ¬¡æ•°
    MAX_SAME_COMMAND_FAILURES = 3
    # æœ€å¤§å…è®¸çš„ç›¸ä¼¼å‘½ä»¤å¤±è´¥æ¬¡æ•°ï¼ˆå¦‚ä¸åŒåŒ…åçš„apt-get installï¼‰
    MAX_SIMILAR_PATTERN_FAILURES = 5
    # å¸¸è§é”™è¯¯æ¨¡å¼åŠå…¶å»ºè®®
    ERROR_PATTERNS = {
        r"Unable to locate package (\S+)": "åŒ…å '{0}' ä¸å­˜åœ¨ã€‚è¯·æ£€æŸ¥æ­£ç¡®çš„åŒ…åæˆ–ä½¿ç”¨ `apt-cache search <å…³é”®è¯>` æœç´¢ã€‚",
        r"E: Package '(\S+)' has no installation candidate": "åŒ… '{0}' ä¸å¯ç”¨ã€‚å°è¯• `apt-get update` æˆ–æœç´¢æ›¿ä»£åŒ…ã€‚",
        r"playwright.*install-deps": "Playwright ä¾èµ–åº”å·²é¢„å®‰è£…ã€‚ç›´æ¥ä½¿ç”¨ `playwright install chromium` æˆ–ç›´æ¥è¿è¡Œ Python è„šæœ¬ã€‚",
        r"pip.*install.*failed": "pip å®‰è£…å¤±è´¥ã€‚æ£€æŸ¥åŒ…åæ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯• `pip install --upgrade pip` åé‡è¯•ã€‚",
        r"ModuleNotFoundError: No module named '(\S+)'": "æ¨¡å— '{0}' æœªå®‰è£…ã€‚ä½¿ç”¨ `pip install {0}` å®‰è£…ã€‚",
        r"command not found": "å‘½ä»¤ä¸å­˜åœ¨ã€‚ä½¿ç”¨ `apt-get install` å®‰è£…æ‰€éœ€å·¥å…·æˆ–æ£€æŸ¥è·¯å¾„ã€‚",
        r"Permission denied": "æƒé™ä¸è¶³ã€‚å°è¯•æ·»åŠ  `sudo` æˆ–æ£€æŸ¥æ–‡ä»¶æƒé™ã€‚",
        r"Connection refused|Cannot connect": "è¿æ¥è¢«æ‹’ç»ã€‚ç¡®ä¿ç›®æ ‡æœåŠ¡æ­£åœ¨è¿è¡Œå¹¶ç›‘å¬æ­£ç¡®çš„ç«¯å£ã€‚",
        r"libwoff2dec1|libwoff1": "libwoff ç›¸å…³ä¾èµ–é€šè¿‡ `playwright install-deps chromium` è‡ªåŠ¨å®‰è£…ï¼Œä¸éœ€è¦æ‰‹åŠ¨å®‰è£…ã€‚",
        r"gstreamer|libavif": "å¤šåª’ä½“åº“é€šè¿‡ `playwright install-deps chromium` å®‰è£…ï¼Œç›´æ¥è¿è¡Œè¯¥å‘½ä»¤ã€‚",
        # === Web åº”ç”¨å¯åŠ¨å¤±è´¥ç›¸å…³é”™è¯¯æ¨¡å¼ ===
        r"Failed to find attribute '(\w+)' in '(\w+)'": "æ¨¡å— '{1}' æ²¡æœ‰ '{0}' å±æ€§ã€‚è¿™é€šå¸¸æ„å‘³ç€å¯åŠ¨å‘½ä»¤é”™è¯¯ã€‚æ£€æŸ¥ README æˆ– pyproject.toml è·å–æ­£ç¡®çš„å¯åŠ¨æ–¹å¼ã€‚å¯¹äº MLflow ä½¿ç”¨ `mlflow server`ï¼ŒDjango ç”¨ `python manage.py runserver`ï¼ŒFastAPI ç”¨ `uvicorn`ã€‚",
        r"Worker failed to boot|Worker exited with code": "Gunicorn Worker å¯åŠ¨å¤±è´¥ã€‚å¯èƒ½åŸå› ï¼š1) æ¨¡å—è·¯å¾„é”™è¯¯ 2) ç¼ºå°‘ä¾èµ– 3) åº”ç”¨ä¸æ˜¯ WSGI/ASGI å…¼å®¹çš„ã€‚å°è¯•ä½¿ç”¨æ¡†æ¶è‡ªå¸¦çš„å¼€å‘æœåŠ¡å™¨å‘½ä»¤ã€‚",
        r"App failed to load": "åº”ç”¨åŠ è½½å¤±è´¥ã€‚æ£€æŸ¥å…¥å£ç‚¹æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿ä½¿ç”¨ `pip install -e .` å®‰è£…äº†é¡¹ç›®ã€‚",
        r"No module named 'databricks'": "ç¼ºå°‘ databricks-sdkã€‚è¿è¡Œ `pip install databricks-sdk` æˆ– `pip install -e .` å®‰è£…æ‰€æœ‰é¡¹ç›®ä¾èµ–ã€‚",
        r"gunicorn.*mlflow.*:app": "MLflow ä¸ä½¿ç”¨ gunicorn ç›´æ¥å¯åŠ¨ã€‚æ­£ç¡®å‘½ä»¤æ˜¯ `mlflow server --host 0.0.0.0 --port 9600`ã€‚",
        r"AttributeError:.*'function' object has no attribute": "é”™è¯¯çš„ WSGI å…¥å£ç‚¹ã€‚CLI å‡½æ•°ä¸èƒ½ä½œä¸º WSGI appã€‚æ£€æŸ¥é¡¹ç›®æ–‡æ¡£è·å–æ­£ç¡®çš„å¯åŠ¨æ–¹å¼ã€‚",
        r"Address already in use|Connection in use": "ç«¯å£å·²è¢«å ç”¨ã€‚ä½¿ç”¨ `lsof -i :<port>` æˆ– `netstat -tlnp | grep <port>` æ£€æŸ¥ï¼Œç„¶å `kill <pid>` ç»ˆæ­¢è¿›ç¨‹ã€‚",
        r"Could not open requirements file.*No such file": "requirements.txt ä¸å­˜åœ¨ã€‚æ£€æŸ¥é¡¹ç›®ç»“æ„ï¼Œå¯èƒ½æ˜¯ requirements/ ç›®å½•æˆ– pyproject.tomlã€‚å¯¹äºç°ä»£é¡¹ç›®ä½¿ç”¨ `pip install -e .`ã€‚",
        r"ImportError:.*cannot import name": "å¯¼å…¥é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç‰ˆæœ¬ä¸å…¼å®¹æˆ–å¾ªç¯å¯¼å…¥ã€‚æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬ï¼Œå°è¯• `pip install -e .` å®‰è£…æ­£ç¡®ç‰ˆæœ¬ã€‚",
        r"unzip.*Timed out": "unzip å‘½ä»¤è¶…æ—¶ï¼Œé€šå¸¸æ˜¯å› ä¸ºç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼ˆæ–‡ä»¶è¦†ç›–ç¡®è®¤ï¼‰ã€‚å¿…é¡»ä½¿ç”¨ `unzip -o -q file.zip` å‚æ•°ï¼š-o (è¦†ç›–) -q (é™é»˜æ¨¡å¼)ã€‚",
        r"replace.*\[y\]es.*\[n\]o.*\[A\]ll": "unzip æ­£åœ¨ç­‰å¾…ç”¨æˆ·è¾“å…¥è¦†ç›–ç¡®è®¤ã€‚ä½¿ç”¨ `unzip -o file.zip` è‡ªåŠ¨è¦†ç›–æ‰€æœ‰æ–‡ä»¶ã€‚",
        r"Timed out.*unzip": "unzip è¶…æ—¶å¯èƒ½åŸå› ï¼š1) æ–‡ä»¶è¿‡å¤§éœ€è¦æ›´é•¿æ—¶é—´ï¼ˆå°è¯•è§£å‹åˆ° /tmp è€Œä¸æ˜¯è¿œç¨‹æŒ‚è½½ç›®å½•ï¼‰2) ç­‰å¾…äº¤äº’è¾“å…¥ï¼ˆå¿…é¡»åŠ  -o -q å‚æ•°ï¼‰3) ç›®æ ‡ç›®å½•æƒé™é—®é¢˜ã€‚å»ºè®®ï¼šcd /tmp && unzip -o -q /path/to/file.zip",
    }
    
    def __init__(self):
        self.command_history: List[Dict] = []
        self.pattern_counts: Dict[str, CommandPattern] = defaultdict(CommandPattern)
        self.total_commands = 0
        self.total_failures = 0
    
    def reset(self):
        """é‡ç½®æ£€æµ‹å™¨çŠ¶æ€"""
        self.command_history.clear()
        self.pattern_counts.clear()
        self.total_commands = 0
        self.total_failures = 0
    
    def _normalize_command(self, cmd: str) -> str:
        """å°†å‘½ä»¤è§„èŒƒåŒ–ä¸ºæ¨¡å¼ï¼ˆå»é™¤å…·ä½“å‚æ•°ï¼‰"""
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        cmd = ' '.join(cmd.split())
        
        # è§„èŒƒåŒ– apt-get/apt install å‘½ä»¤
        if re.match(r'(sudo\s+)?(apt-get|apt)\s+install', cmd):
            # æå–åŒ…åæ¨¡å¼
            return re.sub(r'(sudo\s+)?(apt-get|apt)\s+install\s+(-y\s+)?', 'APT_INSTALL:', cmd)
        
        # è§„èŒƒåŒ– pip install å‘½ä»¤
        if re.match(r'pip3?\s+install', cmd):
            return re.sub(r'pip3?\s+install\s+', 'PIP_INSTALL:', cmd)
        
        # è§„èŒƒåŒ– playwright å‘½ä»¤
        if 'playwright' in cmd:
            return re.sub(r'playwright\s+\S+', 'PLAYWRIGHT_CMD', cmd)
        
        # è§„èŒƒåŒ– unzip å‘½ä»¤
        if re.match(r'unzip\s+', cmd):
            return 'UNZIP_FILE'
        
        return cmd
    
    def _extract_error_suggestion(self, output: str) -> Optional[str]:
        """ä»è¾“å‡ºä¸­æå–é”™è¯¯å¹¶ç»™å‡ºå»ºè®®"""
        for pattern, suggestion in self.ERROR_PATTERNS.items():
            match = re.search(pattern, output, re.IGNORECASE)
            if match:
                groups = match.groups() if match.groups() else []
                try:
                    return suggestion.format(*groups) if groups else suggestion
                except (IndexError, KeyError):
                    return suggestion
        return None
    
    def check_command(self, command: str, output: str, exit_code: int) -> Optional[str]:
        """
        æ£€æŸ¥å‘½ä»¤æ‰§è¡Œæƒ…å†µï¼Œè¿”å›å¹²é¢„æ¶ˆæ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        
        å¢å¼ºç‰ˆï¼šé›†æˆä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†æå™¨ï¼Œæä¾›æ›´æ™ºèƒ½çš„å»ºè®®
        """
        self.total_commands += 1
        is_failure = exit_code != 0
        
        if is_failure:
            self.total_failures += 1
        
        # ğŸ” æ­¥éª¤1ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡åˆ†æå™¨åˆ†æå‘½ä»¤è¾“å‡º
        context_analyzer = get_context_analyzer()
        context_insight = context_analyzer.analyze_command(command, output, exit_code)
        
        # å¦‚æœå‘ç°ä¸Šä¸‹æ–‡é—®é¢˜ï¼Œç”Ÿæˆæ›´æ™ºèƒ½çš„å¹²é¢„æ¶ˆæ¯
        if context_insight and context_insight.blocking:
            return self._generate_contextual_intervention(context_insight)
        
        # è§„èŒƒåŒ–å‘½ä»¤
        pattern = self._normalize_command(command)
        
        # æ›´æ–°æ¨¡å¼ç»Ÿè®¡
        if pattern not in self.pattern_counts:
            self.pattern_counts[pattern] = CommandPattern(base_pattern=pattern)
        
        self.pattern_counts[pattern].count += 1
        if is_failure:
            self.pattern_counts[pattern].failed_count += 1
            self.pattern_counts[pattern].last_output = output[-500:]  # ä¿ç•™æœ€å500å­—ç¬¦
        
        # è®°å½•å†å²
        self.command_history.append({
            'command': command,
            'pattern': pattern,
            'exit_code': exit_code,
            'is_failure': is_failure
        })
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¹²é¢„
        intervention_msg = None
        
        # 1. æ£€æŸ¥ç›¸åŒå‘½ä»¤é‡å¤å¤±è´¥
        if self.pattern_counts[pattern].failed_count >= self.MAX_SAME_COMMAND_FAILURES:
            # ğŸ†• å°è¯•ä»ä¸Šä¸‹æ–‡åˆ†æå™¨è·å–æ›´å…·ä½“çš„å»ºè®®
            accumulated_insights = context_analyzer.get_accumulated_insights()
            error_suggestion = self._extract_error_suggestion(output)
            
            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡æ´å¯Ÿï¼Œä¼˜å…ˆä½¿ç”¨
            if accumulated_insights:
                error_suggestion = accumulated_insights + "\n" + (error_suggestion or "")
            
            intervention_msg = self._generate_intervention(
                f"ç›¸åŒå‘½ä»¤å·²å¤±è´¥ {self.pattern_counts[pattern].failed_count} æ¬¡",
                command,
                error_suggestion
            )
        
        # 2. æ£€æŸ¥ç›¸ä¼¼æ¨¡å¼é‡å¤å¤±è´¥ï¼ˆå¦‚å¤šæ¬¡å°è¯•ä¸åŒçš„aptåŒ…åï¼‰
        elif pattern.startswith('APT_INSTALL:'):
            apt_failures = sum(
                p.failed_count for key, p in self.pattern_counts.items() 
                if key.startswith('APT_INSTALL:')
            )
            if apt_failures >= self.MAX_SIMILAR_PATTERN_FAILURES:
                error_suggestion = self._extract_error_suggestion(output)
                intervention_msg = self._generate_intervention(
                    f"apt-get install ç›¸å…³å‘½ä»¤å·²å¤±è´¥ {apt_failures} æ¬¡",
                    command,
                    error_suggestion or "è€ƒè™‘ä½¿ç”¨ `playwright install-deps chromium` è‡ªåŠ¨å®‰è£…æ‰€æœ‰ä¾èµ–ï¼Œæˆ–ä½¿ç”¨ `apt-cache search` æœç´¢æ­£ç¡®çš„åŒ…å"
                )
        
        # 3. æ£€æŸ¥æ€»ä½“å¤±è´¥ç‡
        if self.total_commands >= 10 and self.total_failures / self.total_commands > 0.7:
            intervention_msg = self._generate_high_failure_rate_warning()
        
        return intervention_msg
    
    def _generate_contextual_intervention(self, insight: 'ContextualInsight') -> str:
        """
        æ ¹æ®ä¸Šä¸‹æ–‡æ´å¯Ÿç”Ÿæˆæ›´æ™ºèƒ½çš„å¹²é¢„æ¶ˆæ¯
        """
        # æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©å›¾æ ‡
        icon_map = {
            'download_failed': 'â¬‡ï¸',
            'url_not_found': 'ğŸ”—',
            'file_corrupted': 'ğŸ“„',
            'file_not_zip': 'ğŸ“¦',
            'unzip_known_bad_file': 'âš ï¸'
        }
        icon = icon_map.get(insight.issue_type, 'â—')
        
        msg = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ {icon} æ™ºèƒ½ä¸Šä¸‹æ–‡åˆ†æ - æ£€æµ‹åˆ°æ ¹æœ¬é—®é¢˜                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ” é—®é¢˜ç±»å‹: {insight.issue_type:<52} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“ è¯æ®:                                                               â•‘"""
        
        # å°†è¯æ®åˆ†æˆå¤šè¡Œ
        evidence_lines = [insight.evidence[i:i+62] for i in range(0, len(insight.evidence), 62)]
        for line in evidence_lines[:3]:
            msg += f"\nâ•‘   {line:<62} â•‘"
        
        msg += f"""
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ’¡ è§£å†³æ–¹æ¡ˆ:                                                           â•‘"""
        
        # å°†å»ºè®®åˆ†æˆå¤šè¡Œ
        suggestion_lines = [insight.suggestion[i:i+62] for i in range(0, len(insight.suggestion), 62)]
        for line in suggestion_lines[:4]:
            msg += f"\nâ•‘   {line:<62} â•‘"
        
        msg += f"""
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸš« ä¸è¦ç»§ç»­å°è¯•ç›¸åŒçš„æ–¹æ³•ï¼è¯·é‡‡ç”¨ä¸Šè¿°è§£å†³æ–¹æ¡ˆã€‚              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"""
        
        return msg
    
    def _generate_intervention(self, reason: str, command: str, suggestion: Optional[str] = None) -> str:
        """ç”Ÿæˆå¹²é¢„æ¶ˆæ¯"""
        msg = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âš ï¸  é‡å¤å¤±è´¥æ£€æµ‹ - éœ€è¦æ”¹å˜ç­–ç•¥                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ åŸå› : {reason[:60]:<60} â•‘
â•‘ å¤±è´¥å‘½ä»¤: {command[:56]:<56} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ”§ å»ºè®®:                                                          â•‘"""
        
        if suggestion:
            # å°†å»ºè®®åˆ†æˆå¤šè¡Œ
            lines = [suggestion[i:i+60] for i in range(0, len(suggestion), 60)]
            for line in lines[:3]:  # æœ€å¤š3è¡Œ
                msg += f"\nâ•‘   {line:<62} â•‘"
        else:
            msg += "\nâ•‘   - å°è¯•å®Œå…¨ä¸åŒçš„æ–¹æ³•                                        â•‘"
            msg += "\nâ•‘   - æ£€æŸ¥é”™è¯¯ä¿¡æ¯ï¼Œç†è§£æ ¹æœ¬åŸå›                                 â•‘"
            msg += "\nâ•‘   - æœç´¢æ­£ç¡®çš„åŒ…åæˆ–å‘½ä»¤è¯­æ³•                                  â•‘"
        
        msg += """
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ âŒ è¯·å‹¿å†æ¬¡å°è¯•ç›¸åŒæˆ–ç›¸ä¼¼çš„å‘½ä»¤ï¼Œå¿…é¡»é‡‡ç”¨æ–°ç­–ç•¥ï¼                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"""
        return msg
    
    def _generate_high_failure_rate_warning(self) -> str:
        """ç”Ÿæˆé«˜å¤±è´¥ç‡è­¦å‘Š"""
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸš¨ é«˜å¤±è´¥ç‡è­¦å‘Š                                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ å·²æ‰§è¡Œ {self.total_commands} ä¸ªå‘½ä»¤ï¼Œå…¶ä¸­ {self.total_failures} ä¸ªå¤±è´¥ ({100*self.total_failures//self.total_commands}%)          â•‘
â•‘                                                                  â•‘
â•‘ å»ºè®®:                                                            â•‘
â•‘ 1. æš‚åœæ‰§è¡Œï¼Œä»”ç»†åˆ†æä¹‹å‰çš„é”™è¯¯è¾“å‡º                              â•‘
â•‘ 2. æ£€æŸ¥ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®                                          â•‘
â•‘ 3. è€ƒè™‘æ˜¯å¦éœ€è¦å…ˆå®‰è£…åŸºç¡€ä¾èµ–                                    â•‘
â•‘ 4. æŸ¥çœ‹æ–‡æ¡£æˆ–æœç´¢æ­£ç¡®çš„å‘½ä»¤ç”¨æ³•                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"""
    
    def get_summary(self) -> str:
        """è·å–å‘½ä»¤æ‰§è¡Œæ‘˜è¦"""
        if not self.command_history:
            return "æ— å‘½ä»¤å†å²è®°å½•"
        
        failed_patterns = [
            (p.base_pattern, p.failed_count) 
            for p in self.pattern_counts.values() 
            if p.failed_count > 0
        ]
        failed_patterns.sort(key=lambda x: x[1], reverse=True)
        
        summary = f"å‘½ä»¤ç»Ÿè®¡: {self.total_commands} æ€»è®¡, {self.total_failures} å¤±è´¥\n"
        if failed_patterns:
            summary += "å¤±è´¥æœ€å¤šçš„å‘½ä»¤æ¨¡å¼:\n"
            for pattern, count in failed_patterns[:5]:
                summary += f"  - {pattern[:50]}: {count} æ¬¡å¤±è´¥\n"
        return summary


# å…¨å±€é‡å¤å‘½ä»¤æ£€æµ‹å™¨
_command_detector: Optional[RepetitiveCommandDetector] = None


def get_command_detector() -> RepetitiveCommandDetector:
    """è·å–æˆ–åˆ›å»ºå…¨å±€å‘½ä»¤æ£€æµ‹å™¨"""
    global _command_detector
    if _command_detector is None:
        _command_detector = RepetitiveCommandDetector()
    return _command_detector


def reset_command_detector():
    """é‡ç½®å‘½ä»¤æ£€æµ‹å™¨å’Œä¸Šä¸‹æ–‡åˆ†æå™¨"""
    global _command_detector
    if _command_detector:
        _command_detector.reset()
    # åŒæ—¶é‡ç½®ä¸Šä¸‹æ–‡åˆ†æå™¨
    reset_context_analyzer()


# ==================== åŸæœ‰ä»£ç  ====================


def get_reflector():
    """è·å–æˆ–åˆ›å»ºå…¨å±€åæ€å™¨å®ä¾‹"""
    global _mid_exec_reflector
    if _mid_exec_reflector is None:
        try:
            from agents.midExecReflector import MidExecutionReflector
            _mid_exec_reflector = MidExecutionReflector()
        except ImportError:
            pass
    return _mid_exec_reflector


def enable_reflection(enabled: bool = True, context: str = "", deployment_strategy: dict = None):
    """å¯ç”¨æˆ–ç¦ç”¨åæ€æœºåˆ¶ï¼ˆå¢å¼ºï¼šæ”¯æŒdeployment_strategyï¼‰"""
    global _reflection_enabled, _mid_exec_reflector
    _reflection_enabled = enabled
    if enabled:
        # å¦‚æœæä¾›äº†deployment_strategy,åˆ›å»ºæ–°çš„reflectorå®ä¾‹
        if deployment_strategy:
            try:
                from agents.midExecReflector import MidExecutionReflector
                _mid_exec_reflector = MidExecutionReflector(
                    context=context, 
                    deployment_strategy=deployment_strategy
                )
                print("[command_ops] âœ… MidExecReflector initialized with DeploymentStrategy")
            except ImportError as e:
                print(f"[command_ops] âš ï¸ Failed to import MidExecutionReflector: {e}")
        elif context:
            # å¦‚æœåªæœ‰context,æ›´æ–°ç°æœ‰reflector
            reflector = get_reflector()
            if reflector:
                reflector.update_context(context)


def reset_reflection():
    """é‡ç½®åæ€å™¨çŠ¶æ€"""
    global _mid_exec_reflector
    if _mid_exec_reflector:
        _mid_exec_reflector.reset()

@tools.tool
def execute_find_command(filename: str) -> str:
    """
    This tool runs a 'find' command in the given directory to search for a specific file.
    If no files match, it returns "No files found."
    :param filename: The filename (or part of it) to search for.
    :return: The output of the 'find' command or a message if no files are found.
    """
    
    cur_dir = os.getcwd()
    os.chdir("simulation_environments/" + os.environ['REPO_PATH'])
    # Execute the find command
    process = subprocess.run(
        f"find ./ -type f -name '*{filename}*'",
        shell=True,
        capture_output=True,
        text=True,
        timeout=10
    )
    os.chdir(cur_dir)
    
    # Check if files are found
    if process.stdout.strip():
        return f"# Files found:\n{process.stdout}"
    else:
        return "No files found."

@tools.tool
def execute_ls_command(dir: str) -> str:
    """
    This tool runs an ls command in the given directory and returns the output.
    :param dir: The directory to run the ls command in.
    :return: The output of the ls command.
    """

    # print("Trying to execute: ls on", dir, "\nProceed? y/N")
    # p = input()
    # if p!='y':
    #     return "Unable to execute, permission denied"
    
    return execute_command_foreground(f"ls -a {dir}")

# Environment variables for commands
env = {}

@tools.tool
def set_environment_variable(key: str, value: str, clear: bool) -> str:
    """
    This tool sets an environment variable that will be used by all successive commands.

    :param key: The environment variable name.
    :param value: The value to assign to the environment variable.
    :param clear: Clears all previous env variables set using this command.
    :return: Confirmation message.
    """
    
    global env

    # Check for confirmation
    # print(f"Trying to export {key}={value}, clear={clear}. \nProceed? y/N")
    # p = input()
    # if p.lower() != 'y':
    #     return "Operation cancelled by user."

    if clear:
        env = {}
    env[key] = value
    
    return f"Success, current env_list={env}."

@tools.tool
def execute_linux_command(command: str, background: bool) -> str:
    """
    Executes a shell command in the root directory of the target repository.
    
    USAGE GUIDELINES:
    - Use background=False for: installations, builds, one-time commands
    - Use background=True for: servers, daemons, long-running processes
    
    IMPORTANT NOTES:
    - Export commands won't persist across calls (use set_environment_variable instead)
    - Avoid commands requiring user input (they will hang)
    - sudo commands are supported
    - Exit code 0 = success, non-zero = error
    - Empty/null output does NOT mean failure - check exit code!
    
    EXAMPLES:
    - execute_linux_command('pip install mlflow==2.11.2', background=False)
    - execute_linux_command('mlflow ui --host 0.0.0.0 --port 5000', background=True)
    - execute_linux_command('ps aux | grep mlflow', background=False)
    - execute_linux_command('curl http://localhost:5000', background=False)

    :param command: The shell command to execute
    :param background: True for long-running processes (servers), False for normal commands
    :return: Command output with exit code and logs
    """
    print("Trying to execute: ", command)
    if background:
        return execute_command_background(command)
    else:
        return execute_command_foreground(command)


# ==================== ç¯å¢ƒè·¯å¾„å¸¸é‡ ====================
SIMULATION_ENV_DIR = "/workspaces/submission/src/simulation_environments"

# éœ€è¦åœ¨ DAG ç»“æŸæ—¶æ¸…ç†çš„è¿›ç¨‹æ¨¡å¼
CLEANUP_PROCESS_PATTERNS = [
    'mlflow',
    'gunicorn', 
    'flask',
    'uvicorn',
    'django',
    'streamlit',
    'node',
    'npm',
    'python.*main.py',  # é¿å…æ€æ‰è‡ªå·±ï¼Œéœ€è¦æ’é™¤å½“å‰è¿›ç¨‹
]


def cleanup_running_processes() -> str:
    """æ¸…ç† DAG è¿è¡Œåæ®‹ç•™çš„åå°è¿›ç¨‹
    
    åœ¨ DAG æ‰§è¡Œå®Œæˆåï¼ˆæ— è®ºæˆåŠŸå¤±è´¥ï¼‰è°ƒç”¨æ­¤å‡½æ•°ï¼Œ
    æ€æ‰æ‰€æœ‰ Web æœåŠ¡è¿›ç¨‹ï¼Œé˜²æ­¢ CPU/å†…å­˜å æ»¡ã€‚
    
    :return: æ¸…ç†ç»“æœæ‘˜è¦
    """
    killed = []
    current_pid = os.getpid()
    
    for pattern in CLEANUP_PROCESS_PATTERNS:
        try:
            # ä½¿ç”¨ pkill æ€æ‰åŒ¹é…çš„è¿›ç¨‹ï¼Œä½†æ’é™¤å½“å‰è¿›ç¨‹
            cmd = f"pkill -9 -f '{pattern}' 2>/dev/null || true"
            subprocess.run(cmd, shell=True, capture_output=True, timeout=10)
            killed.append(pattern)
        except Exception as e:
            print(f"âš ï¸ Failed to kill {pattern}: {e}")
    
    # é¢å¤–æ¸…ç†ç«¯å£å ç”¨
    common_ports = [5000, 8000, 8080, 9600, 3000]
    for port in common_ports:
        try:
            subprocess.run(f"fuser -k {port}/tcp 2>/dev/null || true", shell=True, capture_output=True, timeout=5)
        except:
            pass
    
    result = f"ğŸ§¹ Cleaned up processes: {', '.join(killed)}"
    print(result)
    return result


def wait_for_service(url: str, timeout: int = 60, interval: int = 2) -> dict:
    """ç­‰å¾… Web æœåŠ¡å°±ç»ª
    
    åœ¨ browser-provision å‰è°ƒç”¨ï¼Œç¡®ä¿æœåŠ¡å·²å®Œå…¨å¯åŠ¨ã€‚
    æ¯” cleanup_and_start_service ä¸­çš„å¥åº·æ£€æŸ¥æ›´å½»åº•ã€‚
    
    :param url: æœåŠ¡ URLï¼Œå¦‚ http://localhost:5000
    :param timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    :param interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    :return: æ£€æŸ¥ç»“æœ {ready: bool, status_code: int, elapsed: float, message: str}
    """
    import time
    
    result = {
        'ready': False,
        'status_code': 0,
        'elapsed': 0,
        'message': '',
        'url': url,
    }
    
    start_time = time.time()
    attempts = 0
    max_attempts = timeout // interval
    
    print(f"â³ Waiting for service at {url} (timeout: {timeout}s)...")
    
    while attempts < max_attempts:
        attempts += 1
        elapsed = time.time() - start_time
        
        try:
            # ä½¿ç”¨ curl æ£€æŸ¥æœåŠ¡
            curl_cmd = f"curl -s -o /dev/null -w '%{{http_code}}' '{url}/' --connect-timeout 5 --max-time 10"
            proc = subprocess.run(curl_cmd, shell=True, capture_output=True, text=True, timeout=15)
            status_code = proc.stdout.strip()
            
            if status_code and status_code != '000':
                code = int(status_code)
                result['status_code'] = code
                result['elapsed'] = elapsed
                
                # å¤§å¤šæ•° HTTP å“åº”éƒ½è¡¨ç¤ºæœåŠ¡åœ¨è¿è¡Œï¼ˆåŒ…æ‹¬é‡å®šå‘ï¼‰
                if code in [200, 301, 302, 303, 307, 308, 401, 403, 404, 405, 500]:
                    result['ready'] = True
                    result['message'] = f"Service ready! HTTP {code} after {elapsed:.1f}s"
                    print(f"âœ… {result['message']}")
                    return result
                else:
                    print(f"  Attempt {attempts}: HTTP {code}, waiting...")
            else:
                print(f"  Attempt {attempts}: Connection refused, waiting...")
                
        except subprocess.TimeoutExpired:
            print(f"  Attempt {attempts}: Timeout, waiting...")
        except Exception as e:
            print(f"  Attempt {attempts}: Error - {e}, waiting...")
        
        time.sleep(interval)
    
    result['elapsed'] = time.time() - start_time
    result['message'] = f"Service not ready after {timeout}s ({attempts} attempts)"
    print(f"âŒ {result['message']}")
    return result


def cleanup_simulation_environment(keep_current_cve: str = "") -> str:
    """æ¸…ç† simulation_environments ç›®å½•å’Œè™šæ‹Ÿç¯å¢ƒï¼Œåªä¿ç•™æœ€è¿‘ä¸€æ¬¡çš„ç¯å¢ƒ
    
    ä¸ºäº†èŠ‚çœå­˜å‚¨ç©ºé—´å’Œä¿æŠ¤ç³»ç»Ÿç¯å¢ƒï¼Œæ¯æ¬¡è¿è¡Œæ–° CVE å‰ï¼š
    1. æ¸…ç†æ—§çš„é¡¹ç›®æ–‡ä»¶
    2. æ¸…ç†æ—§çš„è™šæ‹Ÿç¯å¢ƒ
    
    :param keep_current_cve: å½“å‰æ­£åœ¨è¿è¡Œçš„ CVE åç§°ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œç”¨äºä¿ç•™ç›¸å…³æ–‡ä»¶
    :return: æ¸…ç†ç»“æœæ‘˜è¦
    """
    import shutil
    
    # ========== 1. æ¸…ç†è™šæ‹Ÿç¯å¢ƒ ==========
    cleanup_venv()
    
    # ========== 2. æ¸…ç† simulation_environments ==========
    if not os.path.exists(SIMULATION_ENV_DIR):
        os.makedirs(SIMULATION_ENV_DIR, exist_ok=True)
        return "Created simulation_environments directory"
    
    cleaned = []
    kept = []
    
    for item in os.listdir(SIMULATION_ENV_DIR):
        item_path = os.path.join(SIMULATION_ENV_DIR, item)
        
        # å¦‚æœæŒ‡å®šäº†å½“å‰ CVEï¼Œä¿ç•™ç›¸å…³æ–‡ä»¶
        if keep_current_cve and keep_current_cve.lower() in item.lower():
            kept.append(item)
            continue
        
        # åˆ é™¤æ—§æ–‡ä»¶å’Œç›®å½•
        try:
            if os.path.isdir(item_path):
                shutil.rmtree(item_path)
            else:
                os.remove(item_path)
            cleaned.append(item)
        except Exception as e:
            print(f"âš ï¸ Failed to remove {item}: {e}")
    
    result = f"Cleaned {len(cleaned)} items from simulation_environments"
    if kept:
        result += f", kept {len(kept)} items for current CVE"
    print(f"ğŸ§¹ {result}")
    
    return result


def get_working_directory() -> str:
    """è·å–å‘½ä»¤æ‰§è¡Œçš„å·¥ä½œç›®å½•
    
    å·¥ä½œç›®å½•ä¼˜å…ˆçº§:
    1. REPO_PATHï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼Œåœ¨ simulation_environments ä¸‹ï¼‰
    2. WORK_DIR ç¯å¢ƒå˜é‡ï¼ˆæ‰‹åŠ¨æŒ‡å®šï¼‰
    3. simulation_environments ç›®å½•ï¼ˆå§‹ç»ˆç”¨äºä¸‹è½½/è§£å‹æºç ï¼‰
    
    æ³¨æ„ï¼šå§‹ç»ˆè¿”å› simulation_environmentsï¼Œå³ä½¿å®ƒæ˜¯ç©ºçš„ã€‚
    è¿™æ · wget/unzip ç­‰ä¸‹è½½å‘½ä»¤ä¼šæŠŠæ–‡ä»¶æ”¾åˆ°æ­£ç¡®çš„ä½ç½®ã€‚
    """
    # ä¼˜å…ˆä½¿ç”¨ REPO_PATHï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰
    if os.environ.get("REPO_PATH"):
        repo_dir = f"{SIMULATION_ENV_DIR}/{os.environ['REPO_PATH']}"
        if os.path.exists(repo_dir):
            return repo_dir
    
    # å…¶æ¬¡æ£€æŸ¥ WORK_DIR ç¯å¢ƒå˜é‡
    if os.environ.get("WORK_DIR"):
        return os.environ["WORK_DIR"]
    
    # å§‹ç»ˆä½¿ç”¨ simulation_environments ç›®å½•
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    if not os.path.exists(SIMULATION_ENV_DIR):
        os.makedirs(SIMULATION_ENV_DIR, exist_ok=True)
    
    return SIMULATION_ENV_DIR


# ==================== pip å‘½ä»¤éš”ç¦»æœºåˆ¶ ====================
VENV_PATH = "/tmp/venv"

def is_pip_command(command: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯ pip å®‰è£…å‘½ä»¤"""
    pip_patterns = [
        r'^\s*pip\s+install',
        r'^\s*pip3\s+install',
        r'^\s*python\s+-m\s+pip\s+install',
        r'^\s*python3\s+-m\s+pip\s+install',
        r'&&\s*pip\s+install',
        r'&&\s*pip3\s+install',
        r';\s*pip\s+install',
        r';\s*pip3\s+install',
    ]
    for pattern in pip_patterns:
        if re.search(pattern, command, re.IGNORECASE):
            return True
    return False


def ensure_venv_exists() -> bool:
    """ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    if os.path.exists(f"{VENV_PATH}/bin/activate"):
        return True
    
    try:
        print(f"[Isolation] ğŸ”§ Creating virtual environment at {VENV_PATH}...")
        result = subprocess.run(
            f"python3 -m venv {VENV_PATH}",
            shell=True,
            capture_output=True,
            text=True,
            timeout=60
        )
        if result.returncode == 0:
            print(f"[Isolation] âœ… Virtual environment created")
            return True
        else:
            print(f"[Isolation] âŒ Failed to create venv: {result.stderr}")
            return False
    except Exception as e:
        print(f"[Isolation] âŒ Error creating venv: {e}")
        return False


def wrap_pip_command_in_venv(command: str) -> str:
    """å°† pip å‘½ä»¤åŒ…è£…åœ¨è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œ
    
    åŸå§‹å‘½ä»¤:
        pip install flask
        cd project && pip install -r requirements.txt
    
    åŒ…è£…å:
        source /tmp/venv/bin/activate && pip install flask
        cd project && source /tmp/venv/bin/activate && pip install -r requirements.txt
    """
    # å¦‚æœå‘½ä»¤å·²ç»åŒ…å« venv æ¿€æ´»ï¼Œä¸éœ€è¦å†åŒ…è£…
    if '/tmp/venv/bin/activate' in command or 'source.*venv' in command:
        return command
    
    # ç¡®ä¿ venv å­˜åœ¨
    ensure_venv_exists()
    
    activate_cmd = f"source {VENV_PATH}/bin/activate"
    
    # å¤„ç†å¤åˆå‘½ä»¤ (cd xxx && pip install)
    if '&&' in command:
        # åœ¨ç¬¬ä¸€ä¸ª pip å‘½ä»¤å‰æ’å…¥æ¿€æ´»
        parts = command.split('&&')
        new_parts = []
        activated = False
        for part in parts:
            part = part.strip()
            if not activated and ('pip install' in part.lower() or 'pip3 install' in part.lower()):
                new_parts.append(activate_cmd)
                activated = True
            new_parts.append(part)
        return ' && '.join(new_parts)
    
    # å¤„ç†ç®€å•å‘½ä»¤
    if command.strip().startswith('pip') or command.strip().startswith('python'):
        return f"{activate_cmd} && {command}"
    
    return command


def cleanup_venv():
    """æ¸…ç†è™šæ‹Ÿç¯å¢ƒï¼ˆåœ¨æ¯æ¬¡ CVE å¤ç°å¼€å§‹æ—¶è°ƒç”¨ï¼‰"""
    if os.path.exists(VENV_PATH):
        try:
            import shutil
            shutil.rmtree(VENV_PATH)
            print(f"[Isolation] ğŸ§¹ Cleaned up virtual environment: {VENV_PATH}")
        except Exception as e:
            print(f"[Isolation] âš ï¸ Failed to cleanup venv: {e}")


def execute_command_foreground(command: str) -> str:
    """
    This tool runs a command (in the root directory of the target repository) in the shell, waits for termination and returns the output.
    Do not spawn processes that run servers as it will hang indefinitely.

    :param command: The command to run.
    :return: The output of the command.
    """
    
    # å›è°ƒè¶…æ—¶æ—¶é—´ - æ ¹æ®å‘½ä»¤ç±»å‹åŠ¨æ€è°ƒæ•´
    # npm install / yarn install / composer install ç­‰å®‰è£…å‘½ä»¤éœ€è¦æ›´é•¿æ—¶é—´
    cmd_lower = command.lower()
    if any(x in cmd_lower for x in ['npm install', 'yarn install', 'pnpm install', 'composer install', 'pip install -r', 'bundle install', 'cargo build', 'mvn install', 'gradle build']):
        # å¤§å‹é¡¹ç›®å®‰è£…å¯èƒ½éœ€è¦ 10-15 åˆ†é’Ÿ
        timeout = 900  # 15 åˆ†é’Ÿ
        print(f"ğŸ•’ Using extended timeout ({timeout}s) for package installation...")
    elif any(x in cmd_lower for x in ['git clone', 'docker pull', 'docker build']):
        timeout = 600  # 10 åˆ†é’Ÿ
    else:
        timeout = 300  # 5 åˆ†é’Ÿï¼ˆé»˜è®¤ï¼‰
    
    # ğŸš« æ­¥éª¤ 0ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥é˜»æ­¢æ‰§è¡Œè¿™ä¸ªå‘½ä»¤ï¼ˆåŸºäºä¹‹å‰çš„å¤±è´¥è®°å¿†ï¼‰
    context_analyzer = get_context_analyzer()
    block_reason = context_analyzer.should_block_command(command)
    if block_reason:
        print(f"\nâ›” å‘½ä»¤è¢«æ™ºèƒ½åˆ†æå™¨é˜»æ­¢: {command[:50]}...")
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ â›” å‘½ä»¤å·²è¢«é˜»æ­¢æ‰§è¡Œ                                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ åŸå› : {block_reason[:58]:<58} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ æ­¤å‘½ä»¤ä¹‹å‰å·²å¤±è´¥ï¼Œå¹¶ä¸”æ ¹æœ¬åŸå› å·²è¢«è¯†åˆ«ã€‚                      â•‘
â•‘ è¯·é‡‡ç”¨ä¸åŒçš„æ–¹æ³•ï¼Œä¸è¦ç»§ç»­å°è¯•åŒæ ·çš„å¤±è´¥æ“ä½œï¼                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    
    # ========== pip å‘½ä»¤éš”ç¦»ï¼šä¿æŠ¤ç³»ç»Ÿç¯å¢ƒ ==========
    original_command = command
    if is_pip_command(command):
        command = wrap_pip_command_in_venv(command)
        if command != original_command:
            print(f"[Isolation] ğŸ”’ pip command isolated to venv")
            print(f"[Isolation] Original: {original_command}")
            print(f"[Isolation] Wrapped:  {command}")
    
    stdout_log = create_unique_logfile("stdout")
    stderr_log = create_unique_logfile("stderr")
    exit_code = 0
    work_dir = get_working_directory()
    timeout_occurred = False
    
    try:
        with open(stdout_log, "w", encoding='utf-8') as stdout, open(stderr_log, "w", encoding='utf-8') as stderr:
            result = subprocess.run(
                command,
                shell=True,
                executable="/bin/bash",
                cwd=work_dir,
                stdout=stdout,
                stderr=stderr,
                text=True,
                timeout=timeout,
                errors="ignore",
                env=os.environ.copy() | env
            )
            exit_code = result.returncode
    except subprocess.TimeoutExpired:
        exit_code = 124  # æ ‡å‡†çš„è¶…æ—¶é€€å‡ºç 
        timeout_occurred = True
        output = f"âŒ Timed out after {timeout}s! Command: {original_command}"
        
        # ğŸ”„ é‡å¤å‘½ä»¤æ£€æµ‹ï¼ˆè¶…æ—¶ä¹Ÿç®—å¤±è´¥ï¼‰
        detector = get_command_detector()
        repetition_warning = detector.check_command(original_command, output, exit_code)
        if repetition_warning:
            output = output + "\n\n" + repetition_warning
        
        return output

    # Get the last 100 lines of both log files
    tail_output = get_tail_log(stdout_log, stderr_log)
    
    # Add exit code and status indicator
    status_icon = "âœ…" if exit_code == 0 else "âš ï¸"
    
    # ğŸ†• å‘½ä»¤å¤±è´¥æ—¶ï¼Œè®°å½•åˆ° ContextAwareAnalyzer çš„é‡å¤å¤±è´¥æ£€æµ‹å™¨
    if exit_code != 0:
        block_msg = context_analyzer.record_command_failure(original_command, tail_output)
        if block_msg:
            # å¦‚æœè¶…è¿‡é‡å¤æ¬¡æ•°ï¼Œè¿”å›é˜»æ­¢æ¶ˆæ¯
            return f"""
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ğŸ›‘ é‡å¤å¤±è´¥æ£€æµ‹è§¦å‘ï¼åŒä¸€å‘½ä»¤å·²å¤±è´¥å¤šæ¬¡                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
{block_msg}
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â— æ­¤å‘½ä»¤å·²è¢«è‡ªåŠ¨é˜»æ­¢ï¼Œåç»­ç›¸åŒå‘½ä»¤å°†ä¸å†æ‰§è¡Œ               â”‚
â”‚ âœ… è¯·é‡‡ç”¨å®Œå…¨ä¸åŒçš„ç­–ç•¥ï¼                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""
    
    # å¦‚æœå‘½ä»¤è¢«éš”ç¦»ï¼Œåœ¨è¾“å‡ºä¸­è¯´æ˜
    isolation_note = ""
    if command != original_command:
        isolation_note = f"\n[Isolation] â„¹ï¸ Command was executed in isolated venv ({VENV_PATH})\n"
    
    output = (
        f"{status_icon} Command completed with exit code: {exit_code}\n"
        f"Command: {original_command}\n"
        f"{isolation_note}\n"
        f"{tail_output}\n"
        f"{'Note: Exit code 0 = success, non-zero = error' if exit_code != 0 else ''}"
    )
    
    # ğŸ†• å…³é”®ä¿®å¤ï¼šå³ä½¿ exit_code == 0ï¼Œå¯¹äºä¸‹è½½å‘½ä»¤ä¹Ÿè¦åˆ†ææ˜¯å¦çœŸæ­£æˆåŠŸ
    # curl/wget å¯èƒ½è¿”å› 0 ä½†ä¸‹è½½çš„æ˜¯é”™è¯¯é¡µé¢ï¼ˆå¦‚ GitHub 404 é¡µé¢ï¼‰
    if exit_code == 0 and any(x in cmd_lower for x in ['curl', 'wget']):
        insight = context_analyzer.analyze_curl_wget_output(original_command, tail_output, exit_code)
        if insight and insight.blocking:
            # ä¸‹è½½è™½ç„¶"æˆåŠŸ"ä½†å®é™…æ˜¯é”™è¯¯é¡µé¢
            output = output + f"\n\n" + f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âš ï¸ ä¸‹è½½éªŒè¯å¤±è´¥ - æ–‡ä»¶å†…å®¹æ— æ•ˆ                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ {insight.evidence[:60]:<60} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ {insight.suggestion[:60]:<60} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ’¡ åç»­å¯¹æ­¤æ–‡ä»¶çš„æ“ä½œï¼ˆå¦‚ unzipï¼‰å°†è¢«è‡ªåŠ¨é˜»æ­¢              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    
    # ğŸ”„ é‡å¤å‘½ä»¤æ£€æµ‹
    detector = get_command_detector()
    repetition_warning = detector.check_command(original_command, output, exit_code)
    if repetition_warning:
        output = output + "\n\n" + repetition_warning
    
    # ğŸ” ä¸­é€”åæ€æ£€æŸ¥
    if _reflection_enabled:
        reflector = get_reflector()
        if reflector:
            reflection_result = reflector.check_and_reflect(command, output)
            if reflection_result and reflection_result.should_intervene:
                # å°†åæ€ç»“æœé™„åŠ åˆ°è¾“å‡ºï¼Œè®© Agent çœ‹åˆ°
                intervention_msg = reflector.get_intervention_message(reflection_result)
                output = output + "\n\n" + intervention_msg
    
    return output

background_process_list={}


def is_python_run_command(command: str) -> bool:
    """æ£€æµ‹æ˜¯å¦æ˜¯ Python è¿è¡Œå‘½ä»¤ï¼ˆéœ€è¦ä½¿ç”¨ venv ä¸­çš„ Pythonï¼‰"""
    python_patterns = [
        r'^\s*python\s+',
        r'^\s*python3\s+',
        r'&&\s*python\s+',
        r'&&\s*python3\s+',
        r';\s*python\s+',
        r';\s*python3\s+',
        r'uvicorn\s+',
        r'gunicorn\s+',
        r'flask\s+run',
        r'streamlit\s+run',
    ]
    for pattern in python_patterns:
        if re.search(pattern, command, re.IGNORECASE):
            return True
    return False


def wrap_python_command_in_venv(command: str) -> str:
    """å°† Python è¿è¡Œå‘½ä»¤åŒ…è£…åœ¨è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œ"""
    # å¦‚æœå‘½ä»¤å·²ç»åŒ…å« venv æ¿€æ´»ï¼Œä¸éœ€è¦å†åŒ…è£…
    if '/tmp/venv/bin/activate' in command:
        return command
    
    # å¦‚æœ venv ä¸å­˜åœ¨ï¼Œä¸åŒ…è£…ï¼ˆå¯èƒ½è¿˜æ²¡å®‰è£…ä¾èµ–ï¼‰
    if not os.path.exists(f"{VENV_PATH}/bin/activate"):
        return command
    
    activate_cmd = f"source {VENV_PATH}/bin/activate"
    
    # å¤„ç†å¤åˆå‘½ä»¤ (cd xxx && python app.py)
    if '&&' in command:
        parts = command.split('&&')
        new_parts = []
        activated = False
        for part in parts:
            part = part.strip()
            if not activated and is_python_run_command(part):
                new_parts.append(activate_cmd)
                activated = True
            new_parts.append(part)
        return ' && '.join(new_parts)
    
    # å¤„ç†ç®€å•å‘½ä»¤
    return f"{activate_cmd} && {command}"


def execute_command_background(command: str) -> str:
    """
    This tool runs a command in the background (in the root directory of the target repository) in the shell and returns the output.
    Use this to start servers.
    Do not spawn processes using single &.

    :param command: The command to run.
    :return: The output of the command.
    """
    
    global background_process_list

    original_command = command
    command = command.removesuffix('&')
    
    # ğŸš¨ æ­¥éª¤ 0ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥é˜»æ­¢æ‰§è¡Œè¿™ä¸ªå‘½ä»¤ï¼ˆåŸºäºä¹‹å‰çš„å¤±è´¥è®°å¿†ï¼‰
    context_analyzer = get_context_analyzer()
    block_reason = context_analyzer.should_block_command(command)
    if block_reason:
        print(f"\nâ›” åå°å‘½ä»¤è¢«æ™ºèƒ½åˆ†æå™¨é˜»æ­¢: {command[:50]}...")
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ â›” åå°å‘½ä»¤å·²è¢«é˜»æ­¢æ‰§è¡Œ                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ åŸå› : {block_reason[:58]:<58} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ è¿™æ˜¯ä¸€ä¸ªç±»åº“é¡¹ç›®ï¼Œæ— æ³•ç”¨æ­¤å‘½ä»¤å¯åŠ¨ã€‚                          â•‘
â•‘ è¯·æ”¹ç”¨ dotnet test æˆ–åˆ›å»ºæµ‹è¯•ç¨‹åºæ¥å¤ç°æ¼æ´ã€‚                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    
    # ========== Python/pip å‘½ä»¤éš”ç¦»ï¼šä½¿ç”¨ venv ==========
    if is_pip_command(command):
        command = wrap_pip_command_in_venv(command)
        if command != original_command.removesuffix('&'):
            print(f"[Isolation] ğŸ”’ pip command isolated to venv")
    elif is_python_run_command(command):
        command = wrap_python_command_in_venv(command)
        if command != original_command.removesuffix('&'):
            print(f"[Isolation] ğŸ Python command will use venv")
    
    stdout_log = create_unique_logfile("stdout")
    stderr_log = create_unique_logfile("stderr")
    work_dir = get_working_directory()

    process = subprocess.Popen(
        command,
        shell=True,
        executable="/bin/bash",
        cwd=work_dir,
        stdout=open(stdout_log, "w", encoding='utf-8'),
        stderr=open(stderr_log, "w", encoding='utf-8'),
        preexec_fn=os.setsid,
        env=os.environ.copy() | env
    )

    background_process_list[process.pid]=process

    time.sleep(5)

    # Get the last 100 lines of both log files and add process info
    tail_output = get_tail_log(stdout_log, stderr_log)
    return (
        f"âœ… Background process started successfully!\n"
        f"PID: {process.pid}\n"
        f"Command: {command}\n\n"
        f"{tail_output}\n"
        f"âš ï¸ Note: Background processes may show minimal initial output.\n"
        f"Verify service is running with:\n"
        f"  - ps aux | grep <process_name>\n"
        f"  - ss -ltnp | grep :<port>\n"
        f"  - curl http://localhost:<port>\n"
    )

def cleanup_background_processes():
    global background_process_list
    global env

    env={}
    
    # é‡ç½®å‘½ä»¤æ£€æµ‹å™¨
    reset_command_detector()

    for pid in list(background_process_list.keys()):
        try:
            # Kill the entire process group
            os.killpg(os.getpgid(pid), signal.SIGTERM)
            print(f"Terminated process group for PID {pid}")
        except:
            # print(f"Process group for PID {pid} not found (already terminated?)")
            pass
        finally:
            # Remove from the list
            del background_process_list[pid]

def create_unique_logfile(suffix: str) -> str:
    """Generate a unique log file in /tmp with a specific suffix."""
    log_filename = f"/tmp/{uuid.uuid4().hex[:5]}_{suffix}.log"
    return log_filename

def get_last_lines(file_path: str, line_count: int = 100, max_chars: int = 15000):
    """
    Retrieve the last `line_count` lines from a file.
    
    ğŸ”§ ä¿®å¤ CVE-2024-3651: æ·»åŠ å­—ç¬¦æ•°é™åˆ¶é˜²æ­¢ token è¶…é™
    - line_count: æœ€å¤šè¿”å›å¤šå°‘è¡Œ
    - max_chars: æœ€å¤šè¿”å›å¤šå°‘å­—ç¬¦ï¼ˆçº¦ 3750 tokensï¼‰
    """
    try:
        with open(file_path, "r", encoding='utf-8') as file:
            r = file.readlines()
            lines = r[-line_count:]
            result = "".join(lines)
            
            # ğŸ”§ å­—ç¬¦æ•°é™åˆ¶ï¼šé˜²æ­¢è¶…é•¿è¾“å‡ºå¯¼è‡´ token è¶…é™
            if len(result) > max_chars:
                result = result[-max_chars:]
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ¢è¡Œç¬¦ï¼Œä»å®Œæ•´è¡Œå¼€å§‹
                first_newline = result.find('\n')
                if first_newline > 0:
                    result = result[first_newline + 1:]
                result = f"[... output truncated, showing last {len(result)} chars ...]\n" + result
            
            return result, len(r)
    except Exception as e:
        return f"Error reading log file: {e}", 0
    
def get_tail_log(stdout_log: str, stderr_log: str):
    last_stdout_lines, stdout_len = get_last_lines(stdout_log, 100)
    last_stderr_lines, stderr_len = get_last_lines(stderr_log, 100)
    return (
        f"LOGS for current command\n"
        f"STDOUT Log File: {stdout_log}\nLast {min(100, stdout_len)} lines out of {stdout_len}:\n{last_stdout_lines}\n\n"
        f"STDERR Log File: {stderr_log}\nLast {min(100, stderr_len)} lines out of {stderr_len}:\n{last_stderr_lines}\n"
    )
    
# @tools.tool
# def get_background_command_logs(pid: int) -> str:
#     """
#     This tool captures any pending logs from a background process's stdout and stderr.

#     :param pid: The pid of the target process.
#     :return: String with the outputs from the process.
#     """
#     print("Trying to get logs for PID: ", pid, "\nProceed? y/N")
#     p = input()
#     if p!='y':
#         return "Unable to execute, permission denied"
#     return capture_outputs(pid, 0)

# def read_from_stream(stream):
#     read = b""
#     while True:
#         data = stream.read(1)
#         if not data:
#             break
#         read += data
#     read = read.decode(errors='ignore')
#     return read

# def capture_outputs(pid: int, timeout: int):
#     if pid not in Ps:
#         return "Process not found, PID: " + str(pid) + "\n"
    
#     p = Ps[pid]
#     reads = [p.stdout.fileno(), p.stderr.fileno()]
#     ret = select.select(reads, [], [], timeout)
#     out = f"Output for process with PID: {pid}\n"
#     for fd in ret[0]:
#         if fd == p.stdout.fileno():
#             read = read_from_stream(p.stdout)
#             out+=('stdout:\n' + read + '\n')
#         if fd == p.stderr.fileno():
#             read = read_from_stream(p.stderr)
#             out+=('stderr:\n' + read + '\n')
#         out += "###\n"
#     if not ret[0]:
#         out += "No new output on stdout/stderr\n"
#     if p.poll() is None:
#         out += "status: Process is still running, you can consider waiting.\n"
#     else:
#         out += f"status: Process exited with code {p.returncode}\n"
#         del Ps[pid]
#     return out

# @tools.tool
# def send_inputs(pid: int, inp: str) -> str:
#     """
#     This tool sends an input to the stdin of the given pid if it is still running.

#     :param pid: The pid of the target process.
#     :param inp: The input to send via stdin.
#     :return: String denoting if the write was succesful or not.
#     """

#     print(f"Trying to write {inp} to {pid}...\nProceed? y/N")
#     p = input()
#     if p!='y':
#         return "Unable to execute, permission denied"
    
#     pid = int(pid)
#     if pid not in Ps:
#         return "Process not found, PID: " + str(pid) + "\n"
#     p = Ps[pid]
#     p.stdin.write(str.encode(inp))
#     p.stdin.flush()
#     return f"###Write to stdin of PID {pid} finished###\n"

# @tools.tool
# def wait(tim: int) -> str:
#     """
#     This tool waits for the given duration in seconds.
#     Can be used when you are waiting for subsequent outputs from a process.
#     Will display outputs from all running processes after the wait.

#     :param tim: Duration in seconds.
#     :return: If wait was successful.
#     """

#     print("Trying to sleep for: ", tim, "\nProceed?")
#     p = input()
#     if p!='y':
#         return "Unable to execute, permission denied"

#     time.sleep(tim)
#     outs = ""
#     for pid in list(Ps.keys()):
#         outs += capture_outputs(pid)

#     return outs