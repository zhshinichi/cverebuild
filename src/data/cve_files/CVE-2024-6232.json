{
    "CVE-2024-6232": {
        "published_date": "2024-09-03T12:29:00.102Z",
        "patch_commits": [
            {
                "url": "https://github.com/python/cpython/commit/4eaf4891c12589e3c7bdad5f5b076e4c8392dd06",
                "content": "[3.12] gh-121285: Remove backtracking when parsing tarfile headers (GH-121286) (GH-123543)\n\ngh-121285: Remove backtracking when parsing tarfile headers (GH-121286)\r\n\r\n* Remove backtracking when parsing tarfile headers\r\n* Rewrite PAX header parsing to be stricter\r\n* Optimize parsing of GNU extended sparse headers v0.0\r\n\r\n(cherry picked from commit 34ddb64d088dd7ccc321f6103d23153256caa5d4)\r\n\r\nCo-authored-by: Seth Michael Larson <seth@python.org>\r\nCo-authored-by: Kirill Podoprigora <kirill.bast9@mail.ru>\r\nCo-authored-by: Gregory P. Smith <greg@krypto.org>\n\nFilename: Lib/tarfile.py:\n```\n@@ -843,6 +843,9 @@\ndef data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n\n@@ -1412,55 +1415,76 @@\ndef _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while match := regex.match(buf, pos):\n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n+\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n \n+            pos += length\n+\n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n\n@@ -1475,7 +1499,7 @@\ndef _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n\n@@ -1497,15 +1521,24 @@\ndef _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):\n```\n\nFilename: Lib/test/test_tarfile.py:\n```\n@@ -1237,6 +1237,48 @@\ndef test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"method tar: ReadError\\('invalid header'\\)\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested\n```\n\nFilename: Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst:\n```\n@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers.\n```"
            },
            {
                "url": "https://github.com/python/cpython/commit/743acbe872485dc18df4d8ab2dc7895187f062c4",
                "content": "[3.10] gh-121285: Remove backtracking when parsing tarfile headers (GH-121286) (#123640)\n\n* Remove backtracking when parsing tarfile headers\r\n* Rewrite PAX header parsing to be stricter\r\n* Optimize parsing of GNU extended sparse headers v0.0\r\n\r\n(cherry picked from commit 34ddb64d088dd7ccc321f6103d23153256caa5d4)\r\n\r\nCo-authored-by: Kirill Podoprigora <kirill.bast9@mail.ru>\r\nCo-authored-by: Gregory P. Smith <greg@krypto.org>\n\nFilename: Lib/tarfile.py:\n```\n@@ -841,6 +841,9 @@\ndef data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n\n@@ -1410,59 +1413,76 @@\ndef _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while True:\n-            match = regex.match(buf, pos)\n-            if not match:\n-                break\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n \n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n+\n+            pos += length\n \n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n\n@@ -1477,7 +1497,7 @@\ndef _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n\n@@ -1499,15 +1519,24 @@\ndef _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):\n```\n\nFilename: Lib/test/test_tarfile.py:\n```\n@@ -1139,6 +1139,48 @@\ndef test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"method tar: ReadError\\('invalid header'\\)\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested\n```\n\nFilename: Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst:\n```\n@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers.\n```"
            },
            {
                "url": "https://github.com/python/cpython/commit/d449caf8a179e3b954268b3a88eb9170be3c8fbf",
                "content": "[3.11] gh-121285: Remove backtracking when parsing tarfile headers (GH-121286) (#123639)\n\n* Remove backtracking when parsing tarfile headers\r\n* Rewrite PAX header parsing to be stricter\r\n* Optimize parsing of GNU extended sparse headers v0.0\r\n\r\n(cherry picked from commit 34ddb64d088dd7ccc321f6103d23153256caa5d4)\r\n\r\nCo-authored-by: Kirill Podoprigora <kirill.bast9@mail.ru>\r\nCo-authored-by: Gregory P. Smith <greg@krypto.org>\n\nFilename: Lib/tarfile.py:\n```\n@@ -842,6 +842,9 @@\ndef data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n\n@@ -1411,59 +1414,76 @@\ndef _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while True:\n-            match = regex.match(buf, pos)\n-            if not match:\n-                break\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n \n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n+\n+            pos += length\n \n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n\n@@ -1478,7 +1498,7 @@\ndef _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n\n@@ -1500,15 +1520,24 @@\ndef _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):\n```\n\nFilename: Lib/test/test_tarfile.py:\n```\n@@ -1208,6 +1208,48 @@\ndef test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"method tar: ReadError\\('invalid header'\\)\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested\n```\n\nFilename: Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst:\n```\n@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers.\n```"
            },
            {
                "url": "https://github.com/python/cpython/commit/ed3a49ea734ada357ff4442996fd4ae71d253373",
                "content": "[3.13] gh-121285: Remove backtracking when parsing tarfile headers (GH-121286) (#123542)\n\ngh-121285: Remove backtracking when parsing tarfile headers (GH-121286)\r\n\r\n* Remove backtracking when parsing tarfile headers\r\n* Rewrite PAX header parsing to be stricter\r\n* Optimize parsing of GNU extended sparse headers v0.0\r\n\r\n(cherry picked from commit 34ddb64d088dd7ccc321f6103d23153256caa5d4)\r\n\r\nCo-authored-by: Seth Michael Larson <seth@python.org>\r\nCo-authored-by: Kirill Podoprigora <kirill.bast9@mail.ru>\r\nCo-authored-by: Gregory P. Smith <greg@krypto.org>\n\nFilename: Lib/tarfile.py:\n```\n@@ -846,6 +846,9 @@\ndef data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n\n@@ -1433,55 +1436,76 @@\ndef _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while match := regex.match(buf, pos):\n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n+\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n \n+            pos += length\n+\n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n\n@@ -1496,7 +1520,7 @@\ndef _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n\n@@ -1518,15 +1542,24 @@\ndef _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):\n```\n\nFilename: Lib/test/test_tarfile.py:\n```\n@@ -1268,6 +1268,48 @@\ndef test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"method tar: ReadError\\('invalid header'\\)\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested\n```\n\nFilename: Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst:\n```\n@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers.\n```"
            },
            {
                "url": "https://github.com/python/cpython/commit/7d1f50cd92ff7e10a1c15a8f591dde8a6843a64d",
                "content": "[3.8] gh-121285: Remove backtracking when parsing tarfile headers (GH-121286) (#123642)\n\n* Remove backtracking when parsing tarfile headers\r\n* Rewrite PAX header parsing to be stricter\r\n* Optimize parsing of GNU extended sparse headers v0.0\r\n\r\n(cherry picked from commit 34ddb64d088dd7ccc321f6103d23153256caa5d4)\r\n\r\nCo-authored-by: Seth Michael Larson <seth@python.org>\r\nCo-authored-by: Kirill Podoprigora <kirill.bast9@mail.ru>\r\nCo-authored-by: Gregory P. Smith <greg@krypto.org>\n\nFilename: Lib/tarfile.py:\n```\n@@ -840,6 +840,9 @@\ndef data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n\n@@ -1390,59 +1393,76 @@\ndef _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while True:\n-            match = regex.match(buf, pos)\n-            if not match:\n-                break\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n \n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n+\n+            pos += length\n \n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n\n@@ -1457,7 +1477,7 @@\ndef _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n\n@@ -1479,15 +1499,24 @@\ndef _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):\n```\n\nFilename: Lib/test/test_tarfile.py:\n```\n@@ -1047,6 +1047,48 @@\ndef test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"file could not be opened successfully\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested\n```\n\nFilename: Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst:\n```\n@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers.\n```"
            },
            {
                "url": "https://github.com/python/cpython/commit/b4225ca91547aa97ed3aca391614afbb255bc877",
                "content": "[3.9] gh-121285: Remove backtracking when parsing tarfile headers (GH-121286) (#123641)\n\n* Remove backtracking when parsing tarfile headers\r\n* Rewrite PAX header parsing to be stricter\r\n* Optimize parsing of GNU extended sparse headers v0.0\r\n\r\n(cherry picked from commit 34ddb64d088dd7ccc321f6103d23153256caa5d4)\r\n\r\nCo-authored-by: Seth Michael Larson <seth@python.org>\r\nCo-authored-by: Kirill Podoprigora <kirill.bast9@mail.ru>\r\nCo-authored-by: Gregory P. Smith <greg@krypto.org>\n\nFilename: Lib/tarfile.py:\n```\n@@ -840,6 +840,9 @@\ndef data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n\n@@ -1399,59 +1402,76 @@\ndef _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while True:\n-            match = regex.match(buf, pos)\n-            if not match:\n-                break\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n \n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n+\n+            pos += length\n \n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n\n@@ -1466,7 +1486,7 @@\ndef _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n\n@@ -1488,15 +1508,24 @@\ndef _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):\n```\n\nFilename: Lib/test/test_tarfile.py:\n```\n@@ -1113,6 +1113,48 @@\ndef test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"file could not be opened successfully\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested\n```\n\nFilename: Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst:\n```\n@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers.\n```"
            },
            {
                "url": "https://github.com/python/cpython/commit/34ddb64d088dd7ccc321f6103d23153256caa5d4",
                "content": "gh-121285: Remove backtracking when parsing tarfile headers (GH-121286)\n\n* Remove backtracking when parsing tarfile headers\r\n* Rewrite PAX header parsing to be stricter\r\n* Optimize parsing of GNU extended sparse headers v0.0\r\n\r\nCo-authored-by: Kirill Podoprigora <kirill.bast9@mail.ru>\r\nCo-authored-by: Gregory P. Smith <greg@krypto.org>\n\nFilename: Lib/tarfile.py:\n```\n@@ -845,6 +845,9 @@\ndef data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n\n@@ -1432,55 +1435,76 @@\ndef _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while match := regex.match(buf, pos):\n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n+\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n \n+            pos += length\n+\n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n\n@@ -1495,7 +1519,7 @@\ndef _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n\n@@ -1517,15 +1541,24 @@\ndef _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):\n```\n\nFilename: Lib/test/test_tarfile.py:\n```\n@@ -1261,6 +1261,48 @@\ndef test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"method tar: ReadError\\('invalid header'\\)\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested\n```\n\nFilename: Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst:\n```\n@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers.\n```"
            }
        ],
        "sw_version": "v3.8.19",
        "sw_version_wget": "https://github.com/python/cpython/archive/refs/tags/v3.8.19.zip",
        "description": "There is a MEDIUM severity vulnerability affecting CPython.\n\n\n\n\n\nRegular expressions that allowed excessive backtracking during tarfile.TarFile header parsing are vulnerable to ReDoS via specifically-crafted tar archives.",
        "sec_adv": [],
        "cwe": [
            {
                "id": "CWE-1333",
                "value": "CWE-1333 Inefficient Regular Expression Complexity"
            }
        ]
    }
}