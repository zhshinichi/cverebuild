#!/usr/bin/env python3
"""
ä¸¥æ ¼ç­›é€‰ Web CVE - è¦æ±‚å¿…é¡»åŒæ—¶å…·æœ‰:
1. patch_commits (è¡¥ä¸æäº¤é“¾æ¥)
2. sec_adv (å®‰å…¨å…¬å‘Šé“¾æ¥)  
3. sw_version_wget (è½¯ä»¶ä»“åº“/ä¸‹è½½é“¾æ¥)

ä» cvelist/2024 å’Œ 2025 ç›®å½•æ£€ç´¢
"""

import json
import os
import re
from pathlib import Path
from typing import Optional
from openai import OpenAI

# API é…ç½®
API_KEY = "sk-ziyWDSRgl3ymsBm3MWN8C5fPJwrzxaakqdsCYsWIB0dTqHmg"
BASE_URL = "https://api.openai-hub.com/v1"

# ç›®æ ‡æ•°é‡
TARGET_COUNT = 200

# è·¯å¾„é…ç½®
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR.parent
CVELIST_DIR = DATA_DIR / "cvelist"
OUTPUT_FILE = DATA_DIR / "large_scale" / "webdata.json"


def extract_patch_commits(cve_data: dict) -> list:
    """
    æå– patch commit é“¾æ¥
    
    æ¥æº:
    - references ä¸­å¸¦æœ‰ tags: ["patch"] çš„ URL
    - URL åŒ…å« /commit/ æˆ– /commits/ çš„ GitHub é“¾æ¥
    """
    patch_commits = []
    
    # ä» cna.references æå–
    cna = cve_data.get("containers", {}).get("cna", {})
    references = cna.get("references", [])
    
    for ref in references:
        url = ref.get("url", "")
        tags = ref.get("tags", [])
        
        # æ˜ç¡®æ ‡è®°ä¸º patch çš„
        if "patch" in tags:
            if url and url not in patch_commits:
                patch_commits.append(url)
            continue
        
        # GitHub commit é“¾æ¥
        if re.search(r'github\.com/[^/]+/[^/]+/commit/[a-f0-9]+', url):
            if url not in patch_commits:
                patch_commits.append(url)
        
        # GitLab commit é“¾æ¥
        if re.search(r'gitlab\.[^/]+/[^/]+/[^/]+/-/commit/[a-f0-9]+', url):
            if url not in patch_commits:
                patch_commits.append(url)
    
    # ä» adp å®¹å™¨æå–
    for adp in cve_data.get("containers", {}).get("adp", []):
        for ref in adp.get("references", []):
            url = ref.get("url", "")
            tags = ref.get("tags", [])
            
            if "patch" in tags or "x_transferred" not in tags:
                if re.search(r'github\.com/[^/]+/[^/]+/commit/[a-f0-9]+', url):
                    if url not in patch_commits:
                        patch_commits.append(url)
    
    return patch_commits


def extract_security_advisory(cve_data: dict) -> list:
    """
    æå– security advisory é“¾æ¥
    
    æ¥æº:
    - references ä¸­å¸¦æœ‰ tags: ["vendor-advisory"] çš„ URL
    - references ä¸­å¸¦æœ‰ tags: ["issue-tracking"] çš„ URL
    - URL åŒ…å« advisory, secadv, security-announce ç­‰å…³é”®è¯
    - GitHub Security Advisory é“¾æ¥
    """
    sec_advs = []
    
    # å…³é”®è¯æ¨¡å¼
    advisory_patterns = [
        r'advisory',
        r'secadv',
        r'security-announce',
        r'security/advisories',
        r'GHSA-',  # GitHub Security Advisory
        r'/security/',
        r'CVE-\d{4}-\d+',  # åŒ…å« CVE ID çš„å…¬å‘Šé“¾æ¥
    ]
    
    cna = cve_data.get("containers", {}).get("cna", {})
    references = cna.get("references", [])
    
    for ref in references:
        url = ref.get("url", "")
        tags = ref.get("tags", [])
        
        # æ˜ç¡®æ ‡è®°ä¸º vendor-advisory æˆ– issue-tracking
        if "vendor-advisory" in tags or "issue-tracking" in tags:
            if url and url not in sec_advs:
                sec_advs.append(url)
            continue
        
        # é€šè¿‡ URL æ¨¡å¼è¯†åˆ«
        for pattern in advisory_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                if url not in sec_advs:
                    sec_advs.append(url)
                break
    
    # ä» adp å®¹å™¨æå–
    for adp in cve_data.get("containers", {}).get("adp", []):
        for ref in adp.get("references", []):
            url = ref.get("url", "")
            tags = ref.get("tags", [])
            
            if "vendor-advisory" in tags or "issue-tracking" in tags:
                if url and url not in sec_advs:
                    sec_advs.append(url)
    
    return sec_advs


def extract_sw_version_wget(cve_data: dict) -> list:
    """
    æå–è½¯ä»¶ä»“åº“/ç‰ˆæœ¬ä¸‹è½½é“¾æ¥
    
    æ¥æº:
    - affected[].repo å­—æ®µ
    - GitHub/GitLab ä»“åº“ä¸»é¡µé“¾æ¥
    - Release/download é“¾æ¥
    - pypi, npm, maven ç­‰åŒ…ç®¡ç†å™¨é“¾æ¥
    """
    sw_links = []
    
    cna = cve_data.get("containers", {}).get("cna", {})
    
    # ä» affected.repo æå–
    for affected in cna.get("affected", []):
        repo = affected.get("repo", "")
        if repo and repo not in sw_links:
            sw_links.append(repo)
    
    # ä» references æå–ä»“åº“é“¾æ¥
    references = cna.get("references", [])
    
    repo_patterns = [
        r'github\.com/[^/]+/[^/]+/?$',  # GitHub ä»“åº“ä¸»é¡µ
        r'github\.com/[^/]+/[^/]+/releases',  # GitHub releases
        r'github\.com/[^/]+/[^/]+/archive',  # GitHub archive
        r'gitlab\.[^/]+/[^/]+/[^/]+/?$',  # GitLab ä»“åº“
        r'pypi\.org/project/',  # PyPI
        r'npmjs\.com/package/',  # npm
        r'packagist\.org/packages/',  # Composer/PHP
        r'rubygems\.org/gems/',  # Ruby Gems
        r'crates\.io/crates/',  # Rust crates
        r'mvnrepository\.com/',  # Maven
    ]
    
    for ref in references:
        url = ref.get("url", "")
        
        for pattern in repo_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                # æå–ä»“åº“åŸºç¡€ URL
                if 'github.com' in url:
                    # æå– github.com/owner/repo éƒ¨åˆ†
                    match = re.search(r'(https?://github\.com/[^/]+/[^/]+)', url)
                    if match:
                        base_url = match.group(1)
                        if base_url not in sw_links:
                            sw_links.append(base_url)
                elif url not in sw_links:
                    sw_links.append(url)
                break
    
    return sw_links


def extract_versions(cve_data: dict) -> list:
    """
    æå–å—å½±å“çš„ç‰ˆæœ¬ä¿¡æ¯
    """
    versions = []
    
    cna = cve_data.get("containers", {}).get("cna", {})
    
    for affected in cna.get("affected", []):
        for version in affected.get("versions", []):
            ver_str = version.get("version", "")
            if ver_str and ver_str not in versions:
                versions.append(ver_str)
            
            less_than = version.get("lessThan", "")
            if less_than and less_than not in versions:
                versions.append(less_than)
    
    return versions


def extract_cwe(cve_data: dict) -> list:
    """
    æå– CWE ä¿¡æ¯
    """
    cwes = []
    
    cna = cve_data.get("containers", {}).get("cna", {})
    
    for problem_type in cna.get("problemTypes", []):
        for desc in problem_type.get("descriptions", []):
            cwe_id = desc.get("cweId", "")
            if cwe_id and cwe_id not in cwes:
                cwes.append(cwe_id)
    
    return cwes


def is_web_related_rule(cve_data: dict) -> tuple:
    """
    è§„åˆ™åˆ¤æ–­æ˜¯å¦ä¸º Web ç›¸å…³æ¼æ´
    
    Returns:
        (is_web, score, reason)
    """
    cna = cve_data.get("containers", {}).get("cna", {})
    
    # è·å–æè¿°
    descriptions = cna.get("descriptions", [])
    desc_text = ""
    for desc in descriptions:
        if desc.get("lang", "").startswith("en"):
            desc_text = desc.get("value", "")
            break
    if not desc_text and descriptions:
        desc_text = descriptions[0].get("value", "")
    
    desc_lower = desc_text.lower()
    
    # è·å–äº§å“åç§°
    products = []
    for affected in cna.get("affected", []):
        products.append(affected.get("product", "").lower())
        products.append(affected.get("vendor", "").lower())
    
    products_text = " ".join(products)
    
    # æ’é™¤æ¡ä»¶ - å•†ä¸šè½¯ä»¶/ç¡¬ä»¶
    exclude_keywords = [
        'cisco', 'juniper', 'fortinet', 'palo alto', 'checkpoint',
        'microsoft windows', 'windows server', 'microsoft office',
        'oracle database', 'sap', 'ibm', 'vmware', 'citrix',
        'android', 'ios', 'macos', 'firmware', 'bios', 'uefi',
        'router', 'switch', 'firewall', 'camera', 'printer', 'scanner',
        'nvidia driver', 'amd driver', 'intel driver',
        'antivirus', 'endpoint protection', 'mcafee', 'symantec', 'kaspersky',
        'adobe acrobat', 'adobe reader',
    ]
    
    for keyword in exclude_keywords:
        if keyword in desc_lower or keyword in products_text:
            return (False, 0, f"æ’é™¤: {keyword}")
    
    # Web ç›¸å…³å…³é”®è¯è¯„åˆ†
    score = 0
    matched = []
    
    # é«˜åˆ†å…³é”®è¯ (Web æ ¸å¿ƒæŠ€æœ¯)
    high_score_keywords = {
        'xss': 5, 'cross-site scripting': 5, 'cross site scripting': 5,
        'sql injection': 5, 'sqli': 5,
        'csrf': 5, 'cross-site request forgery': 5,
        'ssrf': 5, 'server-side request forgery': 5,
        'rce': 4, 'remote code execution': 4,
        'command injection': 4,
        'path traversal': 4, 'directory traversal': 4,
        'local file inclusion': 4, 'lfi': 4,
        'remote file inclusion': 4, 'rfi': 4,
        'authentication bypass': 4,
        'authorization bypass': 4,
        'privilege escalation': 3,
        'insecure deserialization': 4,
        'xml external entity': 4, 'xxe': 4,
        'open redirect': 3,
        'clickjacking': 3,
        'session fixation': 3,
        'session hijacking': 3,
    }
    
    # ä¸­åˆ†å…³é”®è¯ (Web æŠ€æœ¯æ ˆ)
    medium_score_keywords = {
        'web application': 3, 'webapp': 3, 'web app': 3,
        'http': 2, 'https': 2,
        'rest api': 3, 'restful': 3, 'api endpoint': 3,
        'graphql': 3,
        'json': 2, 'xml': 2,
        'html': 2, 'javascript': 2, 'css': 2,
        'php': 2, 'python': 2, 'node.js': 2, 'nodejs': 2,
        'ruby': 2, 'rails': 2, 'django': 3, 'flask': 3,
        'express': 2, 'fastapi': 3,
        'spring': 2, 'spring boot': 3,
        'laravel': 3, 'symfony': 3,
        'react': 2, 'vue': 2, 'angular': 2,
        'nginx': 2, 'apache': 2, 'tomcat': 2,
        'wordpress': 3, 'drupal': 3, 'joomla': 3,
        'magento': 3, 'prestashop': 3, 'opencart': 3,
        'cms': 2, 'content management': 2,
        'e-commerce': 2, 'ecommerce': 2, 'online store': 2,
        'login': 2, 'authentication': 2, 'oauth': 3, 'jwt': 3,
        'cookie': 2, 'session': 2,
        'upload': 2, 'file upload': 3,
        'form': 1, 'input': 1, 'parameter': 1,
        'database': 2, 'mysql': 2, 'postgresql': 2, 'mongodb': 2,
        'redis': 2, 'memcached': 2,
    }
    
    # äº§å“ç±»å‹å…³é”®è¯
    product_keywords = {
        'plugin': 2, 'extension': 2, 'addon': 2, 'module': 2,
        'theme': 1, 'template': 1,
        'dashboard': 2, 'admin panel': 3, 'control panel': 2,
        'portal': 2, 'intranet': 2,
        'blog': 2, 'forum': 2, 'wiki': 2,
        'crm': 2, 'erp': 2, 'hrm': 2,
        'booking': 2, 'reservation': 2,
        'payment': 2, 'checkout': 2,
        'newsletter': 2, 'mailing': 2,
        'contact form': 2, 'feedback': 1,
    }
    
    # è®¡ç®—åˆ†æ•°
    all_text = desc_lower + " " + products_text
    
    for keyword, points in high_score_keywords.items():
        if keyword in all_text:
            score += points
            matched.append(f"{keyword}(+{points})")
    
    for keyword, points in medium_score_keywords.items():
        if keyword in all_text:
            score += points
            matched.append(f"{keyword}(+{points})")
    
    for keyword, points in product_keywords.items():
        if keyword in all_text:
            score += points
            matched.append(f"{keyword}(+{points})")
    
    return (score >= 5, score, ", ".join(matched[:5]))


def use_llm_verify(client: OpenAI, cve_data: dict, cve_id: str) -> bool:
    """
    ä½¿ç”¨ LLM éªŒè¯æ˜¯å¦ä¸º Web ç›¸å…³æ¼æ´
    """
    cna = cve_data.get("containers", {}).get("cna", {})
    
    # è·å–æè¿°
    descriptions = cna.get("descriptions", [])
    desc_text = ""
    for desc in descriptions:
        if desc.get("lang", "").startswith("en"):
            desc_text = desc.get("value", "")
            break
    if not desc_text and descriptions:
        desc_text = descriptions[0].get("value", "")
    
    # è·å–äº§å“ä¿¡æ¯
    products = []
    for affected in cna.get("affected", []):
        products.append(f"{affected.get('vendor', '')} {affected.get('product', '')}")
    
    prompt = f"""åˆ¤æ–­è¿™ä¸ª CVE æ˜¯å¦æ˜¯ Web ç›¸å…³æ¼æ´ã€‚

CVE ID: {cve_id}
äº§å“: {', '.join(products)}
æè¿°: {desc_text[:500]}

Web ç›¸å…³æ¼æ´çš„å®šä¹‰:
1. å½±å“ Web åº”ç”¨ç¨‹åºã€Web æ¡†æ¶ã€CMSã€Web æœåŠ¡å™¨ç­‰
2. æ¶‰åŠ HTTP/HTTPS åè®®ã€Web APIã€æµè§ˆå™¨ç­‰
3. æ¼æ´ç±»å‹åŒ…æ‹¬: XSS, SQLæ³¨å…¥, CSRF, SSRF, RCE, è®¤è¯ç»•è¿‡ç­‰
4. å¿…é¡»æ˜¯å¼€æºè½¯ä»¶æˆ–æœ‰å…¬å¼€ä»“åº“çš„è½¯ä»¶

æ’é™¤æ¡ä»¶:
- å•†ä¸šè½¯ä»¶ (Microsoft, Oracle, SAP, IBM, Cisco ç­‰)
- ç¡¬ä»¶è®¾å¤‡ (è·¯ç”±å™¨, é˜²ç«å¢™, æ‘„åƒå¤´ç­‰)
- ç§»åŠ¨æ“ä½œç³»ç»Ÿ (Android, iOS)
- æ¡Œé¢è½¯ä»¶ (é Web ç›¸å…³)

åªå›ç­” YES æˆ– NO"""

    try:
        response = client.chat.completions.create(
            model="gpt-5",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=10,
            temperature=0
        )
        answer = response.choices[0].message.content.strip().upper()
        return "YES" in answer
    except Exception as e:
        print(f"    âš ï¸ LLM é”™è¯¯: {e}")
        return False


def convert_to_output_format(cve_data: dict, cve_id: str, 
                              patch_commits: list, sec_advs: list, 
                              sw_versions: list) -> dict:
    """
    è½¬æ¢ä¸ºè¾“å‡ºæ ¼å¼
    """
    cna = cve_data.get("containers", {}).get("cna", {})
    metadata = cve_data.get("cveMetadata", {})
    
    # è·å–æè¿°
    descriptions = cna.get("descriptions", [])
    desc_text = ""
    for desc in descriptions:
        if desc.get("lang", "").startswith("en"):
            desc_text = desc.get("value", "")
            break
    if not desc_text and descriptions:
        desc_text = descriptions[0].get("value", "")
    
    # è·å–ç‰ˆæœ¬
    versions = extract_versions(cve_data)
    
    # è·å– CWE
    cwes = extract_cwe(cve_data)
    
    return {
        "cve_id": cve_id,
        "published_date": metadata.get("datePublished", ""),
        "patch_commits": patch_commits,
        "sw_version": versions,
        "sw_version_wget": sw_versions,
        "description": desc_text,
        "sec_adv": sec_advs,
        "cwe": cwes
    }


def scan_cve_files():
    """
    æ‰«ææ‰€æœ‰ CVE æ–‡ä»¶
    """
    cve_files = []
    
    for year in ["2024", "2025"]:
        year_dir = CVELIST_DIR / year
        if not year_dir.exists():
            continue
        
        for subdir in sorted(year_dir.iterdir()):
            if not subdir.is_dir():
                continue
            
            for json_file in sorted(subdir.glob("CVE-*.json")):
                cve_files.append(json_file)
    
    return cve_files


def main():
    print("=" * 60)
    print("ä¸¥æ ¼ Web CVE ç­›é€‰å™¨")
    print("è¦æ±‚: patch_commits + sec_adv + sw_version_wget éƒ½å¿…é¡»æœ‰")
    print("=" * 60)
    print()
    
    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    print("[1/4] åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    # æµ‹è¯•è¿æ¥
    try:
        client.models.list()
        print("  âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"  âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    print()
    print(f"[2/4] æ‰«æ CVE æ–‡ä»¶ (ç›®æ ‡: {TARGET_COUNT} ä¸ª)...")
    
    cve_files = scan_cve_files()
    print(f"  æ‰¾åˆ° {len(cve_files)} ä¸ª CVE æ–‡ä»¶")
    
    selected_cves = []
    stats = {
        "total_scanned": 0,
        "has_all_fields": 0,
        "rule_passed": 0,
        "llm_verified": 0,
    }
    
    for json_file in cve_files:
        if len(selected_cves) >= TARGET_COUNT:
            break
        
        stats["total_scanned"] += 1
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                cve_data = json.load(f)
        except Exception as e:
            continue
        
        cve_id = cve_data.get("cveMetadata", {}).get("cveId", "")
        if not cve_id:
            continue
        
        # æå–ä¸‰ä¸ªå…³é”®å­—æ®µ
        patch_commits = extract_patch_commits(cve_data)
        sec_advs = extract_security_advisory(cve_data)
        sw_versions = extract_sw_version_wget(cve_data)
        
        # ä¸¥æ ¼è¦æ±‚: ä¸‰ä¸ªå­—æ®µéƒ½å¿…é¡»æœ‰
        if not patch_commits or not sec_advs or not sw_versions:
            continue
        
        stats["has_all_fields"] += 1
        
        # è§„åˆ™åˆ¤æ–­æ˜¯å¦ Web ç›¸å…³
        is_web, score, reason = is_web_related_rule(cve_data)
        
        if not is_web:
            # å¦‚æœè§„åˆ™ä¸é€šè¿‡ä½†åˆ†æ•° > 3ï¼Œä½¿ç”¨ LLM éªŒè¯
            if score >= 3:
                stats["rule_passed"] += 1
                if not use_llm_verify(client, cve_data, cve_id):
                    continue
                stats["llm_verified"] += 1
            else:
                continue
        else:
            stats["rule_passed"] += 1
            stats["llm_verified"] += 1
        
        # è½¬æ¢ä¸ºè¾“å‡ºæ ¼å¼
        cve_entry = convert_to_output_format(
            cve_data, cve_id, patch_commits, sec_advs, sw_versions
        )
        
        selected_cves.append(cve_entry)
        
        print(f"  âœ… [{len(selected_cves)}/{TARGET_COUNT}] {cve_id}")
        print(f"      patch: {len(patch_commits)}, adv: {len(sec_advs)}, repo: {len(sw_versions)}")
        
        # è¿›åº¦æŠ¥å‘Š
        if stats["total_scanned"] % 1000 == 0:
            print(f"  ğŸ“Š è¿›åº¦: æ‰«æ {stats['total_scanned']}, "
                  f"æœ‰å­—æ®µ {stats['has_all_fields']}, "
                  f"å·²é€‰ {len(selected_cves)}")
    
    print()
    print("[3/4] ç­›é€‰å®Œæˆ")
    print(f"  - æ€»æ‰«æ: {stats['total_scanned']}")
    print(f"  - æœ‰å…¨éƒ¨å­—æ®µ: {stats['has_all_fields']}")
    print(f"  - è§„åˆ™é€šè¿‡: {stats['rule_passed']}")
    print(f"  - æœ€ç»ˆé€‰æ‹©: {len(selected_cves)}")
    
    # ä¿å­˜ç»“æœ
    print()
    print(f"[4/4] ä¿å­˜åˆ° {OUTPUT_FILE}...")
    
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(selected_cves, f, indent=2, ensure_ascii=False)
    
    print()
    print("âœ… å®Œæˆï¼")
    print(f"   è¾“å‡º: {OUTPUT_FILE}")
    print()
    
    # ç»Ÿè®¡å­—æ®µå¡«å……ç‡
    print("  å­—æ®µå¡«å……ç»Ÿè®¡:")
    fields = ["description", "patch_commits", "sec_adv", "sw_version_wget", "cwe"]
    for field in fields:
        count = sum(1 for cve in selected_cves if cve.get(field))
        print(f"  - {field}: {count}/{len(selected_cves)}")


if __name__ == "__main__":
    main()
