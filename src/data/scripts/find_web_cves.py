#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä» cvelist/2024 å’Œ cvelist/2025 ä¸­ç­›é€‰ Web ç›¸å…³æ¼æ´
æ¡ä»¶ï¼š
1. æœ‰ GitHub å…¬å¼€ä»“åº“æˆ–å…¶ä»–å…¬å¼€å†…å®¹
2. Web/æµè§ˆå™¨ç›¸å…³
3. éå•†ä¸šè½¯ä»¶
4. éç¡¬ä»¶ç›¸å…³
5. æ‰¾åˆ° 200 ä¸ªå°±åœæ­¢
"""

import json
import os
import re
import random
from pathlib import Path
from typing import Dict, Any, List, Optional, Generator
from openai import OpenAI

# é…ç½®
BASE_DIR = Path(__file__).parent.parent
CVELIST_DIR = BASE_DIR / "cvelist"
OUTPUT_FILE = BASE_DIR / "large_scale" / "webdata.json"

# OpenAI é…ç½®
OPENAI_API_KEY = "sk-ziyWDSRgl3ymsBm3MWN8C5fPJwrzxaakqdsCYsWIB0dTqHmg"
OPENAI_API_BASE = "https://api.openai-hub.com/v1"

# ç›®æ ‡æ•°é‡
TARGET_COUNT = 200

# å•†ä¸šè½¯ä»¶å…³é”®è¯ï¼ˆæ’é™¤ï¼‰
COMMERCIAL_KEYWORDS = [
    'sap', 'oracle', 'microsoft', 'adobe', 'ibm', 'cisco', 'vmware', 
    'fortinet', 'paloalto', 'juniper', 'f5', 'citrix', 'salesforce',
    'workday', 'servicenow', 'splunk', 'tableau', 'qlik', 'informatica',
    'teradata', 'snowflake', 'databricks', 'cloudera', 'hortonworks',
    'enterprise', 'commercial', 'proprietary', 'licensed'
]

# ç¡¬ä»¶ç›¸å…³å…³é”®è¯ï¼ˆæ’é™¤ï¼‰
HARDWARE_KEYWORDS = [
    'firmware', 'bios', 'uefi', 'driver', 'kernel', 'embedded',
    'router', 'switch', 'firewall', 'iot', 'plc', 'scada',
    'camera', 'printer', 'scanner', 'nas', 'san', 'ups',
    'hardware', 'device', 'chip', 'cpu', 'gpu', 'memory'
]

# Web ç›¸å…³å…³é”®è¯ï¼ˆåŒ…å«ï¼‰
WEB_KEYWORDS = [
    'xss', 'cross-site', 'csrf', 'ssrf', 'sql injection', 'sqli',
    'path traversal', 'directory traversal', 'lfi', 'rfi',
    'authentication bypass', 'authorization bypass', 'middleware',
    'http', 'https', 'web', 'browser', 'cookie', 'session', 'jwt',
    'api', 'rest', 'graphql', 'json', 'xml', 'html', 'javascript',
    'php', 'python', 'node', 'express', 'django', 'flask', 'rails',
    'react', 'vue', 'angular', 'next.js', 'nuxt', 'laravel', 'symfony',
    'wordpress', 'drupal', 'joomla', 'magento', 'shopify',
    'upload', 'download', 'redirect', 'open redirect', 'injection',
    'deserialization', 'prototype pollution', 'template injection',
    'server-side', 'client-side', 'frontend', 'backend'
]


def iter_cve_files(years: List[int]) -> Generator[Path, None, None]:
    """éå†æŒ‡å®šå¹´ä»½çš„æ‰€æœ‰ CVE æ–‡ä»¶"""
    for year in years:
        year_dir = CVELIST_DIR / str(year)
        if not year_dir.exists():
            print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {year_dir}")
            continue
        
        # éå†å­ç›®å½• (0xxx, 1xxx, ..., 99xxx)
        for subdir in sorted(year_dir.iterdir()):
            if subdir.is_dir() and subdir.name.endswith('xxx'):
                for cve_file in sorted(subdir.glob('CVE-*.json')):
                    yield cve_file


def extract_urls(cve_data: Dict) -> List[str]:
    """æå–æ‰€æœ‰ URL"""
    urls = []
    try:
        cna = cve_data.get("containers", {}).get("cna", {})
        for ref in cna.get("references", []):
            url = ref.get("url", "")
            if url:
                urls.append(url)
        
        for adp in cve_data.get("containers", {}).get("adp", []):
            for ref in adp.get("references", []):
                url = ref.get("url", "")
                if url:
                    urls.append(url)
    except:
        pass
    return urls


def extract_description(cve_data: Dict) -> str:
    """æå–æè¿°"""
    try:
        cna = cve_data.get("containers", {}).get("cna", {})
        for desc in cna.get("descriptions", []):
            if desc.get("lang") == "en":
                return desc.get("value", "")
        if cna.get("descriptions"):
            return cna["descriptions"][0].get("value", "")
    except:
        pass
    return ""


def extract_affected(cve_data: Dict) -> Dict:
    """æå–å—å½±å“çš„è½¯ä»¶ä¿¡æ¯"""
    try:
        cna = cve_data.get("containers", {}).get("cna", {})
        affected = cna.get("affected", [])
        if affected:
            first = affected[0]
            return {
                "vendor": first.get("vendor", ""),
                "product": first.get("product", ""),
                "versions": first.get("versions", [])
            }
    except:
        pass
    return {}


def extract_cwe(cve_data: Dict) -> List[Dict]:
    """æå– CWE"""
    cwes = []
    try:
        cna = cve_data.get("containers", {}).get("cna", {})
        for pt in cna.get("problemTypes", []):
            for desc in pt.get("descriptions", []):
                cwe_id = desc.get("cweId", "")
                cwe_desc = desc.get("description", "")
                if cwe_id:
                    cwes.append({
                        "id": cwe_id,
                        "value": f"{cwe_id}: {cwe_desc}"
                    })
    except:
        pass
    return cwes


def extract_published_date(cve_data: Dict) -> str:
    """æå–å‘å¸ƒæ—¥æœŸ"""
    return cve_data.get("cveMetadata", {}).get("datePublished", "")


def rule_based_filter(cve_data: Dict, description: str, urls: List[str], affected: Dict) -> Dict:
    """åŸºäºè§„åˆ™çš„åˆæ­¥ç­›é€‰"""
    result = {
        "has_github": False,
        "has_public_repo": False,
        "is_web_related": False,
        "is_commercial": False,
        "is_hardware": False,
        "github_info": {},
        "score": 0
    }
    
    desc_lower = description.lower()
    vendor_lower = affected.get("vendor", "").lower()
    product_lower = affected.get("product", "").lower()
    combined_text = f"{desc_lower} {vendor_lower} {product_lower}"
    
    # æ£€æŸ¥æ˜¯å¦å•†ä¸šè½¯ä»¶
    for kw in COMMERCIAL_KEYWORDS:
        if kw in combined_text:
            result["is_commercial"] = True
            break
    
    # æ£€æŸ¥æ˜¯å¦ç¡¬ä»¶ç›¸å…³
    for kw in HARDWARE_KEYWORDS:
        if kw in combined_text:
            result["is_hardware"] = True
            break
    
    # æ£€æŸ¥æ˜¯å¦ Web ç›¸å…³
    for kw in WEB_KEYWORDS:
        if kw in combined_text:
            result["is_web_related"] = True
            result["score"] += 1
    
    # æ£€æŸ¥ URL
    for url in urls:
        url_lower = url.lower()
        
        # GitHub
        if "github.com" in url_lower:
            result["has_github"] = True
            result["has_public_repo"] = True
            result["score"] += 2
            
            # æå– GitHub ä¿¡æ¯
            commit_match = re.search(r'github\.com/([^/]+)/([^/]+)/commit/([a-f0-9]+)', url)
            if commit_match:
                result["github_info"]["owner"] = commit_match.group(1)
                result["github_info"]["repo"] = commit_match.group(2)
                result["github_info"]["commit_url"] = url
                result["score"] += 3
            
            advisory_match = re.search(r'github\.com/([^/]+)/([^/]+)/security/advisories/(GHSA-[a-z0-9-]+)', url)
            if advisory_match:
                result["github_info"]["owner"] = advisory_match.group(1)
                result["github_info"]["repo"] = advisory_match.group(2)
                result["github_info"]["advisory_url"] = url
                result["github_info"]["ghsa_id"] = advisory_match.group(3)
                result["score"] += 3
            
            release_match = re.search(r'github\.com/([^/]+)/([^/]+)/releases/tag/([^/]+)', url)
            if release_match:
                result["github_info"]["owner"] = release_match.group(1)
                result["github_info"]["repo"] = release_match.group(2)
                result["github_info"]["tag"] = release_match.group(3)
                result["score"] += 1
        
        # GitLab
        elif "gitlab.com" in url_lower:
            result["has_public_repo"] = True
            result["score"] += 2
        
        # å…¶ä»–å…¬å¼€ä»“åº“
        elif any(x in url_lower for x in ["bitbucket.org", "sourceforge.net", "codeberg.org"]):
            result["has_public_repo"] = True
            result["score"] += 1
    
    return result


def llm_verify(client: OpenAI, cve_id: str, description: str, affected: Dict, urls: List[str]) -> bool:
    """ä½¿ç”¨ LLM éªŒè¯æ˜¯å¦ç¬¦åˆæ¡ä»¶"""
    prompt = f"""åˆ¤æ–­è¿™ä¸ª CVE æ˜¯å¦ç¬¦åˆä»¥ä¸‹æ‰€æœ‰æ¡ä»¶ï¼š
1. æ˜¯ Web/æµè§ˆå™¨/ç½‘é¡µç›¸å…³çš„æ¼æ´ï¼ˆå¦‚ XSS, CSRF, SQLæ³¨å…¥, è®¤è¯ç»•è¿‡ç­‰ï¼‰
2. ä¸æ˜¯å•†ä¸šè½¯ä»¶ï¼ˆå¦‚ SAP, Oracle, Microsoft, Adobe ç­‰ï¼‰
3. ä¸æ˜¯ç¡¬ä»¶/å›ºä»¶ç›¸å…³
4. æœ‰å…¬å¼€çš„ä»£ç ä»“åº“æˆ–æŠ€æœ¯ç»†èŠ‚

CVE ID: {cve_id}
è½¯ä»¶: {affected.get('vendor', 'N/A')} - {affected.get('product', 'N/A')}
æè¿°: {description[:500]}
ç›¸å…³é“¾æ¥: {', '.join(urls[:5])}

åªå›ç­” YES æˆ– NOï¼Œä¸éœ€è¦è§£é‡Šã€‚"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=10,
            temperature=0
        )
        answer = response.choices[0].message.content.strip().upper()
        return "YES" in answer
    except Exception as e:
        print(f"    âš ï¸ LLM error: {e}")
        return False


def format_cve_data(cve_id: str, cve_raw: Dict, rule_result: Dict) -> Dict:
    """æ ¼å¼åŒ– CVE æ•°æ®ä¸ºç›®æ ‡æ ¼å¼"""
    github_info = rule_result.get("github_info", {})
    
    # patch_commits
    patch_commits = []
    if "commit_url" in github_info:
        patch_commits.append({
            "url": github_info["commit_url"],
            "content": ""
        })
    
    # sec_adv
    sec_adv = []
    if "advisory_url" in github_info:
        sec_adv.append({
            "url": github_info["advisory_url"],
            "content": "",
            "effective": False,
            "effective_reason": ""
        })
    
    # sw_version_wget
    sw_version_wget = ""
    affected = extract_affected(cve_raw)
    if github_info.get("owner") and github_info.get("repo"):
        versions = affected.get("versions", [])
        for v in versions:
            if v.get("status") == "affected":
                version_str = v.get("version", "")
                version_match = re.search(r'[vV]?(\d+\.\d+(?:\.\d+)?)', version_str)
                if version_match:
                    sw_version_wget = f"https://github.com/{github_info['owner']}/{github_info['repo']}/archive/refs/tags/{version_match.group(0)}.zip"
                    break
    
    # sw_version
    sw_version = ""
    versions = affected.get("versions", [])
    for v in versions:
        if v.get("status") == "affected":
            sw_version = v.get("version", "")
            break
    
    return {
        "published_date": extract_published_date(cve_raw),
        "patch_commits": patch_commits,
        "sw_version": sw_version,
        "sw_version_wget": sw_version_wget,
        "description": extract_description(cve_raw),
        "sec_adv": sec_adv,
        "cwe": extract_cwe(cve_raw)
    }


def main():
    print("=" * 60)
    print("Web CVE ç­›é€‰å™¨ (è§„åˆ™ + LLM)")
    print("=" * 60)
    
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    print("\n[1/4] åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
    client = OpenAI(
        api_key=OPENAI_API_KEY,
        base_url=OPENAI_API_BASE
    )
    print("  âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    
    # ç»Ÿè®¡
    total_scanned = 0
    rule_passed = 0
    llm_verified = 0
    selected_cves = {}
    
    print(f"\n[2/4] æ‰«æ CVE æ–‡ä»¶ (ç›®æ ‡: {TARGET_COUNT} ä¸ª)...")
    print("  æ‰«æ 2024 å’Œ 2025 å¹´çš„ CVE...")
    
    # éå†æ‰€æœ‰ CVE æ–‡ä»¶
    for cve_file in iter_cve_files([2024, 2025]):
        if len(selected_cves) >= TARGET_COUNT:
            break
        
        total_scanned += 1
        
        if total_scanned % 1000 == 0:
            print(f"  ğŸ“Š è¿›åº¦: æ‰«æ {total_scanned}, è§„åˆ™é€šè¿‡ {rule_passed}, LLMéªŒè¯ {llm_verified}, å·²é€‰ {len(selected_cves)}")
        
        try:
            with open(cve_file, "r", encoding="utf-8") as f:
                cve_data = json.load(f)
            
            cve_id = cve_data.get("cveMetadata", {}).get("cveId", "")
            if not cve_id:
                continue
            
            # æå–ä¿¡æ¯
            description = extract_description(cve_data)
            urls = extract_urls(cve_data)
            affected = extract_affected(cve_data)
            
            # è·³è¿‡æ²¡æœ‰æè¿°çš„
            if not description or len(description) < 50:
                continue
            
            # è§„åˆ™ç­›é€‰
            rule_result = rule_based_filter(cve_data, description, urls, affected)
            
            # å¿…é¡»æœ‰å…¬å¼€ä»“åº“
            if not rule_result["has_public_repo"]:
                continue
            
            # æ’é™¤å•†ä¸šè½¯ä»¶å’Œç¡¬ä»¶
            if rule_result["is_commercial"] or rule_result["is_hardware"]:
                continue
            
            # å¿…é¡» Web ç›¸å…³
            if not rule_result["is_web_related"]:
                continue
            
            # è§„åˆ™é€šè¿‡
            rule_passed += 1
            
            # é«˜åˆ†ç›´æ¥é€šè¿‡ï¼Œä½åˆ†ç”¨ LLM éªŒè¯
            if rule_result["score"] >= 5:
                llm_verified += 1
                selected_cves[cve_id] = format_cve_data(cve_id, cve_data, rule_result)
                print(f"  âœ… [{len(selected_cves)}/{TARGET_COUNT}] {cve_id} (é«˜åˆ†é€šè¿‡: {rule_result['score']})")
            elif rule_result["score"] >= 2:
                # LLM éªŒè¯
                if llm_verify(client, cve_id, description, affected, urls):
                    llm_verified += 1
                    selected_cves[cve_id] = format_cve_data(cve_id, cve_data, rule_result)
                    print(f"  âœ… [{len(selected_cves)}/{TARGET_COUNT}] {cve_id} (LLMéªŒè¯é€šè¿‡)")
        
        except Exception as e:
            continue
    
    print(f"\n[3/4] ç­›é€‰å®Œæˆ")
    print(f"  - æ€»æ‰«æ: {total_scanned}")
    print(f"  - è§„åˆ™é€šè¿‡: {rule_passed}")
    print(f"  - LLMéªŒè¯: {llm_verified}")
    print(f"  - æœ€ç»ˆé€‰æ‹©: {len(selected_cves)}")
    
    # æŒ‰ CVE ID æ’åº
    selected_cves = dict(sorted(selected_cves.items()))
    
    # ä¿å­˜
    print(f"\n[4/4] ä¿å­˜åˆ° {OUTPUT_FILE}...")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(selected_cves, f, indent=4, ensure_ascii=False)
    
    # ç»Ÿè®¡å­—æ®µå¡«å……æƒ…å†µ
    with_commits = sum(1 for v in selected_cves.values() if v.get("patch_commits"))
    with_adv = sum(1 for v in selected_cves.values() if v.get("sec_adv"))
    with_wget = sum(1 for v in selected_cves.values() if v.get("sw_version_wget"))
    with_desc = sum(1 for v in selected_cves.values() if v.get("description"))
    with_cwe = sum(1 for v in selected_cves.values() if v.get("cwe"))
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"   è¾“å‡º: {OUTPUT_FILE}")
    print(f"\n  å­—æ®µå¡«å……ç»Ÿè®¡:")
    print(f"  - description: {with_desc}/{len(selected_cves)}")
    print(f"  - patch_commits: {with_commits}/{len(selected_cves)}")
    print(f"  - sec_adv: {with_adv}/{len(selected_cves)}")
    print(f"  - sw_version_wget: {with_wget}/{len(selected_cves)}")
    print(f"  - cwe: {with_cwe}/{len(selected_cves)}")


if __name__ == "__main__":
    main()
