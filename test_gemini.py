#!/usr/bin/env python3
"""æµ‹è¯• Gemini API é…ç½®ï¼ˆé€šè¿‡ OpenAI å…¼å®¹æ¥å£ï¼‰"""
import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ£€æŸ¥ API key
openai_key = os.getenv('OPENAI_API_KEY')
google_key = os.getenv('GOOGLE_API_KEY')

print("=" * 60)
print("API Key æ£€æŸ¥:")
print(f"  OPENAI_API_KEY: {'âœ… exists' if openai_key else 'âŒ missing'} (length: {len(openai_key) if openai_key else 0})")
print(f"  GOOGLE_API_KEY: {'âœ… exists' if google_key else 'âŒ missing'} (length: {len(google_key) if google_key else 0})")
print("=" * 60)

if not google_key:
    print("âŒ GOOGLE_API_KEY not found in environment")
    sys.exit(1)

# æµ‹è¯•æ¨¡å‹æ³¨å†Œ
try:
    print("\nğŸ” Testing model registry...")
    from src.agentlib.agentlib.lib.common.available_llms import ModelRegistry
    
    # æµ‹è¯• GPT æ¨¡å‹
    gpt_name, gpt_class = ModelRegistry.get_llm_class_by_name('gpt-4o-mini')
    print(f"âœ… GPT model: gpt-4o-mini -> {gpt_name}")
    print(f"   Class: {gpt_class.__name__}")
    
    # æµ‹è¯• Gemini æ¨¡å‹
    gemini_name, gemini_class = ModelRegistry.get_llm_class_by_name('gemini-2.5-pro')
    print(f"âœ… Gemini model: gemini-2.5-pro -> {gemini_name}")
    print(f"   Class: {gemini_class.__name__}")
    
except Exception as e:
    print(f"âŒ Failed to load model: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æµ‹è¯•å®é™…è°ƒç”¨
try:
    print("\nğŸ§ª Testing Gemini API call...")
    print(f"   Using API key: {google_key[:10]}...{google_key[-10:]}")
    
    llm = gemini_class(
        model=gemini_name,
        temperature=0.5,
        base_url=os.getenv('OPENAI_API_BASE', 'https://api.openai-hub.com/v1')
    )
    
    response = llm.invoke("è¯·ç”¨ä¸­æ–‡å›å¤ï¼šä½ å¥½ï¼Œæµ‹è¯•ä¸€ä¸‹")
    print(f"âœ… Gemini å“åº”: {response.content}")
    
except Exception as e:
    print(f"âŒ API call failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print("\n" + "=" * 60)
print("ğŸ‰ All tests passed! Gemini is ready to use.")
print("=" * 60)
